{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture_02_Linear_Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w= 0.0\n",
      "\t 1.0 2.0 0.0 4.0\n",
      "\t 2.0 4.0 0.0 16.0\n",
      "\t 3.0 6.0 0.0 36.0\n",
      "MSE= 18.666666666666668\n",
      "w= 0.1\n",
      "\t 1.0 2.0 0.1 3.61\n",
      "\t 2.0 4.0 0.2 14.44\n",
      "\t 3.0 6.0 0.30000000000000004 32.49\n",
      "MSE= 16.846666666666668\n",
      "w= 0.2\n",
      "\t 1.0 2.0 0.2 3.24\n",
      "\t 2.0 4.0 0.4 12.96\n",
      "\t 3.0 6.0 0.6000000000000001 29.160000000000004\n",
      "MSE= 15.120000000000003\n",
      "w= 0.30000000000000004\n",
      "\t 1.0 2.0 0.30000000000000004 2.8899999999999997\n",
      "\t 2.0 4.0 0.6000000000000001 11.559999999999999\n",
      "\t 3.0 6.0 0.9000000000000001 26.009999999999998\n",
      "MSE= 13.486666666666665\n",
      "w= 0.4\n",
      "\t 1.0 2.0 0.4 2.5600000000000005\n",
      "\t 2.0 4.0 0.8 10.240000000000002\n",
      "\t 3.0 6.0 1.2000000000000002 23.04\n",
      "MSE= 11.946666666666667\n",
      "w= 0.5\n",
      "\t 1.0 2.0 0.5 2.25\n",
      "\t 2.0 4.0 1.0 9.0\n",
      "\t 3.0 6.0 1.5 20.25\n",
      "MSE= 10.5\n",
      "w= 0.6000000000000001\n",
      "\t 1.0 2.0 0.6000000000000001 1.9599999999999997\n",
      "\t 2.0 4.0 1.2000000000000002 7.839999999999999\n",
      "\t 3.0 6.0 1.8000000000000003 17.639999999999993\n",
      "MSE= 9.146666666666663\n",
      "w= 0.7000000000000001\n",
      "\t 1.0 2.0 0.7000000000000001 1.6899999999999995\n",
      "\t 2.0 4.0 1.4000000000000001 6.759999999999998\n",
      "\t 3.0 6.0 2.1 15.209999999999999\n",
      "MSE= 7.886666666666666\n",
      "w= 0.8\n",
      "\t 1.0 2.0 0.8 1.44\n",
      "\t 2.0 4.0 1.6 5.76\n",
      "\t 3.0 6.0 2.4000000000000004 12.959999999999997\n",
      "MSE= 6.719999999999999\n",
      "w= 0.9\n",
      "\t 1.0 2.0 0.9 1.2100000000000002\n",
      "\t 2.0 4.0 1.8 4.840000000000001\n",
      "\t 3.0 6.0 2.7 10.889999999999999\n",
      "MSE= 5.646666666666666\n",
      "w= 1.0\n",
      "\t 1.0 2.0 1.0 1.0\n",
      "\t 2.0 4.0 2.0 4.0\n",
      "\t 3.0 6.0 3.0 9.0\n",
      "MSE= 4.666666666666667\n",
      "w= 1.1\n",
      "\t 1.0 2.0 1.1 0.8099999999999998\n",
      "\t 2.0 4.0 2.2 3.2399999999999993\n",
      "\t 3.0 6.0 3.3000000000000003 7.289999999999998\n",
      "MSE= 3.779999999999999\n",
      "w= 1.2000000000000002\n",
      "\t 1.0 2.0 1.2000000000000002 0.6399999999999997\n",
      "\t 2.0 4.0 2.4000000000000004 2.5599999999999987\n",
      "\t 3.0 6.0 3.6000000000000005 5.759999999999997\n",
      "MSE= 2.986666666666665\n",
      "w= 1.3\n",
      "\t 1.0 2.0 1.3 0.48999999999999994\n",
      "\t 2.0 4.0 2.6 1.9599999999999997\n",
      "\t 3.0 6.0 3.9000000000000004 4.409999999999998\n",
      "MSE= 2.2866666666666657\n",
      "w= 1.4000000000000001\n",
      "\t 1.0 2.0 1.4000000000000001 0.3599999999999998\n",
      "\t 2.0 4.0 2.8000000000000003 1.4399999999999993\n",
      "\t 3.0 6.0 4.2 3.2399999999999993\n",
      "MSE= 1.6799999999999995\n",
      "w= 1.5\n",
      "\t 1.0 2.0 1.5 0.25\n",
      "\t 2.0 4.0 3.0 1.0\n",
      "\t 3.0 6.0 4.5 2.25\n",
      "MSE= 1.1666666666666667\n",
      "w= 1.6\n",
      "\t 1.0 2.0 1.6 0.15999999999999992\n",
      "\t 2.0 4.0 3.2 0.6399999999999997\n",
      "\t 3.0 6.0 4.800000000000001 1.4399999999999984\n",
      "MSE= 0.746666666666666\n",
      "w= 1.7000000000000002\n",
      "\t 1.0 2.0 1.7000000000000002 0.0899999999999999\n",
      "\t 2.0 4.0 3.4000000000000004 0.3599999999999996\n",
      "\t 3.0 6.0 5.1000000000000005 0.809999999999999\n",
      "MSE= 0.4199999999999995\n",
      "w= 1.8\n",
      "\t 1.0 2.0 1.8 0.03999999999999998\n",
      "\t 2.0 4.0 3.6 0.15999999999999992\n",
      "\t 3.0 6.0 5.4 0.3599999999999996\n",
      "MSE= 0.1866666666666665\n",
      "w= 1.9000000000000001\n",
      "\t 1.0 2.0 1.9000000000000001 0.009999999999999974\n",
      "\t 2.0 4.0 3.8000000000000003 0.0399999999999999\n",
      "\t 3.0 6.0 5.7 0.0899999999999999\n",
      "MSE= 0.046666666666666586\n",
      "w= 2.0\n",
      "\t 1.0 2.0 2.0 0.0\n",
      "\t 2.0 4.0 4.0 0.0\n",
      "\t 3.0 6.0 6.0 0.0\n",
      "MSE= 0.0\n",
      "w= 2.1\n",
      "\t 1.0 2.0 2.1 0.010000000000000018\n",
      "\t 2.0 4.0 4.2 0.04000000000000007\n",
      "\t 3.0 6.0 6.300000000000001 0.09000000000000043\n",
      "MSE= 0.046666666666666835\n",
      "w= 2.2\n",
      "\t 1.0 2.0 2.2 0.04000000000000007\n",
      "\t 2.0 4.0 4.4 0.16000000000000028\n",
      "\t 3.0 6.0 6.6000000000000005 0.36000000000000065\n",
      "MSE= 0.18666666666666698\n",
      "w= 2.3000000000000003\n",
      "\t 1.0 2.0 2.3000000000000003 0.09000000000000016\n",
      "\t 2.0 4.0 4.6000000000000005 0.36000000000000065\n",
      "\t 3.0 6.0 6.9 0.8100000000000006\n",
      "MSE= 0.42000000000000054\n",
      "w= 2.4000000000000004\n",
      "\t 1.0 2.0 2.4000000000000004 0.16000000000000028\n",
      "\t 2.0 4.0 4.800000000000001 0.6400000000000011\n",
      "\t 3.0 6.0 7.200000000000001 1.4400000000000026\n",
      "MSE= 0.7466666666666679\n",
      "w= 2.5\n",
      "\t 1.0 2.0 2.5 0.25\n",
      "\t 2.0 4.0 5.0 1.0\n",
      "\t 3.0 6.0 7.5 2.25\n",
      "MSE= 1.1666666666666667\n",
      "w= 2.6\n",
      "\t 1.0 2.0 2.6 0.3600000000000001\n",
      "\t 2.0 4.0 5.2 1.4400000000000004\n",
      "\t 3.0 6.0 7.800000000000001 3.2400000000000024\n",
      "MSE= 1.6800000000000008\n",
      "w= 2.7\n",
      "\t 1.0 2.0 2.7 0.49000000000000027\n",
      "\t 2.0 4.0 5.4 1.960000000000001\n",
      "\t 3.0 6.0 8.100000000000001 4.410000000000006\n",
      "MSE= 2.2866666666666693\n",
      "w= 2.8000000000000003\n",
      "\t 1.0 2.0 2.8000000000000003 0.6400000000000005\n",
      "\t 2.0 4.0 5.6000000000000005 2.560000000000002\n",
      "\t 3.0 6.0 8.4 5.760000000000002\n",
      "MSE= 2.986666666666668\n",
      "w= 2.9000000000000004\n",
      "\t 1.0 2.0 2.9000000000000004 0.8100000000000006\n",
      "\t 2.0 4.0 5.800000000000001 3.2400000000000024\n",
      "\t 3.0 6.0 8.700000000000001 7.290000000000005\n",
      "MSE= 3.780000000000003\n",
      "w= 3.0\n",
      "\t 1.0 2.0 3.0 1.0\n",
      "\t 2.0 4.0 6.0 4.0\n",
      "\t 3.0 6.0 9.0 9.0\n",
      "MSE= 4.666666666666667\n",
      "w= 3.1\n",
      "\t 1.0 2.0 3.1 1.2100000000000002\n",
      "\t 2.0 4.0 6.2 4.840000000000001\n",
      "\t 3.0 6.0 9.3 10.890000000000004\n",
      "MSE= 5.646666666666668\n",
      "w= 3.2\n",
      "\t 1.0 2.0 3.2 1.4400000000000004\n",
      "\t 2.0 4.0 6.4 5.760000000000002\n",
      "\t 3.0 6.0 9.600000000000001 12.96000000000001\n",
      "MSE= 6.720000000000003\n",
      "w= 3.3000000000000003\n",
      "\t 1.0 2.0 3.3000000000000003 1.6900000000000006\n",
      "\t 2.0 4.0 6.6000000000000005 6.7600000000000025\n",
      "\t 3.0 6.0 9.9 15.210000000000003\n",
      "MSE= 7.886666666666668\n",
      "w= 3.4000000000000004\n",
      "\t 1.0 2.0 3.4000000000000004 1.960000000000001\n",
      "\t 2.0 4.0 6.800000000000001 7.840000000000004\n",
      "\t 3.0 6.0 10.200000000000001 17.640000000000008\n",
      "MSE= 9.14666666666667\n",
      "w= 3.5\n",
      "\t 1.0 2.0 3.5 2.25\n",
      "\t 2.0 4.0 7.0 9.0\n",
      "\t 3.0 6.0 10.5 20.25\n",
      "MSE= 10.5\n",
      "w= 3.6\n",
      "\t 1.0 2.0 3.6 2.5600000000000005\n",
      "\t 2.0 4.0 7.2 10.240000000000002\n",
      "\t 3.0 6.0 10.8 23.040000000000006\n",
      "MSE= 11.94666666666667\n",
      "w= 3.7\n",
      "\t 1.0 2.0 3.7 2.8900000000000006\n",
      "\t 2.0 4.0 7.4 11.560000000000002\n",
      "\t 3.0 6.0 11.100000000000001 26.010000000000016\n",
      "MSE= 13.486666666666673\n",
      "w= 3.8000000000000003\n",
      "\t 1.0 2.0 3.8000000000000003 3.240000000000001\n",
      "\t 2.0 4.0 7.6000000000000005 12.960000000000004\n",
      "\t 3.0 6.0 11.4 29.160000000000004\n",
      "MSE= 15.120000000000005\n",
      "w= 3.9000000000000004\n",
      "\t 1.0 2.0 3.9000000000000004 3.610000000000001\n",
      "\t 2.0 4.0 7.800000000000001 14.440000000000005\n",
      "\t 3.0 6.0 11.700000000000001 32.49000000000001\n",
      "MSE= 16.84666666666667\n",
      "w= 4.0\n",
      "\t 1.0 2.0 4.0 4.0\n",
      "\t 2.0 4.0 8.0 16.0\n",
      "\t 3.0 6.0 12.0 36.0\n",
      "MSE= 18.666666666666668\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 构造训练数据集\n",
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "\n",
    "def forward(x):\n",
    "    return x*w\n",
    "\n",
    "def loss(x, y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred-y)*(y_pred-y)  # 平方损失\n",
    "\n",
    "w_list = []  # 记录尝试的权重\n",
    "mse_list = []  # 记录每个权重对应的平方损失\n",
    "\n",
    "for w in np.arange(0.0, 4.1, 0.1):  # 初步能够确定w的取值的范围会导致损失函数最小\n",
    "    print('w=', w)\n",
    "    l_sum = 0\n",
    "    for x_val, y_val in zip(x_data, y_data):\n",
    "        y_pred_val = forward(x_val)\n",
    "        loss_val = loss(x_val, y_val)\n",
    "        l_sum += loss_val  # 总的损失加上所有样本点的损失\n",
    "        print('\\t', x_val, y_val, y_pred_val, loss_val)\n",
    "    print('MSE=', l_sum/3)  # 对于每个w，样本数据计算出来的均方误差\n",
    "    w_list.append(w)\n",
    "    mse_list.append(l_sum/3)\n",
    "\n",
    "plt.plot(w_list, mse_list)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('w')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- exercise\n",
    "    - 实现y=k*x+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 第一种方法：自己实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w=0.0,b=0.0\n",
      "MSE= 27.666666666666668\n",
      "w=0.2,b=0.0\n",
      "MSE= 23.320000000000004\n",
      "w=0.4,b=0.0\n",
      "MSE= 19.346666666666668\n",
      "w=0.6000000000000001,b=0.0\n",
      "MSE= 15.746666666666664\n",
      "w=0.8,b=0.0\n",
      "MSE= 12.519999999999998\n",
      "w=1.0,b=0.0\n",
      "MSE= 9.666666666666666\n",
      "w=1.2000000000000002,b=0.0\n",
      "MSE= 7.186666666666665\n",
      "w=1.4000000000000001,b=0.0\n",
      "MSE= 5.079999999999999\n",
      "w=1.6,b=0.0\n",
      "MSE= 3.3466666666666653\n",
      "w=1.8,b=0.0\n",
      "MSE= 1.9866666666666661\n",
      "w=2.0,b=0.0\n",
      "MSE= 1.0\n",
      "w=2.2,b=0.0\n",
      "MSE= 0.38666666666666627\n",
      "w=2.4000000000000004,b=0.0\n",
      "MSE= 0.14666666666666658\n",
      "w=2.6,b=0.0\n",
      "MSE= 0.28000000000000036\n",
      "w=2.8000000000000003,b=0.0\n",
      "MSE= 0.7866666666666672\n",
      "w=3.0,b=0.0\n",
      "MSE= 1.6666666666666667\n",
      "w=3.2,b=0.0\n",
      "MSE= 2.920000000000003\n",
      "w=3.4000000000000004,b=0.0\n",
      "MSE= 4.5466666666666695\n",
      "w=3.6,b=0.0\n",
      "MSE= 6.5466666666666695\n",
      "w=3.8000000000000003,b=0.0\n",
      "MSE= 8.920000000000002\n",
      "w=0.0,b=0.2\n",
      "MSE= 25.706666666666663\n",
      "w=0.2,b=0.2\n",
      "MSE= 21.52\n",
      "w=0.4,b=0.2\n",
      "MSE= 17.706666666666663\n",
      "w=0.6000000000000001,b=0.2\n",
      "MSE= 14.266666666666666\n",
      "w=0.8,b=0.2\n",
      "MSE= 11.199999999999998\n",
      "w=1.0,b=0.2\n",
      "MSE= 8.506666666666666\n",
      "w=1.2000000000000002,b=0.2\n",
      "MSE= 6.186666666666664\n",
      "w=1.4000000000000001,b=0.2\n",
      "MSE= 4.239999999999998\n",
      "w=1.6,b=0.2\n",
      "MSE= 2.6666666666666647\n",
      "w=1.8,b=0.2\n",
      "MSE= 1.466666666666666\n",
      "w=2.0,b=0.2\n",
      "MSE= 0.6399999999999997\n",
      "w=2.2,b=0.2\n",
      "MSE= 0.1866666666666663\n",
      "w=2.4000000000000004,b=0.2\n",
      "MSE= 0.10666666666666687\n",
      "w=2.6,b=0.2\n",
      "MSE= 0.4000000000000001\n",
      "w=2.8000000000000003,b=0.2\n",
      "MSE= 1.0666666666666667\n",
      "w=3.0,b=0.2\n",
      "MSE= 2.106666666666666\n",
      "w=3.2,b=0.2\n",
      "MSE= 3.520000000000002\n",
      "w=3.4000000000000004,b=0.2\n",
      "MSE= 5.306666666666668\n",
      "w=3.6,b=0.2\n",
      "MSE= 7.466666666666668\n",
      "w=3.8000000000000003,b=0.2\n",
      "MSE= 10.0\n",
      "w=0.0,b=0.4\n",
      "MSE= 23.826666666666664\n",
      "w=0.2,b=0.4\n",
      "MSE= 19.8\n",
      "w=0.4,b=0.4\n",
      "MSE= 16.14666666666667\n",
      "w=0.6000000000000001,b=0.4\n",
      "MSE= 12.866666666666665\n",
      "w=0.8,b=0.4\n",
      "MSE= 9.959999999999997\n",
      "w=1.0,b=0.4\n",
      "MSE= 7.426666666666667\n",
      "w=1.2000000000000002,b=0.4\n",
      "MSE= 5.266666666666665\n",
      "w=1.4000000000000001,b=0.4\n",
      "MSE= 3.4799999999999986\n",
      "w=1.6,b=0.4\n",
      "MSE= 2.066666666666665\n",
      "w=1.8,b=0.4\n",
      "MSE= 1.0266666666666662\n",
      "w=2.0,b=0.4\n",
      "MSE= 0.3599999999999998\n",
      "w=2.2,b=0.4\n",
      "MSE= 0.06666666666666654\n",
      "w=2.4000000000000004,b=0.4\n",
      "MSE= 0.14666666666666736\n",
      "w=2.6,b=0.4\n",
      "MSE= 0.6000000000000011\n",
      "w=2.8000000000000003,b=0.4\n",
      "MSE= 1.4266666666666683\n",
      "w=3.0,b=0.4\n",
      "MSE= 2.6266666666666674\n",
      "w=3.2,b=0.4\n",
      "MSE= 4.200000000000004\n",
      "w=3.4000000000000004,b=0.4\n",
      "MSE= 6.146666666666672\n",
      "w=3.6,b=0.4\n",
      "MSE= 8.46666666666667\n",
      "w=3.8000000000000003,b=0.4\n",
      "MSE= 11.160000000000002\n",
      "w=0.0,b=0.6000000000000001\n",
      "MSE= 22.02666666666667\n",
      "w=0.2,b=0.6000000000000001\n",
      "MSE= 18.16\n",
      "w=0.4,b=0.6000000000000001\n",
      "MSE= 14.666666666666663\n",
      "w=0.6000000000000001,b=0.6000000000000001\n",
      "MSE= 11.546666666666665\n",
      "w=0.8,b=0.6000000000000001\n",
      "MSE= 8.799999999999999\n",
      "w=1.0,b=0.6000000000000001\n",
      "MSE= 6.426666666666666\n",
      "w=1.2000000000000002,b=0.6000000000000001\n",
      "MSE= 4.426666666666663\n",
      "w=1.4000000000000001,b=0.6000000000000001\n",
      "MSE= 2.7999999999999985\n",
      "w=1.6,b=0.6000000000000001\n",
      "MSE= 1.546666666666666\n",
      "w=1.8,b=0.6000000000000001\n",
      "MSE= 0.6666666666666664\n",
      "w=2.0,b=0.6000000000000001\n",
      "MSE= 0.16000000000000014\n",
      "w=2.2,b=0.6000000000000001\n",
      "MSE= 0.026666666666666772\n",
      "w=2.4000000000000004,b=0.6000000000000001\n",
      "MSE= 0.2666666666666671\n",
      "w=2.6,b=0.6000000000000001\n",
      "MSE= 0.8800000000000008\n",
      "w=2.8000000000000003,b=0.6000000000000001\n",
      "MSE= 1.8666666666666678\n",
      "w=3.0,b=0.6000000000000001\n",
      "MSE= 3.2266666666666652\n",
      "w=3.2,b=0.6000000000000001\n",
      "MSE= 4.960000000000003\n",
      "w=3.4000000000000004,b=0.6000000000000001\n",
      "MSE= 7.066666666666669\n",
      "w=3.6,b=0.6000000000000001\n",
      "MSE= 9.546666666666669\n",
      "w=3.8000000000000003,b=0.6000000000000001\n",
      "MSE= 12.400000000000004\n",
      "w=0.0,b=0.8\n",
      "MSE= 20.30666666666667\n",
      "w=0.2,b=0.8\n",
      "MSE= 16.599999999999998\n",
      "w=0.4,b=0.8\n",
      "MSE= 13.266666666666666\n",
      "w=0.6000000000000001,b=0.8\n",
      "MSE= 10.306666666666665\n",
      "w=0.8,b=0.8\n",
      "MSE= 7.719999999999999\n",
      "w=1.0,b=0.8\n",
      "MSE= 5.506666666666668\n",
      "w=1.2000000000000002,b=0.8\n",
      "MSE= 3.6666666666666656\n",
      "w=1.4000000000000001,b=0.8\n",
      "MSE= 2.1999999999999993\n",
      "w=1.6,b=0.8\n",
      "MSE= 1.106666666666666\n",
      "w=1.8,b=0.8\n",
      "MSE= 0.38666666666666644\n",
      "w=2.0,b=0.8\n",
      "MSE= 0.04000000000000007\n",
      "w=2.2,b=0.8\n",
      "MSE= 0.06666666666666678\n",
      "w=2.4000000000000004,b=0.8\n",
      "MSE= 0.4666666666666681\n",
      "w=2.6,b=0.8\n",
      "MSE= 1.2400000000000018\n",
      "w=2.8000000000000003,b=0.8\n",
      "MSE= 2.3866666666666685\n",
      "w=3.0,b=0.8\n",
      "MSE= 3.9066666666666676\n",
      "w=3.2,b=0.8\n",
      "MSE= 5.800000000000005\n",
      "w=3.4000000000000004,b=0.8\n",
      "MSE= 8.066666666666672\n",
      "w=3.6,b=0.8\n",
      "MSE= 10.706666666666672\n",
      "w=3.8000000000000003,b=0.8\n",
      "MSE= 13.720000000000004\n",
      "w=0.0,b=1.0\n",
      "MSE= 18.666666666666668\n",
      "w=0.2,b=1.0\n",
      "MSE= 15.120000000000003\n",
      "w=0.4,b=1.0\n",
      "MSE= 11.946666666666667\n",
      "w=0.6000000000000001,b=1.0\n",
      "MSE= 9.146666666666663\n",
      "w=0.8,b=1.0\n",
      "MSE= 6.719999999999999\n",
      "w=1.0,b=1.0\n",
      "MSE= 4.666666666666667\n",
      "w=1.2000000000000002,b=1.0\n",
      "MSE= 2.986666666666665\n",
      "w=1.4000000000000001,b=1.0\n",
      "MSE= 1.6799999999999995\n",
      "w=1.6,b=1.0\n",
      "MSE= 0.746666666666666\n",
      "w=1.8,b=1.0\n",
      "MSE= 0.18666666666666665\n",
      "w=2.0,b=1.0\n",
      "MSE= 0.0\n",
      "w=2.2,b=1.0\n",
      "MSE= 0.18666666666666698\n",
      "w=2.4000000000000004,b=1.0\n",
      "MSE= 0.7466666666666679\n",
      "w=2.6,b=1.0\n",
      "MSE= 1.6800000000000008\n",
      "w=2.8000000000000003,b=1.0\n",
      "MSE= 2.986666666666668\n",
      "w=3.0,b=1.0\n",
      "MSE= 4.666666666666667\n",
      "w=3.2,b=1.0\n",
      "MSE= 6.720000000000003\n",
      "w=3.4000000000000004,b=1.0\n",
      "MSE= 9.14666666666667\n",
      "w=3.6,b=1.0\n",
      "MSE= 11.946666666666667\n",
      "w=3.8000000000000003,b=1.0\n",
      "MSE= 15.120000000000005\n",
      "w=0.0,b=1.2000000000000002\n",
      "MSE= 17.106666666666666\n",
      "w=0.2,b=1.2000000000000002\n",
      "MSE= 13.719999999999997\n",
      "w=0.4,b=1.2000000000000002\n",
      "MSE= 10.706666666666665\n",
      "w=0.6000000000000001,b=1.2000000000000002\n",
      "MSE= 8.066666666666665\n",
      "w=0.8,b=1.2000000000000002\n",
      "MSE= 5.799999999999998\n",
      "w=1.0,b=1.2000000000000002\n",
      "MSE= 3.9066666666666663\n",
      "w=1.2000000000000002,b=1.2000000000000002\n",
      "MSE= 2.386666666666665\n",
      "w=1.4000000000000001,b=1.2000000000000002\n",
      "MSE= 1.2399999999999995\n",
      "w=1.6,b=1.2000000000000002\n",
      "MSE= 0.4666666666666659\n",
      "w=1.8,b=1.2000000000000002\n",
      "MSE= 0.06666666666666643\n",
      "w=2.0,b=1.2000000000000002\n",
      "MSE= 0.04000000000000007\n",
      "w=2.2,b=1.2000000000000002\n",
      "MSE= 0.3866666666666673\n",
      "w=2.4000000000000004,b=1.2000000000000002\n",
      "MSE= 1.1066666666666694\n",
      "w=2.6,b=1.2000000000000002\n",
      "MSE= 2.2000000000000006\n",
      "w=2.8000000000000003,b=1.2000000000000002\n",
      "MSE= 3.66666666666667\n",
      "w=3.0,b=1.2000000000000002\n",
      "MSE= 5.506666666666665\n",
      "w=3.2,b=1.2000000000000002\n",
      "MSE= 7.720000000000003\n",
      "w=3.4000000000000004,b=1.2000000000000002\n",
      "MSE= 10.306666666666674\n",
      "w=3.6,b=1.2000000000000002\n",
      "MSE= 13.266666666666667\n",
      "w=3.8000000000000003,b=1.2000000000000002\n",
      "MSE= 16.60000000000001\n",
      "w=0.0,b=1.4000000000000001\n",
      "MSE= 15.626666666666665\n",
      "w=0.2,b=1.4000000000000001\n",
      "MSE= 12.399999999999999\n",
      "w=0.4,b=1.4000000000000001\n",
      "MSE= 9.546666666666665\n",
      "w=0.6000000000000001,b=1.4000000000000001\n",
      "MSE= 7.0666666666666655\n",
      "w=0.8,b=1.4000000000000001\n",
      "MSE= 4.959999999999998\n",
      "w=1.0,b=1.4000000000000001\n",
      "MSE= 3.2266666666666652\n",
      "w=1.2000000000000002,b=1.4000000000000001\n",
      "MSE= 1.8666666666666647\n",
      "w=1.4000000000000001,b=1.4000000000000001\n",
      "MSE= 0.8799999999999993\n",
      "w=1.6,b=1.4000000000000001\n",
      "MSE= 0.266666666666666\n",
      "w=1.8,b=1.4000000000000001\n",
      "MSE= 0.0266666666666666\n",
      "w=2.0,b=1.4000000000000001\n",
      "MSE= 0.16000000000000028\n",
      "w=2.2,b=1.4000000000000001\n",
      "MSE= 0.6666666666666673\n",
      "w=2.4000000000000004,b=1.4000000000000001\n",
      "MSE= 1.5466666666666693\n",
      "w=2.6,b=1.4000000000000001\n",
      "MSE= 2.800000000000002\n",
      "w=2.8000000000000003,b=1.4000000000000001\n",
      "MSE= 4.426666666666669\n",
      "w=3.0,b=1.4000000000000001\n",
      "MSE= 6.4266666666666685\n",
      "w=3.2,b=1.4000000000000001\n",
      "MSE= 8.800000000000006\n",
      "w=3.4000000000000004,b=1.4000000000000001\n",
      "MSE= 11.546666666666674\n",
      "w=3.6,b=1.4000000000000001\n",
      "MSE= 14.66666666666667\n",
      "w=3.8000000000000003,b=1.4000000000000001\n",
      "MSE= 18.16\n",
      "w=0.0,b=1.6\n",
      "MSE= 14.226666666666667\n",
      "w=0.2,b=1.6\n",
      "MSE= 11.159999999999998\n",
      "w=0.4,b=1.6\n",
      "MSE= 8.466666666666663\n",
      "w=0.6000000000000001,b=1.6\n",
      "MSE= 6.146666666666666\n",
      "w=0.8,b=1.6\n",
      "MSE= 4.199999999999999\n",
      "w=1.0,b=1.6\n",
      "MSE= 2.626666666666667\n",
      "w=1.2000000000000002,b=1.6\n",
      "MSE= 1.4266666666666652\n",
      "w=1.4000000000000001,b=1.6\n",
      "MSE= 0.5999999999999993\n",
      "w=1.6,b=1.6\n",
      "MSE= 0.14666666666666647\n",
      "w=1.8,b=1.6\n",
      "MSE= 0.06666666666666678\n",
      "w=2.0,b=1.6\n",
      "MSE= 0.3599999999999998\n",
      "w=2.2,b=1.6\n",
      "MSE= 1.0266666666666677\n",
      "w=2.4000000000000004,b=1.6\n",
      "MSE= 2.0666666666666678\n",
      "w=2.6,b=1.6\n",
      "MSE= 3.4800000000000018\n",
      "w=2.8000000000000003,b=1.6\n",
      "MSE= 5.266666666666668\n",
      "w=3.0,b=1.6\n",
      "MSE= 7.426666666666665\n",
      "w=3.2,b=1.6\n",
      "MSE= 9.960000000000003\n",
      "w=3.4000000000000004,b=1.6\n",
      "MSE= 12.866666666666669\n",
      "w=3.6,b=1.6\n",
      "MSE= 16.146666666666672\n",
      "w=3.8000000000000003,b=1.6\n",
      "MSE= 19.8\n",
      "w=0.0,b=1.8\n",
      "MSE= 12.906666666666668\n",
      "w=0.2,b=1.8\n",
      "MSE= 9.999999999999998\n",
      "w=0.4,b=1.8\n",
      "MSE= 7.466666666666666\n",
      "w=0.6000000000000001,b=1.8\n",
      "MSE= 5.306666666666666\n",
      "w=0.8,b=1.8\n",
      "MSE= 3.5199999999999996\n",
      "w=1.0,b=1.8\n",
      "MSE= 2.106666666666667\n",
      "w=1.2000000000000002,b=1.8\n",
      "MSE= 1.0666666666666662\n",
      "w=1.4000000000000001,b=1.8\n",
      "MSE= 0.3999999999999999\n",
      "w=1.6,b=1.8\n",
      "MSE= 0.10666666666666662\n",
      "w=1.8,b=1.8\n",
      "MSE= 0.1866666666666668\n",
      "w=2.0,b=1.8\n",
      "MSE= 0.6399999999999997\n",
      "w=2.2,b=1.8\n",
      "MSE= 1.466666666666667\n",
      "w=2.4000000000000004,b=1.8\n",
      "MSE= 2.6666666666666696\n",
      "w=2.6,b=1.8\n",
      "MSE= 4.240000000000003\n",
      "w=2.8000000000000003,b=1.8\n",
      "MSE= 6.18666666666667\n",
      "w=3.0,b=1.8\n",
      "MSE= 8.506666666666668\n",
      "w=3.2,b=1.8\n",
      "MSE= 11.200000000000008\n",
      "w=3.4000000000000004,b=1.8\n",
      "MSE= 14.266666666666675\n",
      "w=3.6,b=1.8\n",
      "MSE= 17.706666666666674\n",
      "w=3.8000000000000003,b=1.8\n",
      "MSE= 21.520000000000007\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 构造数据集\n",
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [3.0, 5.0, 7.0]\n",
    "\n",
    "def forward(x):  \n",
    "    return w*x+b\n",
    "\n",
    "def loss(x, y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred-y)*(y_pred-y)\n",
    "\n",
    "w_list = np.arange(0, 4, 0.2)\n",
    "b_list = np.arange(0, 2, 0.2)\n",
    "w_list, b_list = np.meshgrid(w_list, b_list)  # 形成矩阵\n",
    "mse_list = np.zeros_like(w_list)  # 最后的因变量也是矩阵\n",
    "for i in range(len(w_list)):\n",
    "    for j in range(len(w_list[0])):\n",
    "        l_sum = 0\n",
    "        w, b = w_list[i][j], b_list[i][j]\n",
    "        print('w={},b={}'.format(w, b))\n",
    "        for x_val, y_val in zip(x_data, y_data):\n",
    "            y_pred_val = forward(x_val)\n",
    "            loss_val = loss(x_val, y_val)\n",
    "            l_sum += loss_val\n",
    "        print('MSE=', l_sum/3)  # 对于每个w与b的组合对应的MSE\n",
    "        mse_list[i][j] = l_sum/3\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "surf = ax.plot_surface(w_list, b_list, mse_list, rstride=1, cstride=1, cmap=plt.cm.viridis)\n",
    "fig.colorbar(surf)\n",
    "ax.set_xlabel('w')\n",
    "ax.set_ylabel('b')\n",
    "ax.set_zlabel('loss')\n",
    "ax.set_title('loss surface')\n",
    "plt.show()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 第二种方法：[参考网址](https://blog.csdn.net/weixin_44841652/article/details/105017087)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.2 0.4 0.6 0.8 1.  1.2 1.4 1.6 1.8 2.  2.2 2.4 2.6 2.8 3.  3.2 3.4\n",
      "  3.6 3.8]\n",
      " [0.2 0.4 0.6 0.8 1.  1.2 1.4 1.6 1.8 2.  2.2 2.4 2.6 2.8 3.  3.2 3.4 3.6\n",
      "  3.8 4. ]\n",
      " [0.4 0.6 0.8 1.  1.2 1.4 1.6 1.8 2.  2.2 2.4 2.6 2.8 3.  3.2 3.4 3.6 3.8\n",
      "  4.  4.2]\n",
      " [0.6 0.8 1.  1.2 1.4 1.6 1.8 2.  2.2 2.4 2.6 2.8 3.  3.2 3.4 3.6 3.8 4.\n",
      "  4.2 4.4]\n",
      " [0.8 1.  1.2 1.4 1.6 1.8 2.  2.2 2.4 2.6 2.8 3.  3.2 3.4 3.6 3.8 4.  4.2\n",
      "  4.4 4.6]\n",
      " [1.  1.2 1.4 1.6 1.8 2.  2.2 2.4 2.6 2.8 3.  3.2 3.4 3.6 3.8 4.  4.2 4.4\n",
      "  4.6 4.8]\n",
      " [1.2 1.4 1.6 1.8 2.  2.2 2.4 2.6 2.8 3.  3.2 3.4 3.6 3.8 4.  4.2 4.4 4.6\n",
      "  4.8 5. ]\n",
      " [1.4 1.6 1.8 2.  2.2 2.4 2.6 2.8 3.  3.2 3.4 3.6 3.8 4.  4.2 4.4 4.6 4.8\n",
      "  5.  5.2]\n",
      " [1.6 1.8 2.  2.2 2.4 2.6 2.8 3.  3.2 3.4 3.6 3.8 4.  4.2 4.4 4.6 4.8 5.\n",
      "  5.2 5.4]\n",
      " [1.8 2.  2.2 2.4 2.6 2.8 3.  3.2 3.4 3.6 3.8 4.  4.2 4.4 4.6 4.8 5.  5.2\n",
      "  5.4 5.6]]\n",
      "[[0.  0.4 0.8 1.2 1.6 2.  2.4 2.8 3.2 3.6 4.  4.4 4.8 5.2 5.6 6.  6.4 6.8\n",
      "  7.2 7.6]\n",
      " [0.2 0.6 1.  1.4 1.8 2.2 2.6 3.  3.4 3.8 4.2 4.6 5.  5.4 5.8 6.2 6.6 7.\n",
      "  7.4 7.8]\n",
      " [0.4 0.8 1.2 1.6 2.  2.4 2.8 3.2 3.6 4.  4.4 4.8 5.2 5.6 6.  6.4 6.8 7.2\n",
      "  7.6 8. ]\n",
      " [0.6 1.  1.4 1.8 2.2 2.6 3.  3.4 3.8 4.2 4.6 5.  5.4 5.8 6.2 6.6 7.  7.4\n",
      "  7.8 8.2]\n",
      " [0.8 1.2 1.6 2.  2.4 2.8 3.2 3.6 4.  4.4 4.8 5.2 5.6 6.  6.4 6.8 7.2 7.6\n",
      "  8.  8.4]\n",
      " [1.  1.4 1.8 2.2 2.6 3.  3.4 3.8 4.2 4.6 5.  5.4 5.8 6.2 6.6 7.  7.4 7.8\n",
      "  8.2 8.6]\n",
      " [1.2 1.6 2.  2.4 2.8 3.2 3.6 4.  4.4 4.8 5.2 5.6 6.  6.4 6.8 7.2 7.6 8.\n",
      "  8.4 8.8]\n",
      " [1.4 1.8 2.2 2.6 3.  3.4 3.8 4.2 4.6 5.  5.4 5.8 6.2 6.6 7.  7.4 7.8 8.2\n",
      "  8.6 9. ]\n",
      " [1.6 2.  2.4 2.8 3.2 3.6 4.  4.4 4.8 5.2 5.6 6.  6.4 6.8 7.2 7.6 8.  8.4\n",
      "  8.8 9.2]\n",
      " [1.8 2.2 2.6 3.  3.4 3.8 4.2 4.6 5.  5.4 5.8 6.2 6.6 7.  7.4 7.8 8.2 8.6\n",
      "  9.  9.4]]\n",
      "[[ 0.   0.6  1.2  1.8  2.4  3.   3.6  4.2  4.8  5.4  6.   6.6  7.2  7.8\n",
      "   8.4  9.   9.6 10.2 10.8 11.4]\n",
      " [ 0.2  0.8  1.4  2.   2.6  3.2  3.8  4.4  5.   5.6  6.2  6.8  7.4  8.\n",
      "   8.6  9.2  9.8 10.4 11.  11.6]\n",
      " [ 0.4  1.   1.6  2.2  2.8  3.4  4.   4.6  5.2  5.8  6.4  7.   7.6  8.2\n",
      "   8.8  9.4 10.  10.6 11.2 11.8]\n",
      " [ 0.6  1.2  1.8  2.4  3.   3.6  4.2  4.8  5.4  6.   6.6  7.2  7.8  8.4\n",
      "   9.   9.6 10.2 10.8 11.4 12. ]\n",
      " [ 0.8  1.4  2.   2.6  3.2  3.8  4.4  5.   5.6  6.2  6.8  7.4  8.   8.6\n",
      "   9.2  9.8 10.4 11.  11.6 12.2]\n",
      " [ 1.   1.6  2.2  2.8  3.4  4.   4.6  5.2  5.8  6.4  7.   7.6  8.2  8.8\n",
      "   9.4 10.  10.6 11.2 11.8 12.4]\n",
      " [ 1.2  1.8  2.4  3.   3.6  4.2  4.8  5.4  6.   6.6  7.2  7.8  8.4  9.\n",
      "   9.6 10.2 10.8 11.4 12.  12.6]\n",
      " [ 1.4  2.   2.6  3.2  3.8  4.4  5.   5.6  6.2  6.8  7.4  8.   8.6  9.2\n",
      "   9.8 10.4 11.  11.6 12.2 12.8]\n",
      " [ 1.6  2.2  2.8  3.4  4.   4.6  5.2  5.8  6.4  7.   7.6  8.2  8.8  9.4\n",
      "  10.  10.6 11.2 11.8 12.4 13. ]\n",
      " [ 1.8  2.4  3.   3.6  4.2  4.8  5.4  6.   6.6  7.2  7.8  8.4  9.   9.6\n",
      "  10.2 10.8 11.4 12.  12.6 13.2]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAToAAAEvCAYAAADVWQ10AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAADIKElEQVR4nOz9d5xj+VXmj7+vslSSSpVzzjlXT8+MxziMwdjYxovBg3exMYtNXGDhu8QXyw+WxawBE7ywBLMYL2vDsiQbMGCzjhO6qyvnnKOqpFLO9/eH+qpVVSrpqlrVXdOj5/Wa18xUXX10pbr3uedzznOeI4iiSBZZZJHFkwzF4z6BLLLIIovrRpbossgiiyceWaLLIossnnhkiS6LLLJ44pEluiyyyOKJR5bossgiiyceqhS/z2pPssgii8cFIVMLZSO6LLLI4olHluiyyCKLJx5ZossiiyyeeGSJLosssnjikSW6LLLI4olHluiyyCKLJx5ZossiiyyeeGSJLosssnjikSW6LLLI4olHluiyyCKLJx5ZossiiyyeeGSJLosssnjikSW6LLLI4olHluiyyCKLJx5ZossiiyyeeGSJLosssnjikSW6LLLI4olHluiyyCKLJx5ZossiiyyeeGSJLosssnjikSW61wBEUSQcDhMMBhHF7LyjLF57SDUFLItXOURRJBQK4fP5CIVCCIKASqWK/aNUKhGEjA1byiKLGwkhxRM++/h/FSMSiRAIBGIRXSQSAaLkF4lEYgSnUqlQq9WoVCoUCkWW+LK4KcjYhZgluicQ8VtVQRAQBIFQKEQ4HL5AYqIonvlnf3+fqqqqLPFlcROQsQsvu3V9wiCKIoFAIBaxSSR1GVnFHwOwu7tLeXk5oVAo9vv4rW6W+LJ4NSJLdE8Q4req5wlMbhFCEAQUigc1KinHFwwGY7/PEl8WrzZkie4JgCiK+P1+IpEICoXiDFE9LBIRZjAYvEB8arUapVKZJb4sbiSy8pJXOaSt6t27dxPm4DINQRBQKpWxfwRBIBgM4vF4cDqdOBwO3G43fr+fcDiclbNkcSOQjehexTi/pUwFaUubSUjEF/8em5ubRCIRysvLUSgUscKGSqW6ECFmkcWjQJboXoWQ8maSLk7Kq92E6Ck+x6dSqWIRp9/vj52rWq2ObXWzxJfFo0CW6F5liEQiBIPBC1VVkF9weJSIj/ik8wsEAgQCAQAUCsWFHF8WWWQaWaJ7lSBeGwdcIISbEtElg0TKWeLL4lEjS3SvAkiVTqnYkGirJwjCjSe680hFfMfHx5hMJkwmU6xdLUt8WVwFWaK74UimjUt07E3AVXNu54nPZrOhVqvRaDT4/X6AM8WNLPFlIRdZoruhOF9wSHVDJ9u6+v1+pqenCQQC5OXlkZeXh9lsPlMtzTQyFV0qFIozEZ+kGZSIT6lUxra5UlU3iyzOI0t0NxCiKOJ2u1laWqKtrU3WzXvZMcfHx8zPz9PY2IjBYMDhcHB0dMTy8jIqlSpGfCaT6cZHR4mKL5FIBJ/PF4t4JeLLOrNkEY8s0d0wSFFcJBLB6XTKvlEFQTizdRVFkeXlZex2OwMDA6jVaoLBIEVFRRQVFQHRSM9ms7G7u4vT6USr1RIIBHA6nRiNxsdOEql0f8mIT0KW+LKALNHdGJzfqkoaNLmIL0b4fD6mpqbIy8tjcHAQQRAIh8MXXqPVaiktLaW0tBQAr9fL2NgYm5ubuFwuDAZDLOIzGAw3niQuI77Z2VkKCgrIzc3NEt9rFFmiuwFIpI1Lt4oqHX90dMTi4iKtra0UFBSkdR56vR61Wk1HRweiKOLxeLDZbKyuruLxeDAajTHi0+v16X7MR47471HqAY5EIni93jOFjyzxPfnIEt1jRDJt3FXkIpubmwSDQQYHB9FqtQ91boIgkJOTQ05ODpWVlYiiiMvlwmazsbi4iN/vx2QyxYjvYd8vETJV0IivWMcXdqSIL574su7LTyayRPeYkEobl84N5vV6OTg4oKioiO7u7mu5OQVBiGnaqqurYzlEm83G7OwswWCQ3Nxc8vLyYl52mXrfh8Vlub5ExBdvWAqcES9nie/ViyzRPQako41LhYODA5aXl8nPz6e0tPSR3YgKhYLc3Fxyc3Opra0lEolwenqKzWbj4OAgVhTIy8vDYrGgUj3eS01u5ToR8UnELUlapM+TtaR69SBLdI8Q6WrjkiESibCwsIDX62VoaIj19fXH2hmhUCjOFC58Ph8mkwmbzcb6+jqCIGCxWMjLy4sVBVIhk1vXq+D8Q8jhcODz+WLb9KwJ6asHWaJ7RBBFkcPDQwwGA2q1+qFuCI/Hw+TkJKWlpbS2tl6peHHdUCgUFBQUxAoiwWAQu92O1WplZWUFpVJ5Rrx8Gelf59b1KjgvYM66L786kCW6RwAp77OxsUF9fT0ajebKa+3t7bG2tkZHRwe5ubmxn6ciusd9w6nV6jMavkAggM1mY39/n8XFRTQazRnxcibPN1NEJ1VvJWTdl189yBLdNSLRVvWqUVc4HGZ+fp5gMMjQ0BBqtfrM729aRJcKGo2GkpISSkpKgKj2z2azsb29jdPpRK/X4/f78Xg85OTk3AiCiB8RmQiJTEjPE9/5Pt2b8LleC8gS3TUhkTbuqkTncrmYmpqioqKCqqqqJ8a9JB46nY6ysjLKysoQRRGv18vMzAy7u7usra2Rk5NzRsOXDkFcV0SXComITzIhXV9fp76+Puu+/IiQJboM47w2Lv7ilQSr6WBnZ4eNjQ06Ozsxm82XHvdqJ7p4CIKAwWDAYDBQW1uLwWDA7XZjs9lYXl7G5/OdES/rdLqk62WS6B5mnXjiOzk5oaGhIUZ88MCZJeu+nHlkiS6DSGRxHo/z/ajJEAqF8Hq9HB8fMzw8nFKekUmiu47ZEg8DQRAwGo0YjUaqqqqIRCIx8fL8/DyBQCCm4bNYLA+VA02GTH4v0vWRNSF9NMgSXYYgRxsnd+vqdDqZmppCqVTS3d0t6/2fpIhOwmWfR6FQYDabMZvN1NTUEIlEcDgcsRxfOByOSVksFsuNieiSIeu+fL3IEt1D4ryaPtnFlyqiE0WR7e1ttre36e7uZnJyUvbNlSmik9Z52C1apiBnLYVCgcViwWKxUFdXRzgcjomX19fX8Xg8bGxsUFRUJFvDlwjp5ugeBlniyyyyRPcQkJLLiQbVJEKyHF0oFGJ6ehqVSsXw8HAsR/OoiS5TeJznolQqyc/PJz8/H4DR0VHMZjPHx8dpafjOI1XVVS6u4gSdiPgkE4eTkxPq6uqy7stJkCW6KyISibC5uYlGoyE/P1925JGIAE5PT5mZmaG2tpby8vIzx0ciEVkXbDr5v1Tr3CTCzAQUCgWFhYWUlZUB0ajIbrdzcHBwQcNnNBov/b4fV/U2EeJF4vEV/az7cmJkiS5NxBccvF5vWhf/eTKShj3v7u7S09NDTk7OhePlkk4mt643BZkklnhoNBqKi4spLi4GEmv4JOKL1/Bl6nzkPrzSWSuReDlrQvoAWaJLA+e3qkqlMq0oKn7rGgwGmZ6eRqvVcuvWrYQXfiaJzu12c3x8TH5+viw5xpOEVASVSMMn5ffcbndMwyflxq77fNLBZaSZJb6zyBKdTJzvaZS2C1chOrvdzszMDI2NjbHOgGTHy137MoLa29tjdXWVoqIiFhYW8Pv9MTlGXl7emS6LJ3Hrmm7ULWn4KioqYvM7bDYbdrsdu90eq+jK0fAlwnVEdKkgh/hEUUSlUqHX65844ssSXQok08YpFIoY+cnF0dERe3t79PX1YTAYkh6bLumcPzYSiTA/P4/f72doaCh2w8dbKm1tbSGKIhaLhfz8/BtFcjfhXOI1fB6PJ2aFFa/hM5vNMeKTo+F7FBFdKiQivt3dXUKhEJWVlcCTFfFliS4JErVxxSOdiCsQCLCxsYFKpWJoaEj2U1juzX4+ovN6vUxMTFBaWkpbW1us71I6VroxIRqtSs4iTqeTyclJCgoKyM/Pv1KDfSajwpukf5NIxWQyJdTw7ezsEA6Hz4iXz/ckx6+TCUQikYx4/Ul/M6l4kch9+dVMfFmiS4BkFufxkEt0JycnzM3NUVRUlFbZP51Kajy5HB4esrS0REdHBxaLBXggR0h0capUKgoLCyksLMTj8dDY2IjL5Yol519tQ3LO4zoFw8k0fJubm7FoWSI+Ka/7qLeucteSiDk+PQOX286/WtyXs0R3DqkszuORiuhEUWR1dZXj42MGBgZwOBycnp7KPpd0TQDC4TALCwu4XC6GhoYubKPk6vHUanVsOpiUnD85OYkNyTGZTOTn51/brIibCjmEeV7DJ0XL0venUCgwGAyxotbDklQmiS4cDif1BTxPfPHuy/CA+G6iF1+W6OKQrsV5MqLz+/1MTk5isVgYHBxEoVDgcrmuNNlLDkKhEPv7+1RVVdHf35+wz/YqiE/OS0NynE4nJycnzM7OEgqFyM3NJT8/P+OW6ZnuLX1YXOV84qNliKYwdnZ2cDgcjIyMoFarH2qIeKaJTm7XSKIcXzzxCcLNMiHNEh0PCg6Li4tnnsapcBnRWa1WFhYWLowcTFfUK5fojo+PWVxcJDc3l4aGBtnrX+U9BUGI9ZnW1tbGtmonJycxy3SNRoNKpcroTXgTkAni1Wg0WCwWQqEQTU1NCYeIx4uXU73fTdkGJyI+SanwhS98gdnZWX7+538+I+d5FbzmiS5eGxcOhxMOer4M54kuEomwvLzM6elpwpGDV5WjJDt3aWvc2trK8fGx7LUzhfNbtWAwyPr6Oqenp4yMjMQ6R+TeuDcZmep1jSeUREPEpfyenCHijyuiS4V44nM4HI/9gfeaJjpJNiI9qdMVAMdHPz6fL1atHBwcfCj3kkTrn0cgEGBqagqTycTg4CAOh0P2uld9TzlQq9Xk5uaiVqupra29cOPm5OTEiC/VEOybZheVyertZevo9Xr0ej3l5eWIYuoh4jcloksG6bwfJ16TRJfI4hy4cqeDVOVsa2tLuu1Nd+t6GTFKguOmpqZYG1Omel0zjfM3riS+lYZgm83mWH7vunzkMoVMNfXLjQwFIfUQ8XA4jMFgQKPRPHRhKBKJZCyii4fL5YrlKB8XXnNEl0wbp1Ao0tq6QrQhPxQKJaxynsdVIrrzvbEbGxscHBzQ399/JiLKtE3TdSBefCsZaMb7yEUikTNSjJuGx93rKggXh4iPj48TCATOFIaSafiSIVnV9WHgdrupra3N+Lrp4DVDdHK0cenk0DweD1NTUwiCkLDKmQjp5ujiSSe+NzaR4PgmtW7JPZfzGrTzUgyv18vW1haFhYVXqkhmGjfNwFMavVhdXY1WqyUcDsceHOc1fLm5uSkr4pnM0cXD7XZnt66PAnK1cXJbuvb391lZWaG5uTlWaZSDq2xdpahnenqaurq6mNVQorVvekSXCuelGPfu3UOn08Uqkjqdjry8PPLz8x+LcPlxR3SJEB+FxfvsQTQHLYmX19bWEAThjA/feVLL5uhexUhHG6dUKmNeXokgCXL9fj/Dw8MIgsDq6qrsc7nKFDCpLSuRjVM8nkSbJoVCQXFxcay5XipsxAuXJeJ7FMLlTBJdpiKnZPk+lUqVcIj40dERy8vLqFSqMxo+uJ6/v+QA8zjxxBLdZQWHZEiWo3O73UxOTlJeXk5bW1ssOkt3K5rOcJyDgwOUSmXMcTjV2pmKxG7KFjj+PBK5ijidTmw2G7OzswSDwTOuIpkULsfjURYj5CCdKOz8EPHzGj6v18vm5mbGpUDZres1QdLGjYyMMDAwIPsPdlkObXd3l/X19QsjB9MlF7k5OmmOq8FgoLCwUNbT/0nYuibCZX+7eOFyTU3NmR7TjY0NBEG4kY4skPkt4lUJ6byG75VXXkGlUsnW8MmFy+WKRYyPC08c0UkFB8lWOp0/znkiCofDzM3NEQ6HE44cTPcPL2frure3x9raGp2dndjt9kfuMPxqRSLhst1u5/DwEI/Hw/j4eGyb+7iFyzdNHyhBoVBQXl4uW8MnF1Ka4XHiiSG6RFvVdC+meB2d0+lkenqaqqoqKioqMnJhJtu6St5xgUAgRqqnp6ePxUr9phDmwwqXpW2aw+GgtbX1gnA5/qZ9lMTzamiNk6Phk3Kkqcwd3G53Su/F68YTQXTJtHHpPD0VCgWhUIjt7W02Nzfp6urK6JPosvPweDxMTk7GvOOk4wRBkK3ru0kElUlkioDO26V7PB5OTk5YXl7G5/OdcWS5buFypoTHmUSqc0qk4TufI73MtfqqnnmCIFQBfwqUACLwB6Io/pYgCL8AfC9wdP/QnxFF8R+SrfWqJrrz2rjzJKdUKgmHw7K/5Egkgs1mQ6FQJNyqXgcSecdJSKdKm4roJAt3k8mU9HNlgjBv2k18HvHRiiRclhxZJPNMKb8nR3+WLjJZjMgU0o0yFQoFubm55ObmUltbe8G1OhKJEAqF2NraSlu4HIcQ8OOiKI4KgmAC7gmC8C/3f/cxURR/Te5Cr1qiS2ZxLiEdonM4HExNTaHRaOjq6rqOUz6DSCTC0tLSpd5xkLnhOH6/n4mJCdRqNV6vF4VCEctnXcVBWA5eTdFl/E0rmWfa7faY/kxyZA6HwzfKQy6T3/HDioUTuVbPzc3xta99jY2NDV73utfx+te/nm/7tm+jr69P1pqiKO4Be/f/2ykIwhxQcZXze1USnVxtnJwqpyiKbG1tsbOzQ0dHBysrK9dxymcQbwCQrKsiExGdtLVobm7GbDYjCAKBQICTk5OYg7CUr5Lm094Uknpc56FUKs/ozwKBADabjWAwyMjICFqtNrbNjR+HKBc3rcMCMt/nqlKp6Orq4jd/8zcZHR3lc5/7HF/5ylew2+1XWk8QhFqgD3gFeAb4IUEQvgsYIRr12ZKez5Xe9TEhfqsqRxsnRXSXIb6tanh4OLb+Vc5L7gUXCoW4d+/eBa+6REhHd3eeoEQxOjN2b2+P/v5+dDpdbFyfRqM54yAs5asWFxdxOBz4fD6CweC16tHk4mFv5EyQpUajoaSkhM3NTYaGhmKOy9I4RKPRGCM+OVPBMhXRPSp34YdBIBBAq9VisVh4xzvecaU1BEEwAv8X+FFRFB2CIPwe8EtE83a/BPw68MFka7xqiC7eNy5Vh4OEZBHd6ekp09PTNDQ0xHRE6QqA4QHBpDofURRZWVnB7/fz3HPPyVLyX3XrGgqFmJmZQalUMjQ0FBt2ctnr4vNVi4uL6HQ6HA5HTI+Wl5dHQUHBjeg3vQnQ6/VUVFTEhMtSNVKqml+WlJeQqWJEpi2arqvP9WG6IgRBUBMluT8TRfGvAERRPIj7/R8Cn0u1zquC6CKRCBsbGxgMBnJzc2VfJIkiOskBZH9//8LIwats2yQyTXbBBQIBJicnMZvNGAwG2e1K6W5d4UEHR1VVVWxsXTqQqmtSriUYDJ5Rz+t0ulh+77plGZmIxq5bs5aoGnl+lKREerm5ubGHzmslopOkPFeBEP3DfQKYE0XxN+J+XnY/fwfwrcB0qrVuNNHFFxw8Hk/ak4bOE10gEGB6ehq9Xs/w8HBCB5B0kSoPGJ8jKyoqwmq1yl47XROAYDDI+Pg4nZ2d5ObmJlxPznvGE4xaraa4uJji4uIzg3IkWYbkJ3dZ9PKwyMTWNVP5MDlIlJS32WxYrVZWVlZQqVT4fD7cbjdarfahzu3VYLr5kO1fzwD/DpgSBGH8/s9+BnhBEIReolvXdeDDqRa6sUR3fquaKt+WCPEkJBFOvFllJnAZ0SXzjpN788mNMEVRZGlpiWAwyO3bt69NBxbfb1pZWRlzVjk5OTkTvSTbKr9acVXCVKlUF/pLx8bG2NvbY3l5OdZmdZUI+abaqMfjYbauoih+DUj0hSTVzCXCjSQ6aagGPNDGXYXolEoloVCIlZUVrFbrBcLJBBIRXTLvOGk7KjfHmIowpG1xbm4uer3+oUkune17vJ8cPIhepG2uy+WKbXMf1zzYm1bh1Gq1qNVq2traUCgUsTareOGyRHyp/pavlhzd427ohxtGdMm0cUqlUpZXXDwikQirq6sUFxcnNKvMBM4TneQdV19fHytyxEPajsq10k62dZUKKlKUenR0dOmxcvEwN7MUvSgUCux2O+Xl5WdMNKXqpJybOBPnAzfTQy6+oBbfZhWJRHC5XJycnDAzM0MoFDrjuHy+Av6k5+gyiRtDdMnauCBKdD6fT/Z6x8fHbG1tUVJSQnNzc6ZPNwaJ6ERRZHt7m+3t7aTecem4DCeLrra2ttje3r5QUEkGuTd9prad56uTUvfB9PR0zDZd6j64jmgCbl5El2wthUKRcpSkFO2ZzeaMk+91SImyEd19yLE4h9SauPj1lpeXsdvt1NfXX2lgTLr9scFgMGarnso7Lt1K6vnzD4fDzM7OIoqiLJ+6dHFdguF4W6Xa2tqYbbqUpFer1Td6LGImiU6uPCqRI4vNZmN/f5/FxUUEITokWoqaHub8wuHwtZiX3gR3YXjMRCfX4hzkEZ3P52Nqaoq8vDwGBwc5ODjA7XandU5SxCWXQCTiqaurkyXnSKeSep4Upeb/8vJyqqqqbhwZpIPztuk+n4+Tk5OYu4jRaCQYDOL3+x/qBryJEd1VEV8BB9je3ubk5ISNjY3Yd3YVGyW4vqqry+VKmMJ51HhsRJeOxTmkJrqjoyMWFxfPdBxctYAhl+h2d3exWq00NjbK1qxdta1L+nyJmv8zicfVAqbT6c54oblcLiYmJmLTraRtrsViSSuKfZKI7jxUKhUWi4Xq6mpEMTpKUupwiR8lKUf6c11V19dsRCddxOFwGJ1OJ/spchlpSc3xTqeTwcHBM0//dKduSa8Jh8NJL4xIJMLc3BzBYJCKigpZbT8S0m3rikQiLC8vY7PZZI1UTLaW3C6Oxw1JhKvVaunr6zvTZL+6uhqbdSDHlOBJJrr4KEwQHoySlITL56U/yXKi1xnRveaITtLG7e3tIQgC1dXVsl+biOi8Xi+Tk5MUFRUltEx/WO1dIkjbx7KyMqqrq1ldXb3SZC85kJLRJpOJgYGBR9J+dZOa+iWcb7KXZh3EmxJIuax0Hjrp4CaaZSY7p0TSH7vdzvHxcUy4HP+wyEZ0GYIkGxFFEZVKlbZU5DxpHRwcsLy8THt7e0yFnuo1cpCMiBJ5x6UbNcrdujocDiYnJ9FqtbS0tMheXw62dg+YWlylqbaKptr028QeN+JnHcRv2aQJbfFDcp70iE5upfR8TlR6WOzs7OBwOAgGg+h0upgoPFOf9SZMAINHQHSJLM5VKhVerzetdSTSikQiLCws4PV6U27lrrJ1jbdTl5DMO+4qQ6lTHb+zs8PGxgbd3d3Mzc2ldf7xCAZDLKxtMrWwwtT8CpPzy8wur3HqjBZonhvq4c9/55cunN9Ni+iSIdGWTZJkbGxsIIpi7GcPY0pwU4nuqp/n/MNibGwMhUJxZpSklN97mGLQa0Jecpk27qqRVigU4s6dO5SWltLa2vrQBYzL3if+NZJ3XGFhYULvuKtEdMnmRki5P6kXV87abq+PlY1tvjIyzVenVlnZ2Abgs1/8OoEkkfNX7k7w4r0pnh7IrNHo4yTL872mdrudlZWVWLeGXq8/MwRbLh51z6wcZGo7Ld2bFRUVqNXqM5rHmZkZwuHwGUeWdPR2N2ECGFwj0Un5uERODVchoP39fTweD7du3UrYsJ4IVy1GSK+xWq0sLCzQ1tYW0zIlOj6dbfhlJODz+ZiYmKCkpISamprYcdKxx7ZTtvcP2TmwcmI/ZWJumeWNbZY3ttk7PL6wpk6rwWwyYD05TXo+v/oHf8bf/v5HUp7fqxUqlQq9Xk9bW1vMey++5UpuZfImboGvq9c1XvNYUVWNAvHCKMl4R5Zk53ATJoDBNRKd9JRI9EdVqVSEQiFZ6/zup/4v//TlF8k1GTDqtWzafBQX5FGUb6GoII/i/DzMpsQ5gIeJ6KRK5/lKbqLjHyaic3t9LK+uMzYxRW5+Adsna/zFP32N7f1DtvePWF7fxHb6q3h8/thraivLWN/eS7R8DD5/gP6OFqwnU0mPuzMxy7++dI833h6Q/RleTYgnlkQtV/GVSeDSG/imtpJlqoCQ6PP5gmF06uj6l42SXFpaQqPRXCr29ng8Ge8vvwqudet6WXQgl4BcLhcagnxt9IHd1J9//qsXjtNq1JQWFVBckIdKqcRszMFkNGDKycFxauOl2XVMOYbYz3NNOSgEBWq1Co1ajVqtQq1SoVGpODqxs7K+QWlJCR2dnYQiIn6Xm0gkQjgcIRyJ/hMJh4lERA4OrZw6Tjn1hXB7vLg9PjxeH25v9L/dXh9uj5dgKMThsY3NnT2cbg+nLg8nNgdev//MZ7nd18lLY8nttda39+jvbGF0eiHpcWOzixRYzBzbHUmP+9Xf/7MY0T1pEV0ygjpfmZQ6D6QbWLJMz8/Pz1gvaCYngGW6PzX+vEKRCJddBfGjJCG6Gzk/SlKn08WKj1ch462tLaqrq/8fFyeA5QN/DtQStWj69lQ26vCYBMNyiE5KyH/7O7+ZP/zrf2F5ffvSY/2BIBs7+5QXFyYmiX/5+pn/fXqgmxfvTaY8z6f7u3hxNHlEBNDb2sD4/GrK47pbG5mcX056zNjsIvm5Jk5OnUmPc7lTF3O8Pj/drQ0cj88mPW5yfplPfPqveNdbXn+jZBSPmnDPdx5I3nurq6s4nU5UKlWs++CqesZMmW7C9UpeXL4QFoO8z3h+lKRk/vqLv/iLbG9v86EPfYjnn3+eN77xjbGqbyrczwMmmgD2AeCLoih+RBCEnwJ+CvjJVOtd6xV92ZNLpVJdSnShUIipqSmOj48ZHh7GbDbzne94i6z3O7Ynz0dJWFzdQCXjKTO3so5GnfpZsGc9kWe7JOMYnz9Aa2NtyuMW1zbpbm1Medz47BJ55tRVr0/+zb9gtVrZ2tpic3OTzc1N3G73qz66e5gtp2RK0NXVRWNjIyaTCY/Hw/T0NCMjIywvL3NycpJWeuTVYJbpCYTQqK62JZaq4E8//TT/+I//SEVFBR/4wAeYn5/nc59L6Xgew33SHIXoBDBAmgD2TuCT9w/7JPAuOes9lkf3+cqmBKfTyZ07d8jPz6e7uztW3Xnv259HJeOLX1zboqm2KuVxVtspvR1NKY+znTrpbU/tfHJgtdHblpp0JuaXKS9KXNSIx9zSOnpt6qepnNygPxCkraku5XFLGzvMrO9TV1dHaWkpKpWK1dVV7t69y9zcHIeHh2lrHx8WNy35r9frqauro7+/n97eXiwWC1arldHRUcbHx2Nbt2QPh5tajIiH0xfCoHn43J/0WZ955hl+/ud/ng984ANXWkc4OwGsJM5GfZ/o1jYlHgvRnf9Di/dHDk5PT9Pd3U1FxdnRjSWF+bz56SFZaxfmyavI+v3yblqHU54pQESmE7DlksJJPGwOeQQ7vbhKm4zob2J2CYuMqO7X/+jThMNREWp5eTldXV0MDg5SXl6Oy+VicnKSe/fusbq6yunp6ZWcYR41rqtaKglwm5ubGRoaorW1FZVKxfr6Onfu3GF2dpa9vT3853KwNzGiiydmq8tPfk5mHKp9Pt9DFyKEcxPA4n8nRk9c1pbj2osRqRAKhZienkalUiW1HXrfu76Rz3/l5ZTrTS+totdq8PoDyY9bXKU438LhiT3pcfOrGzTVVrKUJEcI0TxXTXkpG7v7SY9b2d7HbMzB4UpOoBs7+ygUApFI8r+jTkauyO318XR7Fy/eS55vXN3a5XNfepm3f8Ot2M/ihzvDxWE5er2egoKCM+1XT1pBA1ITZiJTguPj4wumBAqF4sZFdNI6oijiDYYpNGbGruk6JoABB8L94TiCIJQBh3LWeqxZ59PTU+7cuUNxcTGdnZ1JqzNvefaWrFyT0+Whuy31tlQURRpkbHMB8i2po0RRFCkvST6nFaJbycbq8pTH7R5aGehoTXnc2OwiDTWph5dPzi2Ta0r9/f3hX/w9weDl0h8pYd/W1sbQ0BD19fWEQiHm5+e5e/cuS0tLOByOGxPtPQ5ZiGRKUFtbS19fH/39/eTn58fa1KSuDafT+VAPhExVcCUN3fqxh6o8+SLqVHgYd+H738uFCWDA3wHvv//f7wf+Vs56j4XoJDHx7OwsPT09lJenvvFVKiXf9Ky87avT5ZF13PyyvGLDxNzSpVq9eEzOL2PKSX2hrG3vo5ahLrc7XSmPAdBrUk/fcnm8dDTVpjxu7+iYv/7C12S9r6RLq66upre3N3ZDOxwODg8PZeetLkMmosKbIPSVTAmamppoaWmhoKAAjUbD1tYWd+7cYXp6mt3d3bQctKVzylRE5w+DVpVZOniY9q+vf/3rEJ0A9kZBEMbv//PNwEeA5wVBWALefP//U+KRE500ki8SiTA4OJgW43/LG27LOm52eY3ayrKUx9kcTnraUufCfP4AnU31KY9ze310tqQ+zuZw0teZ+n2X1reoq0yda51d3qCqLPVxkwsrmI2pv+8/+et/wuvzpzzuPKQburKyMtamF5+3mpub4+Dg4JEXNTKBTBKmSqWirKyM9vZ2hoeHY47LUlS8uLiI1WpNKarPpB7vyAvllswKex9m6/rss88iiqIgimK3KIq99//5B1EUj0VRfJMoik2iKL5ZFMUTOes90hyd3W5nZmaGxsZGwuFw2k/s+upyetsaGZ9LrkUDKC8uTNk9AOCRaS6wtXeQ+iBgc2cPgdQZ0uMUrVkS5EhSIqJIRUlhynN0ub2XCpIFQaCxpgKz0cCp080f/vnf8R/e/x5Z53gZzuetpC6E7e1ovjN+/kGiyORxR2LXsc75LfB5U4LzcyKk3l3pe7oOY4G9Uy8FOU/uvAh4RIJhURRZX1/n8PAwNsxld3eXUCiUlvBSqVTy7rc8J4vo5u5vSwNJ8k0AM0tr1FWVsbaVnBS39g7paWtkIsV77xxY6W5pYHIhuYB4ZXOHzpYGphdWkh+3tU9DTQUrGztJjxudWSDfYuLEnlxoPL24itlowOHykG8x01BdgYjI6uYuS3Hv8Vuf/Eve89Y3UlacOu8oB4IgxIoadXV1F+Yf6PX6WBdCJluGbiLRpRoZEN9uFQgEYsWf+fl5DAbDmd9nAvunPoozVGmNx02xaIJHsHUNBAKMjo4SCAQYGhqKOUZctQ/1+acHyNGnNle0OZzUVcjzqi8tkqfWlp0PkXlDqGW2xuTnmlMeEwiGqCopSnpMjkFPXVUZT/d30Vhbycmpk7tT84xMLVzoxPB4ffyX3/3kJSs9PKSiRmtra6yoEYlEWFxc5M6dOywuLhIKhdK+Rs4jU9XfTBJmOnk1jUZDSUkJbW1tDA8Pn/me3G43CwsLD6VxnNyxU5evfaLdheGaic7pdHL37l2qq6tpaWk582Um6464DCqVCp1Wwzuff07W8WqZ0eLM4qosge7E3DJlMkhxcn6ZGhkkOz63RHVF6tza2MwiJTKExvNrW2d0ehazkf6OFp7u76K5vgqv38fkwgpfuTsuq9DxV//0Ze5OXt0PTy6kokZVVRU9PT0MDAxQWFhIKBRidHSUsbGx2ACYqxDXTWrGf5h1zn9PBoOB4uLiCxpHu90uq+p96g3gCUTQKHiih1fDNROdXq9nYGAg1vwbj4dxFnnfO79R1vEzS2uUFCR2H46Hw+WWJUmJRCLUVaUuckA0R5gKoihSUZw8CgMIhcMU5qa+YHKNOQx0tnC7v5P66nLsThejswu8ODbF4tpWTJPn8flpqEpd6Qb4uY/94SPXxEnbN61Wy9DQEO3t7ajV6jNi3P39fQKB5FpJuHlb10yvk5eXR319PQMDA3R3d2M0Gtnf32dkZITJyUm2t7fxeDwJ/4ZfWbLyVF3+tXVY3CSiu9YcXTJ/L6VSKduqSYJKpcLj8fBUXyeNtZVJG/1B0rYVcnCc0twAu0OelGN+dUNW7m9ifglTjgGnO7nUZXwu2rWQ6v3Xdg7PCI0L8y1UlxWj12lxub1s7O5zeGLnpfEZ9DptSseSkel56irLWEtRsJmcX+Ezn/siL3zLm5MeF49MC4a1Wu2ZoobT6eT4+JipqSlEUSQvL4+CgoKERY2bRlDXGRmeNyWQvPdWVlbwer0x1+D8/HzubTtpKIxG/9c5L+I1kaN72Dmt5xHfIyu30X99Zx+ljAtrYXVDVp/sid1BswyBrsfro0uG1MTr89ORpBdVEKCsuICW+mqeGexmoLOFksI8rCd2RmcW+fq9KSbml2NE6fH6aamrSfm+4XAEs1GeOPRX/senUhL2dSDR9SOZQtbV1TEwMEBvby8mk+lMFLOzsxOz6r+JRPeoCNNgMMRMCaRWPo/Hw52xSf51ZAat14rNZiMUCl1bju4mmG7CY5zretWZq9Jr3vv25/mv//2ThFKsYTt10tlcx/TiWsr1Cyy5LLGV8jhvQF7id2N3X1Z0s7i2hVqlIi/XRFlRAQa9DofTgcfrZ/fohL3DY/YOj7GYjYTC4ZQWTfem5yktKmD/6DjpcRPzy3Q1NzC1mLxCfHRi52N//Of8/A9/d9LjHgdUKlUsipEchONnm6rV6pg3WjoW4OfxuIoRlyHdyDC+le9fdwQ++HwryqCHo6MjDg8P0Wg0hEIh8vPzycnJychnvSkTwOAxEp1KpbrQ8JwK8USnUQr0tzVwZ3ox5evktiNNLSyTY9Dj9iQnkpXNXZpqq1haT06KO/tH9Hc0MzqzBESjkcK8XEwGHUWFBaiUCoLBEKcuN8111Xz93iSHSbbZdoeLpwdS96z6A0FqyktTEh2Ax+eTRcZ/9Bef433vfAsN1amj2ceFeAfhqqoqIpEIKysruFwuxsbGUKlUsa3beSfcVHg1bF3lYGTjBLNeRaklB8ihqKgItVqNRqNBEATW19djBCV9V1f13rtJ8pLH1tR/1YguFAqxtrbG4eEhH/63/4Y7P/UrKV83v7JJSVE+B0fJRdRur4+n+jp4eWwm5ZoFFjNL535mMhoosORiyjGg12lRqVQY9Dr6O5o5OXWyf3TM0YmdoxNY3T7b/O8p96MQhJQuKNMLq7JyfyNTc9RUlLGxkzwHt7K5w1BXG3en5pMeFwyF+M+/9Qn+16//fNLjbhIUCgUGgyG2hfP7/ZycnMTa0uJzVqlu5pu4BU6X6HzBMJ+fOeA/veXs+MxwOBzTMcbnQaXhOKFQKGYxb7FYZOfz3G53dut6FaKLRCLYbDZ0Oh1DQ0NEIiLFBf8jaRQE0c6BxurKlEQHxIbJ6HVaTDkGVEoFBp0Os8mISqVCpVTcl8kJPD3Yjd3u5Oj4BJfHh9Plxem6GA0211en7NLY2j2gvb6a2dXNpMc5XG5ZzsfhcITCvNyURAewubuPVqPGn2JL/sUX7/HFl+7xpkc0XyLT1V6tVnvGCVe6maenp4lEIrEOhEQDXx53JJaJdT7xtXVe31SERpX8s8UPx6mtrSUcDmO322Nuy3Ij49fU1vWybVG6OrrT01Omp6fRaDS0tbUBoFDA97/v3Untm0LBIMH7ydanejvuz30IEwpHovNmwxGCoRDBYJBAMMTRiZ36yhJWtw9S9ns+M9DN7PJ6ynM3yRyr55GZ+5taXJFl9XRvap7m+moW15KT58Gxjad6O3g5heU6wH/+zU/w3FCPLFOCm4DLcmLnb+ZQKHRmXoROp4vdzAaD4VVZjIjH1M4pdm+I1zVdlD2lqrpKPcwFBdEumfORcfw2N36Q1FWLER/84Af53Oc+x9HR0bQoip0AgiD8AvC9wNH9w35GFMV/kLvmY43o5MhLJFPOnZ0denp6mJo6G8m8482v45c+/j9l5eEGOlu5N518iwZQkp+6EwFgYW1TltRkbHaR6ooSNneS96Kub+8x0NXKvRTbSKfLIytXB6BSyLupJuaSy2FyDHo6Gmtxe718/FP/lx/77u+4dK1M9WM+yq2iSqWKDXwRRTE2L2JpaQm/3x+LanQ63UMXNR51RBcMR/ijr63xH96Q2AU7XdI8Hxm7XC5sNltsJrFarWZxcZFAIBDzKEwHH/jAB/ihH/ohBgYu7Bw+Jorir6W9II/Rj07O1jUUCjE5OYnD4WB4eBij0XghOqytLJM9qi/ZMOd4LG/tUSqjE8F6YqevI7ULSSQSkdVRAXAqU88n119udnmDzmYZMhd/gNb6s/IahSDQ1lDDQGcL4XCYO5NzzCyt85v/8y+YX9lIut5NMd68aieFwWCgsrKSnp6e2MhLl8vF+Pg4o6OjrK+vX8lP7nFsXf/wK6u0lZppKE58vTyMjk7y3ou36jIajXz1q19le3ubN7/5zfzyL/8yMzOp894SnnvuuYz28sIjILqrDMiBaNh7584dCgsLU5pyfvA9b5d1LlMLK9TJ6AiIRERZxwEcWGW5xDA2s0CxjC6N5Y1t+mTYqLs8XjqaU8+CAAgG5aUIxmaXqCgporw4n9t9HeTnmplb2eDe9AK+OMfmQDDEj/7ybz90H+qjwsNGhgqFArVaTU1NDYODg3R0dKDVatnc3OTOnTvMzMywt7f3SDs15BLd3J6DqV0nLwxfrhHNZGeEUqmksbGR3/7t36a8vJzPfOYz1NfXs7KS3LxCJn5IEIRJQRD+WBCE1DdTHG5kRLe7u8vk5CRdXV0X5kckwvPPDsvyYwMoLZT3pJhZXMMgwzxgfXtPloA4EAxRL8NZGDgzrDoZJmaXyDOnzoEsrG4w0NmS9Jjy4kKGutuoKiti9/CEl8ZmsCaZqjYxt8xH/+B/pd3d8qhxHdVSaevW0dHB8PAw1dXV+P3+M9PBbDZbwnRKpkhFThTm9of46D8v8Xx7Mbn6y7uUrqszQhRFSkpKeOGFF3jHO97xsMv9HtAA9AJ7wK+n8+LHRnSJJoGFw2Gmp6c5PDxkeHhYdiJToVDw/n/zzbKOnZhflmU+6XC56ZExThAgLFOnNz67JMuBeGF1Q9YoQ7fXR5sM12CAY5vjwg1fXlzI7b5OGmsq2T085qWxGV4en6W9oVrWmr/36b/js5//F8bGxh7KSfgy3DSH4cuKGpJtujQdLDc3l8PDQ0ZGRpiYmIj1m8KjLUb87pdWKTRqeGdP8gfsdfS6ZnJQN4AoigeiKIZFUYwAfwgMp/P6x7Z1Pf9zj8fDnTt3MJvN9PT0JE34JroB/t23fhOaJL21sffx+mTlrAC2D45SHwSsbO3SKENI6/MH6GptkLWm3G3h+OwSBZbUxZP17T2GulofkFvtA3JbPud1t3d0gtGQ2hMuEAzxib/9f2echO/evcvGxgZer/dGRHuPuloqFTVaWloYHh6mqSlqFrG8vMydO3dwOp2xtqvrPJ+/m9hjds/Bt/WXo5RRkMq0oafX641ZsmUC9wfhSPhWIMGk+stxI0ayHxwcMDY2Rnt7O9XV1Um/9MvkKoV5Ft7x5mdlvd/GfRfgVNjaPaCvPbWrCYDZJO+POidzTsXM0lrSHlgJHq+PqtLLHVAEQaClvpqnB7rwB4LYHK4oua1fbuRpc7hkvTfAvekFPvnX/0R5eTmdnZ0MDg5SUFAQs8x/mMT9dbjpXhVXJUypqNHd3c3g4CBqtRq3233mu3E4HBktaiwfuvj7yV3ay8wM12XGODVdPExXxAsvvMDt27cBWgRB2BYE4XuA/yYIwpQgCJPAG4AfS2fNxyqGEkWR+fl5PB4Pw8PDSd1OJEhFjER/5O/+trfzl//4/1KusXNgpbu1kcn51E7FobC8benk/Iqs/lLbqZOOhmpmVpJr20C+R9jc6iYFebkc26I5NaNBT0t9DSqVgpXNHRbWNuF+q69cvdzdqXla6qpYWEvd+/urf/BnPP/sEA3VFSgUCoxGI2azmZaWFgKBAMfHx7GtrdlspqCggLy8PFl/74fFTepoUCgUqFQq6urqUKlUBAKBmLW80+m8VI+WCJFIJOH14Q2G+Z1/XUavUfHvbstLQVwHHoboPv3pT0v/GX+BfOJhzueRCIYTwefz4fF4KCsro6WlRfZFJOX2Et0kT/V10tFUx8xS6gZ+ue83tbBCfVUFq1vJrcxD4TD1VWWy+kv3j20olQrCKUh0cn6ZhqoyVlLYvPsDQZ4ZaOTU6cTl9rK6vce9mcRavNGZRSpLi9jeT74tj0QihMJhlApFyhykzx/gx375d/ib3/uvF+aWajSaM5orh8PB8fExW1tRApVmwppMpmuJ4G4S0cHZSEyj0VBaWkppaWlMj3ZycsLs7CzhcDg2C9Ziscju1PjVzy8SCIs815xPqTl9DVum8DCjDq8Dj2XrarVauXfvHnq9npqamrQuoFT6u++WKTWZnF+mqlxepbaowCJ7TaMh9cV1bHemrIJK0F3ifGwxRU02b/V2UFKUz9dGJtg9sLKwvkUwSf4nEAxSmJd6Ti1EzQuGuttkHXt3co5P/J+/T3qMNDdCMors6upCp9PFxv5Jhpo3cUrYdROmVNSoqamhr6+P3t5eLBYLVqs1VtTY2tqKmWgmIrrPTu6xbfdgMaj4N32Vss/nOnCT2r/gEW9dRVFkeXkZu93O4OAgU1NTaZe2UxHde775TfzCb30CV4qmd1EUqSwtZms39XSvidkl8nNNF+YqnIfL46W7uY7JxfWUax7JnAI2s7xBbUUJNoeLxppKIuEwe0dW9q127k0vnDm2uCCPPRm6vvG5JXpam5iQsXWfmF+WtSUH+NsvfJU33u6nyGKSdQOdj2gkQ83JyUkg2mrkcDgeKtrLFEHBo+34UKlUFBYWUlgYFZpLnRrLy8v4fL7Y2ESz2YxKpWLN6uaPvrpGaa6Od3SXX+hnvQyZ/H7icZPmRcAjrLr6/X7u3bsHEFOaX8VlOBXRGQ16vv2b3yRrran5qC1TKvgCAVoba2WtuX9sRyWDuNe2dpMKg8uKCxjubqO/vYnigjwcLg/3phcYm1tm32pP+JqJ+RUaZWr1rDa7rKKI1+dPqj1UKhUMdLbQWFvJvelF/v1P/+qVZsKeN9Ts6upCoVCwvb0dE+XKtU+Px3XdyI8aer2eioqKWFFDp9Ph9XoZHx/n5bv3+A//+x4lRhX1RTncbpBfgLhOG/XX3NbVZrMxMjJCTU0NTU1NsQvvYc03L8P73/1WWWu5PF66W+TJPZbum2OmwuGxjX6Z21L//ZtWo1bR2lDD0/1dDHS1UpSfx97hMXcm5xidXeLO5Dw1ZalnSwCEQvK+z52DI9nb5/G5JfrPtbrpdVqe6u2gpCCfe9OLsSru/Oom//m3/0TWusmgVqtRq9WxIc/V1dX4fL6YKHd1dZXT09OUPc43pRUtk5A6NaqqqhgcHOSf9nTkaJV4fD7a1cdMT0+zt7cny+/xusTCNy2iu/atq91uZ3Fxkf7+/gvzOq8yCSwV0blcLhzHBwx0tlzY2iXC7qFV1vsendgZ7mnnzkTqiuVJko4CtUpFSYGFspIi1Col33CrjxdHp1L2jqaqwklY3zlguFfeeY7PLcny6YPoXFujQY9Go6alrorZ5c1Lq7d/+8WvU18RHWV4VcQTlJS/koS5oVCIk5MTdnd3cTgc5OTkxIoaib6nJyGiOw8pEvu7iV3+ceaAuqIc3thewdtv1+B2uzk+PmZ2djbmJSfZT50nteucF/GaIrrc3FyGhoYShseZ3rru7e2xtrZGV1cX3/++AP/+p1Obcm7s7MuWmthS5OgkLG9s09XayNrmLtUVpeSajEQiEY5tp2zs7LN9YGX7IEqwHU11Kd1PABbWtujvaGF0JjV5r2/voddq8PqTb/O8Pj/tjbWyiM6Uo6evvZkvvzLOS2OpSfTj//uzfOMbnpHdXZIIyfqk4+3T42/scDh85sZ+Urau5xGJRLi7ecpvfnGFzopczHo1LwxVIQgCRqMRo9FITU0N4XAYm82G1WpleXkZrVZ7xn7qOreuUn7xJuDaiU6hUFz6RWZq6yoN9PV4PAwNDaFWq3n7G5+lpDBfVtO9nJwawNL6Fm2Ntcyd86CzmI0U5uVSmJeHQiHg9fnRajS4PF5mU0hdZpbW6G1rYnzuvF/xRZycOlAohNjYwstwaLXxzEAXX09hzglRwW9nc33CmRoqpZLu1kZ8fj+zy+usbu3R197E2Gzqh0IwFOJ7f+a/8c9/8htYzNf3ZD9/Y0u+cgcHBywtLcVmRWi12itZBmUamdpKb9gD/PXqDmadEpc/xHcMVqFXX7yOlUplwqLG6uoqXq8XnU5HJBKJ2StlCjctR/dYBcNXJbp4+YHf72diYoLCwsIzejy1WsX73vmN/MYnPn3ZUjGMzy1RXlLI7sHl21iL2UiBxUyOVs1gVytKpZJTp5u9w2PsDhd2h5vljd0zr2lvrJVlzOnx+VIeA9FI7VZvB6+Mp7a8GZ1ZpCg/j6OT1KMenW4PKqUyNmgo15hDe1MtKxs7FyLIte09ivMtHJ7YU667tXfID///fpM//bWffWRR1XlfuampKSKRCHNzc7FtXEFBQUIX4VcLDp1+/teUmx13hDyDhoaiHJ5vL5b1WqmoUVFRQSQSYWdnh4ODAyYmJhAEIRbtmc3mh/qb3SQbdXjMRKdSqa60dfXdJwabzcbs7Cytra0x99N4fODffDO/9Sd/nlKYq1QoaK6rxmzMiTbdiyLBYBBBocTucHJwbLtPZi4EQaC6PPUsBunzycHi2hb9nS2Mysgprm3votNqztgmJYLX56e7tVEW0W3s7HO7t5MTh5McvZbJ+RVeumRuht3horO5niPbqazo5AsvjvDbn/xLfuQD70l5bDwyseUUBAG1Wk1paSkmkym2jYt3EZZye+fzx9eBTHwmTyDEj/75JIfuEB3leYTCIh98pvZKa0kzNfLy8mhoaCAQCGCz2djZ2WF+fp6cnBzy8/MpKCiQnSOWcJOGV8Nj7IyAKGldZRJYKBRiY2ODvb29hEUOCRWlxbz37c8zOj1HjsGAVqOJhunhEF6vH5fbi83pxOF0c296PqpOTzFKUBRFSovyZBHd5Pyy7Kju+MSOAKSijkOrTba78J2J2ZTTysxGA20NtbHvYSHFzAqA6cVVbvd1XkqG5/HRP/o0A50tPDvYLev4TCKeXOK3cZKL8PHxMQsLCwSDQSwWCwUFBQk7ETJ9LldBOCLyE385jUaloCRHwb7dx+tbCmkoujqhxBcjNBoNJSUllJSUxHKfUqdGKBQ606mR0iIqu3V9gKtsXSFqAlBQUMDw8HDKC/Lb3/Ym/uxv/ynlmk6Xh2f6u/n66GTKY+9NzVNeXMDuYWoRrdyobmP3gMGuVkZS2KhDtC0t12Tk1JncjVgURTQJ3l+hUNDRWItSoWBmeZ1XJuYAaK6tYE+eYQsjU/M011axmGLkI0QH9fzWJ/+SmopSqsrkbbEyhWSdCNKEsKqqqphVenzSXpqTkKlo72GJ7iOfX2Tb5sWsU+IMRKgo0vGh5+Q58VyGy6qu8bnP6urq2PdzfHzM6uoqarU6Fu0ZDIYLn+umbV0fSZLiqi7D5+F2u5mfn0en09HR0SHrqfvsYA8tdZe7q8ZjaUOeVi4UDlNTUZbyOIhGdW0NNbKOPTi2oZBhqeN0eWS7i8wsrdF537OurKiAp3o7KC7IY2pxjfH5FYJxurvF9R06G+U1ggdDITw+LwZ98i1NQ3UFXS0NfP3eFC/86C9glZHbg0evf5MGwDQ3N5+xV1pcXOTOnTv4fD6Oj48fylX5YSqcf/rSJn8xsk2eQY1apSBXq+BdPWUYtQ8Xq8g9p/jvZ2hoiNbWaJ56dXWVO3fuMDc3x+HhYSx/flV5yQc/+EGKi4vp7OyM/UwQhHxBEP5FEISl+/9Oy10YHrNNUzoR3cHBAePj4zQ1NaVdPXvft8jrlEhH7Ds6M09hvryeUbkDgLd2Dxjubpd17L3peUqLUivgDTothfl59LU3s3d0wsvjs+wnkZOsbO1TLPNzbe8fXUq4hRYzQ12trG7tMr24CsDq1h7v+/FfSjmTVsLjbMaPnxnR39+PSqXi5OSE0dFRxsfHz/SdysVVie4Lc4f82r8sMVhjwemLEolRLfDNXfIettdxTjqdjoqKCrq6uhgaGqK8vByXy8XXvvY1nn766Vj+PN0c/Ac+8AE+//nPn//xTwFfFEWxCfji/f9PC4+d6FJ9EaIosri4yPb2NsPDw5jN5rSfqm95doiSQnkPga3d/dQHEXUMaa6TF/1MzC3RKjOq29g9kBVV+gNBqi8xJdCoVTTXVNDX3kREhC+9Mo5eZjLZ6w9g0Gllk8PdyTkGux48HHKNOQx3tXLq8jCSoLgytbDKd//kr6ScIZspZMpeSa1W09TUxNDQEC0tLSgUCpaXl7l79y4LCwtYrdaU1+VVzuWrS1Z+7m9nqbDocPlD5OVo0KmUvK0hM1KZTAiGFQpFzKzhDW94A3/zN39DMBjkT//0T+nv7+fXfk3+4K5LBuO8E/jk/f/+JPCutM8x3RdcBZf9cVNFdIFAgJGRERQKBf39/ajV6it1U2g1Gl54m7yobvfwmN42eWabE7OLsiZxAehkRnV7h1YGuuR1FIxMzVN/f4iPUqmgs7metvoqVColi5u7jM0t47vfZnZnci52bCqs7x5yq0deZAkwv7JOZVkRT/V1gCBwd3ohJlVJhBdHp/mB//zrSf+Omdq6Xocd+/m+0+LiYux2O6OjozFbebfbfeG9042ePj+zz+/8v1U8/jBV+XqkUxiqzaPclJluhusQDBcXF6NUKvnEJz7BxMQEH/7whx92yRJRFKXq3z4gz3YoDo81oktGWna7nbt371JbW0tjY2PsQks0ayIVFAoF3/r8s7Ia+IEYOaSC2+ujU+YkrvG5JWor5P19Vja2L7VnOo/ayjKe7u/CkmtmemmNubVtPL6L5x8Kh1GplLIjirHZRWoqSlMep1Ipaagqx6jTMDazmHKotoR//PIr/OR/+x9Jj7kpriPJyEChUJCXl0djYyNDQ0O0tbWhUqlYXV3l7t27zM/Pc3R0RCgUSiui+9uJPf58ZIfZPSfDdXlMbNkx6VTk6dV8x6A8CyY5uI4WsPjPKbXvZXBtkdTihAu4cVtXURTZ3Nxkbm6Ovr4+ioqKLrzmKiJjg07Lv33nN8o6fn5lg1qZXnXTi6uypoVBtBFeDo5O7PR3JM4VajVq+tqbeKq3g3yLiX99+R4enz/mLpwMi2tbPNXbIesc/IEgWo0a5WVdLQoFg/cNCCYW15hf36Fd5qAeCf/7s1/gv/7ep9J6TbrIxNY1nTV0Oh3l5eV0dXUxODhIaWkpDoeD8fFxZmdn8Xg8KYcI/Z97O/zul1eZ3HZQladjaueU/uo8IiK8tasUvVqRsYfAZU7FD4sMt94dSDMj7v/7MN0FHuvWVaFQnHGfkKaAnZ6eMjw8nHC4xlW+PIkcP/yd34pSKe8jq1Xy/vinThc9MgfezK1s0lwvL683t7IeI1CDXstQdxuDXa2o1CrG5pZ4eWIG631y297bR6uR174zMb9Mucxh2otrW9zqPbuFVSgUDHW3UV5SxMj0AntxPnVjs0vc6pVn1Cnh45/6K37/03+b1mvSwaMmungoFAosFgsNDQ0MDg5SV1eHUqlkfX39TKUy/mH/v17Z4r/8wzw6lZJcnQqDRkmZRceOzUNVnp43tRZndLt52ViCG7bm3wHvv//f7wfSvmAea0QXf/FIU8AsFkvKgdXpQiLUmopS3vaGZ2S9Znlrl9pKeVWtpfVt2cSYI7NibNDreP2tPrpaG/AHgtydmmNkeh6356Kg2Wp3yLZc8nh9sh2TAe5OztNQXY4gCAx2tVJVVsLdqXm29hM/VF8en6WnRd52HqC6vIS/+Mcv85t/8pdnfp7JHN3jIrrzUKlUGI1GOjs7z1QqpUE5v/a5MT7yT4v0VVk4cQdoLDGydOBCp1JSXZDDdz9dC2Q2CruOHJ3H43nowTgLCwvEDcb5CPC8IAhLwJvv/39aeKyCYQlHR0csLi7S2dlJbq48aUM6iN/ufuDdb+XvvvDVlK8RRSgpzGd9O3UHhNVmp72hmtmV1OLZsdlF6ivLWD23rkGvo6W+Gp1Wy/buAVv7h9hOneQYdLLmxt6bnqeqrJitvdRR/cT8Mq21FcwnmQQmIRyJUF1WilKpTFhFTYTp5XXaGmqYS2I9pVYp6WiqZXppk1D4iLmVDTZ29vjoT/4AqvsPjZviOnId8yKkSqVUrfztLy7xJ6OblBuVzO/YqchVcW/9hIHqXHwhkY5yMzUF0R1OOBzO2HdzHTm6DA3GAYhPRsqrJl6Cx7p1FUURv9/P+vo6Q0ND10Jy8CCi29vbQx3xy45+xmYWKC6QJ0s5uD/wRg4kkW1jTSVPD3TR2VxPMBhibGaRl0anYtGSx+ujVqYw2R8IkpcrX6C5c3iSdJi2Rq3iVm87FcVF/L9XxrCY5SeUQ+EIu4dWKksTd0G0N9ZSWlzE+Pzamersn//Dl3jX9/0U45NT2Gy2GzPA+jrnRfhDYX7zi8v8wdc30SgF9Dot5fk5hAQVlblqpndOEQMe3lAuxsYiZjIKu46I7qa1f8Fj3LoGAgFGR0cRRZGBgQHZoloJ6dwECoUCm83G/v4+w8PD/ND75TWYB4IhGmvlVbiO7U76k1ijA9RUlHK7rxOVSkVnUy3LG9u8eG+K6cXVSwfajEzNU51kbms8JudXGJRJ4k6Pl6aai0O39Tott/s6sJhNvDI+FyPdOxNzPNUrX3Jid7oQBDCbHlzwZlMOwz3tzK1uXRp5js6t8hO/9sesrG/icDiYmJhgZ2cHrzd5D/JlyARJZYoMzq+zbfPyE385zadeie4Eeipz0amUmPVqfKEICpWanuo8/v0bWrCYcmK28svLy/j9/rRt5RPhOiK6m+YuDI+J6BwOB3fv3qWyspKcnJy0n9zpVF4DgQCzs1GjyN7eXlQqFW9/wzOy82+Tc8tJI594bO7uxbROCoWChpoKbvd3MtDVSoHFzMbOPi+NTTM+t5zSfURCut/N5t6B7Crw6OwS3feNMXNNOQx0NKFUKnlpbJbDY/uF4+9NLdJaL0/4LJ1LVWkRKqWSgc5W1Co1dybnU36m2ZVNfuRX/4hTb4CmpiYikQgLCwvcvXuX5eVlbDZbSgv1TCKTW1dpnS8tWvl3/3OE5SM3/lCE5qIcAqEIdm+QjWM3tQU5+IJhjDoVb24vo7S0NGYrL1lQnbeVv0oEfB3GpK/ZiC7+i9ze3mZmZobe3l5KSkquZUCOBIfDwcjICJWVlej1+jNavA+98C5Z7+XyeOmSMVdCq1GTb7Hwltfdoq+9GWOOnpWNHV4anebe1DzHdseZ45c3d2W3m23uHdFWJy+yPDy20dMm39U3HA7z7GA3wVCEezPLSd1bgqEQJ/ZTCixm2evbnS5ef6uPsbmlC99BMuwcWPmJX/8TRmeXKS8vp7u7m/7+fiwWC4eHh4yMjDA1NcXu7m5SB5ybtnUVEfjYF5f54c9MUJWvZ8vmxaBWkKtXM7l9ikmnpDrfwNyeA7NOzf/3lrO7BEEQ0Ov15Obm0t/fT09PD0ajkd3dXe7cuRObF5FOtHcdRHfTIrpHVoyINz8cGhqKuXpc14AcyVa9p6cHrVbL9vb2md+/753fyK/+j0+ldAABWFzfQqNWxSzP1SoVtZVlFFjMeDweju1Odo+OmVvZwOPzs7V3kNIFGMB6Ypc1yBrAaneh12llTdi6OzFLXWUpa9uXt7O1NdRg0OsYn11ioLMFj1ee+efhsZ3G6nJsDmfSz6jXaujvaOHezCJffOkeg50tjM0uyyqsSNBqNPzKH36aNz7Vxw+88A5USmXMKkgQhOh3H2ehLrlpxJtG3iSiO3YH+K//usvEnofuCjOjm1F5UFeFmVfW7AzW5BGORPAEw3SU59JbZaHCclHkHr8FVqvVZ2zlXS4Xx8fRATmRSCRmNGo2mx+Z0ehrlui8Xi8jIyOUlZVRXV195qK5KtFdtnWRbNW9Xi/Dw8OoVCoikciF440GPd/17rfyO5/8P0nfS6NWYTEZGehoweF2Yzt1sba1y9L6NonMzzd29nmqt4OXZbgAb+4e3Pd1m0557NGJPXrseOpjQ+FwQl2dWqWit72RU6f7TEX0zuQcw93t3JmcS7k2RKPRtrpK5ta3E/6+v6OFvaNjXozzqxuZXqC/o5mphdUzjimXoaetka0DK2NzK4zNrfDPX7/Hb/zU99NaVxW7XjQaDRUVFVRWVhKJRGIDc+bn5zEajRQUFNyYgsbopp0f++s1jj0hiowa1o49KIBnGvP56tIJFRYdCgHCCJi1KpzeIB98JnGa4LKcYaIhQlJuenFxEYPBcGUjzXRwE7euj4ToVCoVLS0t5OVdrGBe1WU4ETkGAgEmJibIz88/Y6uuUCgSXvAfeuFd/I8/+2uCoRCCIFBeXEhJUT46rRabzY7HH2R7/5DljR08Pj+HVlvSHk4J6zv7ZyLAZFhc2yLHoE+ojzuP0ZkFyosLZU0um1/dvO9vt0Berom2hhqW1re5O5nY7256aZXq8mI2d+WJzufWthnqbuVunH9eSYGFPLOZsdnE8y9GZxbpbWtkbmXz0qZ+tUrJQFcrL587z6nFNd724Z/hx97/bfzQ+951PxIOn3mA5efnU1hYiCAIuFwurFYrXq+X0dHRmLec0WhMm7QehugOHH7++MUN/m5iD6c/hADkGTRsnnjor7Ywue1AQKS+0MDsnpMKi46AKPBjzzehvqSKL7c4ct5W/ryRZl5eHqFQKOOV15sY0T2SWFaj0SQkObhaRJeo31UqcNTU1NDQ0CDrwiwvLuT7/+27aa2vRa/TsXNgZXR6kRfvTTG3usXGzn5sW7l7YGVQZrP9/tExg13yOgSO7aeyc2r+QBBjCv+3eIRC0fybx+vjxdFpjpJ4wXm8PtQqlayh1hKmF9eoryrHoNfxdH8XNoebhUuiPAnjc8s011Um7OWtKCmkqqLsAslJCARD/OoffYa3fd/PsLC+jUajQafTodFoUCqjfbzhcJhQKIRWq6W6uhq9Xk9XVxc6nY7Nzc1LOxKSIb6IIBe+YJjf+/Ia/+b3X+HrK8c4/dH36io1cOTyU5GnxxsIc+oN8VRdPnfWbdQX5aBVK+itsjBQc7ms6SrEJBlpVldX09fXR19fH7m5uYRCoVi+c2dnJzam4GHwmiW6ZLgK0Z03A9jd3Y0VOIqL03OwfeFb3sLi+pasHNXyxjYqmVq5+dUN+dXPafl6vcX1HdqStJHptBqGe9pprqtmfG4Zvz8g2xJpZXNHdoEEwOcPUFVaTGVJMS+NzcjakkLUqqmhuuyMaWdfeyNWh+uCkDoRJhdW+cbv+U/83mc+i9vri9koaTQaNBoNarU6NltEuk4KCwtpa2tjeHiY8vJynE4n4+PjSd1GJIiimBax/MP0Pm//7y/z37+8Rn2hgfXjqP9erUXDsSeIVqXAolczs+ekwqJl/sBJa6kRbyCMVqnguy/ZskrIRASmUqliIw+Hhoaor68nEokwPz8fq26fnJxcqbqdJboEuIrtkhTRSX+Yg4MDhoaGrpQXaK6r4h1velbWsVbbKYPd8iK1E7tDtt2Tzx+gskT+DMxAMHzBibisMI+2+ioUgoI7E3MsrkW1WXen5hmSGYkCvDw2TX9Hcj0gREW/TXVVfPnuBKFI+IxeTg5mltYpL8qn0GKis7WesYW1tDzqutua+bU//SyD7/2P/Nc/+j+xqWQKhSJWyZ+dnY25iQCxaM9gMFBbW0t/fz/t7e1n3EYSecvJ3bpO7Th43x+P8J/+apZ9h5++qlxGt6IFB5NWiUEt4PBHUCsVTO84yDeo0KmVhCMiWpUSo1bJW7tKyc9JrinN1FZT0tAJgkBOTg5VVVX09vbGqttWq5WRkREmJyfZ3t6WrWW8iUT3SHJ0qQbkXCVH5/f7uXfv3oV83FXwE9/7nfztF74qK3G9urWLVqOWdVNOzi+TZzZhc6QefD0+t0xdVTlrW7spj13Z3OFWbweTC8t0NNZyYD1ha9/KntWe8PiFtS2KCywJtXGJ19+mrKjgTMO+hMrSYooL8xidWYz9bHVzl9b6akKhEB6v/GFHkXAYs9HA8Ulq5xUJCoWCp/p7eHkqmgf0+Pz8zv/+HH/wf/6Jd7/5Nt/37W+lNM/IzMwMnZ2dZyyCpKKU9I8UqZWUlFBaGrWkOj095fj4mLW1NTQaTWy63GXXl8sf4vOzh4xu2vn7yQPC96+h2gI9s3sP5DR9VRZeWjtBjIgU5AiYtCqaS3N4ceWE55oK2D/10Vxi4h3dqfWd1yVglnB+FqxU3V5cXMTv98cGhF82JOc1S3QQvVASEclVJoEFAgF2d3fp6Oi4YOOUDJc9mdsaa/nmb7jN3/+/F1OucWi1cbu/k5dGU1c/XR6v7IldEVHEbJQnTG5rqEGlUmAxGxmZXkx5vMPlpjivTDbRnTrdFBfkobAKRO7/zXJNObQ31TEyNc/2wcUJOvOrm3S11LO4tpWyCGPQaaktL2F2LZrP0+u0dDVWM7WcfAKZ2ZhDQ11tjOTi4Q8G+fQ/foXPfP6rDLRU8+Pf/R4M5yL8+GHq0pZM2hlI/280GmMzX6UpYbu7uwQCAYLBIAUFBZjMubyybufvJvf51wUrBTkaTr2BGMmZtEp8wTD+UAQFAk/VW/jq8jEi0FOew85pkKo8PXfWbHSWmxjbtNNbbeF7nq2V9cDOdESXComGCElDsKWHgbQNhsxVXQVBWAecQBgIiaI4eNW1HntTv0qlwuORN0MAovm4vb09ysrK0iI5qd/1sj/sj//7F2QRHUTdSuTMVgUYnVqgpDCPA2vq+aoTc8t0tTQwtbBy4XcVJUVUV5SwuXfA3GpUGtJWV8Uel89/iMfy1h797Y2Mzi7LOn5pfZvbvR2MTC8y2NXC7PJmyvGGUwur9LU3MbWweqlerqWuEqvNGSM5iM6gnVpc51ZPO2NzywQSRPi1FWVElBomFi83CoDow+zIHeFn/+8Yrj+7y2BjKbeay7nVVEZHdVEsxxrfXA8Por1wOBz7R6VSUVZWhkKh4ODUy5ZPzSe/uMKX1tzY/VFSM2oUgIjLL211RWoLDEztOqiw6KjI1XNv8xQRqLWo2TsNoFcrOXb70SjB7gnSXZFLS4mRpmJ5UdB1R3TJIA3JkSJd6WGwvLyM2+3mU5/6FKenp7Kn38nAG0RRTC0zSIHHTnRyixHx+rimpqa0yDH+fS4jup62Jt7y7DD//LU7Kdeynth5ur+LF0dTR2q+QIDeqiZZRAfg9fli0a/ZmENbYy0Ol5u5lXV2Ds9GUnNrW/R3NDM6k1jOcR6zK5tUl5ewuXuQ8lhBEAhFIjzV18FXR1KPgJQwNrvEUHcr96YXz0TwOo2a1oYaJhZWuSxD8MrELI01FXgDQXYOHlzb7Y21rB+c4gukTgG0tbVg15Zxao9eH1+a3uRL09FIMUerpr+hlDf1N2PIyUGnVqJTK9Cr7v9bo0SvVrBn97F85Gb50MWK1cPSgQtfKEJ1vo7lowfXnYBIoQ7W7Q8KWQPVudzbPGWg2sLqkZudUy/+UASTVokYEQEFJWYt41t2+qot7Nl9eIJhPpzG2MJHHdElg16vp7KyksrKSoLBIFarlY985CN853d+J8XFxXz3d383733vex/6XB8WN2LrmipHd14fd3x8jNOZ+qI//z6pKkg/8oH3yCI6gIXVTfRaDV4ZUd3dyTmqyovZkqFR29o75M3PDHJidzC1uMIrE8mjqO39I0w5BlmTtXz+ADqtBqVCkbRDoa2+Gl8wxN2peQw6LU21lSylkI3E4+7kPE/1tsfmxbbUVeNwuRmfX0352uWNHYwGPf3tjYzNrXB7oJdXppdl5U8HBwZY9enxeRKnQtz+IPaAwMe+uosvePHz61QKqvJ0LB2es4MXRTrLjUztnr3m+quipCahNlfF2oGD2lw19zZP6akwMrETfU1HmZnF/VPyc9SMbdp5prGAry4d019j4YNP16JXyyecxxnRJYNareZbvuVb+NjHPsZXv/pVDg8POThI/VBNAhH4Z0EQROD3RVH8g6su9NirrqkiOkkfV1tbG9PHZUp7Fw+n00nY6+Dp/s5Lj4nHsf2Uvkvszs8jHI5QUnBhslEMWk20XWqwqw21SsXo9AJLG6lzXRDtbW1vrJV1HpDYNVhCc20lrfXVzK1tsXZf5iHZtJcUXn7+ifDy+CxP93Vyu6+Tpc0d9mRGtBDNbS6vb/OmZwZZ3NyTRXK9/QPMu7T4gpf/jbuba9gI5CQkObVCoK5Af5HkiEZp50mut9J0huTyDWpK8oz4RCXrpyHai7Qxkmsv0rJ86MIdiOD0hxioyWNu38VAjYV8g4bXN8uvuMPNiugSIRAIxHSMQ0NDD7PUs6Io9gNvBX5QEITnrrrQjSa6eH1cfD4u0/2xBwcHTE1N0dPTw8/8wAdkrxlvd54K96YXqCl/oPHTatS01VfTUluBIES7Hkam5nB5vBzbHbQ3ynfpfWVihq4W+VufOxNzNMcN9a4qLaS9sZbFjR3m1y6ah56cOlAQwSBz5gVAa101u4fHnDocaVfEG2sqMefm8sWXxvB5XTzV2YBOe7lV/Ove+DyLLk2scJIIfa31rHr1+EMXSU4pQGtJDnP7F/ueB6rNjGzaz/ysqTiHmTjiq87TUWnR8cq6HU8gTHWejhVbNNKvyNWy7wpjdQepNEK+VsTr86NWwpbNy099U2opz3nc1Igu0xBFcef+vw+BvwaGr7rWY/+UiVrAUunjrhrRnd+6iqLI8vIyW1tbDA0NYTQaud3fyTMDXbLWtJ06ZWvlRFGkMD+P/s4WBrpaUSgUzK1usrC+k7Co8cr4bFqWSMe2U9nDd0LhMD5/gIaqcppqytk6OGY2iRswwJ7VRl1l6aXDciTodVqevh/Fre/sM7uyRXt9jeyK8q2+DratNnYOo9IWt8fHS+MzmLRKhjvqiedMlVLFs29+K/e2kxsztNWWs+BUEwxfJEIBka5y04WIDaCnwsS9DfuZnxUbNRw7/QTDIo1FOXRVmik265i8/3qdSkFEFPGHInSWG9GrlZx4QnSUGVGrlIQFFWvHXnSEeFOVEp/tIOWwnPO4yRFdpgwQ3G43giCYAARByAHeAqSWOlyCR0Z0cme7BgIB7t27h1qtjvnHpXqNHJx/TSgUYnx8nFAoFJsZK+Envvd9stedXV7DmHP5GMVCi5nBrha6WxuZWlghHA5zb2o+pQuJKIqcOhwoZF40u4dWemW2ktVXlZNnykGjVrC0mboTQcLM8joDXZdHIO0NNeSZzbw0PnvG2WRqcZU8k5HykoJLX6vTaLjV18md6aWEGsXDEzuvTMxSXZRLQ1kBBr2evueeZ/RctHUegx1NbARNJOA4EEX6q3IZ375oH9VcnMPsnvPMXD2dSiBHq6TIpKW93MSy1Y1KITASR4ZtZSZ27D6GavPQq1UsH3kw6ZQYNEo27CFOfSF6a/LR6PT82NujhrPr6+tpDcK+6RFdJsjufm7va4IgTAB3gL8XRfHzV13vsVdd4yMth8PB1NQUzc3NSaUjcgoLyV7j9XoZHx+nurqaioqLLrvPDffS197ImAwpht3hOqOVUyoVtNbXoNdp2N49ZP/YhjXOh+3E7kCtUspql9o7sjHQ2cy9mdRaOYCXx2doa6xlbnk94e+baqswGnRnmu6jjiipnVYk3JmY4+n+Tl4cffCaXJORxuoKRi9p5gfY2D24by5QzdzKWb1cVVkxGp2OOzI0geu7BxTl59Hb04lS9GPRq7F7E4u3h7tamDqBy9ykmvMUZ/JsEiotOvZOvQTO2Wfdqstnz+Fj4SAaQdYVGJiNiwT7q3JZOnLRXmbC4Q2ydP+4/ioLX1+x0lSgxZyjZ2Hfwce+rQOVUkFxcTElJdHRmvFiZbVaHZNxnJ+Gl8mILv4BnwmEQqGMRIn19fWIotiTgVMCbgDRScy/u7vLxsYGvb29KcWGV+mmkIoRJycnzM3N0dHRgcViufT4H/jOb+V7f+6jstbe3jukr72RSCTC2s4BM0trlx67tXd4nyjkReFzK5uUFuWzf5RaLyeKIm6P50LnRmtDDVqNmom5i8R9Z3KWzuZ6phdTV0QlvDg6HbN1GuxqZW17PynJSbCdOvF4fQx1tXB3KjpoZ6CrlcXNPVyXdHWcR0NtNV6FgTuz0e9YqVDQVl+B0ZzPykmAU1/0uniqp5XxI/HSScdD1bncPbctBcjVKQiEQjh8IUxaJfVFOagUAlqVgi8vPZC85OpVeALhWM6vKk+Pyx8iR6Nk0+ZFp1QQEaGvMpdX1o6ptWjJMegJhEW+Y6iK3prCM10aACaTKSZW9vl8MX2az+fDYrFQWFiIxWK50RHdTeyKgEcsL0mESCSCz+eL5ePkCA0vk6okg1Kp5OjoCLfbzcDAALoUYwdff6uXtvpq5lYvqvVz9Dqa66rR67QcWE9Y2dyhKM/MmAz5BESFwUX5eRydpK5Eerw+WuqrZREdRD3upIirs7kOAYGpJCQWDkfY3jugvLiA3cOLLV+XYffwiDc/M8gXXxyV/RqIOrDcnZzn6b4ORKXqUqeSROjr7GD12IvH/yAnF45EmF7eArZQKRW01VdR1dzFUURPkTGE1RXgfOx/GclplVCTqyIQCKIxKdh1hZncdtBTaebF1QffvwIoz9Uztyfl5QRqCvSMrNvwhSJ0V+QyuX1KTb6e5cNTBMBi0hMIRzDrNXz3M9H5rlLkIwmV4wXLSqWS0tJSysrKommM01OsVmuM+Pb29igsLEx5HSfDTZsAdp14rBGdpI8TBIHe3l7Z+/p09/+RSISDgwMikQjDw8Oy/rhKpZLveueb+emP/TEatYqmumosJiMnpw4W1zYZmz27zZpcWKMwz4TVllrf5/b6aG+qk0V0AGMzi/R3tDA6m3rcoCCA/dTB7d52XhqflbW+3eEi32KW5WCsUioZ7mljYm6Zr9wZj26tZWw541FcYGH74AilUkl5UR67R6m/h9vDg4yuJnduDoUj5FU385XtIBDdkqoUAqUmLXkGNXqNCpNOgycQZqA6F38wxKnTg6jSEAiJFJvUsaKChCqTkunds9vbgZo87q5Hz1mvVtBblcvXlqMPiYFqC/c27DQX5xDwe3EGRJ5pKGD5yEWxScv7n6rGoDl7251vTZMmfcXn6sxmMxaLBYVCwcsvv4woiszPzxMMBmMuwlI0KBevlQlg8BiJ7vT0lOnpaZqbm1lakqfsvwokMtVqteTm5sp+gikUCp7qaeVdz7+Of/rKK8yk2NoFQyGK8/NkER1ERcTtTbXMLq3LOn738AiDXnepnZRWo6a3vYn9wxNmV7YoysslR6/FLbPJfnVzN2rUmWR2a0dTHR6v70wr2NjsAj0t9UwsXL5dj8dgdyvza9sc2qPfk0atorO+grn1XcIJSEypUHBreJi7i8kFy4Ig8Lo3v5XRw7O5z1BEZO/Ux96pj4GaPL6ydHxxOyv66K0yM751ltBKTBqc4QjxipQGizJGct3lRnJ0al66H+1V5euZ2XHQXWEm4HOzfhqms9zMxomHmgIDDUVGnm1K3rYoEY9SqUStVscITxRFwuEwwWA0JVFeXk5FRQWiKGKz2Tg8PGRpaQmDwRDL7aWarPdamQAGj6nquru7y+zsbEwfd5Uqqhw4nc6Y2Li0tDStAobkSvxv3/VNsrofINpilY541+8Pyq6q7h+d0NN6sapqMRu53d9FjsHAK+NzbNxv7zqynVJXVS77XCA6WvHpvo4LPy+wmBnuaWN2eZ31nbNzKCIRkcnFVW73JR+FqNdpGe7rYGRmCVecm3IgGGJqaYOqkgIaKkvPvMag09HV25+S5JQKBc88//YLJBePgZo8xracCXN2gzWWCySXo1GgUSuweR7kOqvz9ey6oCZPR32+liOHh5H1KMmpFSCI0F5u4sDuZNUexqBWIAImrQqlIPCD35B6yNJ5xHvtqdVqNjc3Y3k6abtrsVhoampiaGiI2tpaAoHAmQlh0jzY83gtRXSPVEcnDcg5PDw8o4+7DqKLFwEXFRUl1NElg1SlfcPtAV5/q0/261wyWrEkrGzupCn0naWhOlolrior5lZvBz5fkJdGpzlJMGFrenGNp3ovElcyvDw+G5OpCILAU70dBEPhSy3YIVoEeWlsmqf7E79XQ3U5xUUF3Emyxtr2PqtbO9zqakarVlGcn0dRVT0z65cP+IFoRDj85rczfnD5w6ivOo/x7cQkN1Sdy8jG2a2zAqgpyGHz5AEhm7RK1AoFHeUmtu1+Dt0hUKqRmiyaCrTo8DOxZUepUBAIi3RW5LJy6CLfqOFt3WUUGK8+p0EUxdjOp729/YyzMjzw2tNqtVRWVtLb2xubECbNg52dneXg4CAWFb6WcnSPjOgk/zitVktPT8+ZosNViE4QhITElUgEfJX3iCfGn//hD8rOC27uHdLVLL+rYWPnAItJXqgfDkeoLClioLOF7X0rr4zP4ksx1m5kap7WBvnC40gkwsrGDsPdrTTVVvLKxKysPlqAF0enLkR2T/V3sn14Eos0k7+3yMvjs7TVVdLW1sqxI/n7GvQ6er7hbUwdXL4976vOY2rHlVBi0l9l5u7GxfxgX3UuM3FecgJRP7ljd4CRDTthUaS+MIe902gaobvchEajZdEWoaM0h11niO4iFXfWbbQXawkGgry776KMSS5EUWRubg6FQnFhFoparUar1cYiPum6la71goICWltbGR4eprKyEo/Hw+TkJKOjo7jdbrxeb0YGCElwu91nPABvCh7p1rWuro76+voLpHEVl+FExBUvAh4YGDijEUo3oovvje1tb+Jb3yK/ze7w5BRdivyIBLvTRUsKIsrR63iqr4O6qnK+fHcCrUYj++IMhcPYTp3kmeWRqcWUQ1VpIWvbezhcF/s+U+GlsWlu9bRiMZvo62zh5Yk5/EH5zsH9na3Mbx/z1TvjaIIuhhtLKcq9GCEYc3Ko6n0dc4eXW+D3VlmY2nHFfOLi0VVuYmLrooZuoMYSa/kqNmoZqsnjdn0+X1k6xn5/GztUY2FyJ/raIqOaUCTC+I6D5iIDU/tubtfns+1R0FCYw54zzL/t0PPyyy8zPT19JqKSA1EUmZmZQaPR0NTUdOkDV3JWPj9HQ8rthUIh9Ho9NTU19PX10dkZ7ene2dnh7t27zM/Pc3R0lLZs6zxuakT3yIoRWq025lh6Hg8zxFois1Qi4HQjuvOi5J/9wQ/w2S9+TZbQ98B6kpZW7u7kHI01lSxvnM1F1VaWUVpUwNTiCi/HVVDvTMzRWl/NfALpy2Xn09PWiM1xuQBaq9Ew0NnM+PwKs6vRfteivFwsphzszvQIz+Pz01pfzcKGfMcTpUJBf1c7owsPWtHsTjcvjc2gUirpba3HG1awsGOlMD+fku7XsWG7nOR6Ki3M7LkTklxzcQ5LB84Lv+soNzG5bae7IpdwRGRu30m5Rcfd9QeE2FySw9iWHYCyXC1mrZLZfTcmrRKbJ8RgTR7eYJhTT4DyXB1v7ynj+dsNiKKIw+HAarWysbER83UrKirCYDAkJLBIJML09DRGo5H6evkpDrhYyY332wNi5hhtbW0IgoDD4eD4+PjMuUli5XRUDm63O6k+9XHhsQuG4eFbuuSIgFO5l5zH+a2xQaPkG5/u53NfuSvr9eNzyxTmW7AmmbwlIRKJINzPIKmUSnram/D5A8wsrV1I/kM0SnN5vEmrsOcxMbd8KfkOdLawd3h2DitECxpVZcUgithdqbevOo2a3o5WXpmYQxRFivItdDTWMLOcvI/WZNBTXV19huTiEQqHuXffc2+4v5uCxj6O/BE0SoFAgt6uxjwNM3uuhG1f1fk69uxefHGlVKUg0FCcQ45GhVGrZnInum2tKzAwv/egip5vUHPsChCKiAzUWCAc5t529PcNRTmolQqC4QjjW6cM1+Zh8wT5nmejaQxBEMjNzSU3N5eGhgb8fn9MF+f1emOC4Ly8vNhDdmpqitzcXGpra5N+f6mQSL5itVrP7HKMRiNmszl2bsfHx6yursbOraCg4FLr9Hi43W4qKysf6nyvA49dMAwPt3Xd3Nxkd3c3pQg43bax+Env6+vrWK1WfuWnfpgv3fswLnfqISEer4+u5npZRAfRLeyt7hYWNna4l0TiIWF7/4hbPe28MiFPKwdRY8uOprpY50ZTbSVqtTppi9nW3iEVJYWgUGB3XN4831xbhT8YPhN5Hp3YObY7uN3TxitT8wk1cOVFBQgaA/PrqWdlNDU1saeuZGY2GimqlQrqis3kmXIICUp2nSFK84wsHnoSklyhQUkoFKY0V0uL3khEBLs3iDcY5sQdiLV2AeTr1bj9oRghKgQoNms5cPjoLDfj9PhZOopeB72VuaiVAitHbkLhCIM1eYxvnfLJDw5dOptVq9VSUVFBRUUFkUgEm80WIz6tVovP56O4uPihSe48FAoFx8fHrK+v09fXF7v34sXK5+do2O32GPFJ1ukFBQXo9Rd7vF/znRHJcFU3kuXlZVQqFUNDQymfNFd5D1EUmZ6eRqFQ0N/fjyiKfN93fiu/9of/W9br707NU1FcEHPiOA+tRkNXSz3+YJDpxegE+3SqYK9MzNJSW8HC+o6s48PhCEcnNuqryynKz+PO5JysXN/OgZXGmgoioojj3DZWoVDQ0VDD7Op2QjPPSCTCS2MztDfWcuxwnnFabq2vZvvEjddpT3kOPb197CmLcbsfFB6C4QhLe3bYi76+p6GCTbsfnVqBVhlBpVSgUStRCgImrQJfIMiWPYDIgwKOQa2gyKRlN84lWKWAQqOGxcMHxDdQY8EbiF4/2zY3kXAEESg2adCpFLy8dkJnuTkaLbn8fNtABb1VlpSfS/oOJfIIh8OMjo5iMBiw2+288sorFBQUUFhYSG5u7kM3y0ttZX19fTGd3flo7/xg8HixsmSdvri4SCAQuCBWzhTRff7zn+etb33rAqAE/kgUxY88zHqPlOgexmU4HoFAgKOjIwoLC+no6JD1x0+3GBEIBPB4PFRWVsaGggD8wL99N5/8v/+QdBi0hEgkgsmYA+eIrqm2ioI8M7Mr64xMP5Bc2J0u+jqaOU4gFbkM+8ensid85eh1NNZU4fb6GJ9bSqvatryxQ3NdFZFwJKaDqyotxmAwpBxqAzC7vE6uKYf+tkbG5lfoamlgduNQ1jk89fQzzLkNhPyXXyO9jZUsOiAYjjsmGAZfGJNWiValYdN+tgigQKRQJ8bmrkrorsg944rSVW4iEhGZ3nUgANVmJRteEQGRlhIjX106ZqDGgt0dpNCk4dgd5D8+n77PXDgcZnx8PCYGhmiB7fj4mJ2dHebm5jCZTBQWFlJQUJB2Q77VamV1dfUMyZ35PuLEyvCgNU0iP0mOUlZWRnl5+Rmx8uLiIr/7u79LIBB46CHY4XCYH/zBH4So4eY2cFcQhL8TRVH+9uX8Z3uoM8oQ0om2JBFwXl4excXFsp9w6byHy+ViZGQkpkkKh8MIgoBCocBo0PMfv+cFWetAdDpWX3sTebkmbvd1Ul9dwdLGFi+Pz1yIjiDa7jXULX8O66nTldL9V6NWcbuvE61Wy4tj00zML9PRVJd2dLC4tkVlaREGvY6nejuwnrpYSGDUefm5ullY3WCos4UDu0cWyb3uDc8z7dQRCl/+kOprrmLhlIR+c3q1glKT9gKZAfRUWdhwnF23JV95huQ6yo3YPEHu3f9ZS4GKDUf0OrpdH7VDLzNrOXYF0KkVjG/Z+YV3tJOjTS+GCIVCjI2NnSE5iKZ1SkpK6Ojo4KmnnqKqqgq3283Y2BgjIyOsr6/L8rOzWq2srKzQ29ubsmNCwmWDweO3ufFi5R/90R/l9PSUX/zFX+Spp57i4x//eFrfgYQ7d+7Q2NiIKIqroigGgM8A77zSYtJneZgXZwpyc3T7+/sxEbDZbE4rCpR7Ux8dHTE5OUlXVxcKhQKPx4MgCGde/13v/iZZXQc6rYbBrlYMeh2BYJCXxqdZ3Uq9zVxc26Qw3yLrfOH+9K0EXnSCIDDU3UZhQR4vjc9wcvogUhydWeRWT/JuhkSwnToY7GxlcX0nZV/seZQW5mHIMXJ3dgXHqZ1bHfXkXmLIKQgCz73l7YweRS4dpgPQ31LNvE0klCD/p1YI1ObrWTq6+EAZrLZc8LJrKzWxbItehzW5SmrMAjanl217NIKtNitZOgmjVQm8rrGAO2snCEBJro5wJII7EOa9Q9W8vln+dDqAYDDI2NgYVVVVlJVdPtdVKmg0NDQwPDxMV1cXGo2GlZUVXn75Zebm5hL62aWK5OQgkXwlfjB4OByms7MTnU7HX/zFX/DP//zPPPfc1ZzPd3Z2qKqqiv/RNnB1ISKPmOiSmW8mIy1JBLyzsxMTAV/Fky4ZpKLD2toaAwMDGAwG6urqmJub4+7du6ysrOB0OhFFEbVKxU9/379LuI5KqaS3rYmh7jYUCgUjU/N8/d5Uwvaty3DqdFNVmt7NMr20TkXxA2PLjqZa6qvKuTs1z+5B4mlxL4/PyJ6RIXVJuL0BvnJ3Ao1aSUN16mHLsfNprOHUG8R6Gs17+QJBXhqfxe91MdBSTY7+QdeARq3m6be8g3u7yYs+g63VzB6HE5KcUoDWUmNCe/S+qtwLQuEys5Ydm4em4hxaSoxsnIbJM5vYdUavyxwVOAIiFr2S2oIclg9dhCIiQ7X5OH0hSs16yi06PpTGNC94QHI1NTUxXzq50Gq1lJeX09PTw61btygpKeH4+Ji7d+8yNjbG1tYWu7u7rK6uphXJycF5sbJKpWJ7e5vx8fHoBDuzme7u7oy938PixhcjQqEQU1NT6PV6+vv7Y2R5Fe3dZYhEIszORrf/AwMDMfcIqfIUDAZjhohut5v8/HxeN9BBT1sjE3PLKBQK6ipKMObo2dg5ZHzuoknB3cl56irLYkNnUmFsdjHm+SYHwVAItUZDe2MtkYiYUtIh4cXRaXpa6pI25VeUFJFvMcemekG099ag09Lf0ZR03KJaraKlrpqZtcSRrMcX4O70IiaDjo6aEnZsbhqG3sT4TnJ79KG2GiaPQolNNUWR7spcxhIIgttKjUxun/25Qa2gJl+P3Rtk/j4xDtZYzrSG1RaZ8IdCHDr8RPwe9k7DlBlVOH1+QhERlz/E9wzVkZ8jn0wCgQDj4+PU1dWlNaM4ERQKBfn5+eTnR9MYHo+H9fV1Dg4O0Ov1bGxsUFRUlJGCRqL33tnZ4bu+67v43Oc+R02N/E6cRKioqGBr60xKpBKQV3G7BDea6DweDxMTEwlFwEqlEr8/va1TIkjuJkVFRVRXV8cqT/HNzmq1mtLS0pgxwMnJCYeHh7znzbcRwyE29w5Z2UpOYMFQCG2aT9T51Q0K8swc21IXJxprKjHl6FGr1bLJUcL08gbdrQ1Mzp8dnC0ICp7qbWdyfiWhV53H52dsZpGn+zp4cexinri4wIJeb7iU5OLh9Pg4sDspr64naNumxmBkx6ckFLl4Uw631TJ+GLzUVHOw2nJhoA1ATZ6ejRNPLAIsz9VRYdESjsDLaw9IraXUyPjWg9cP1lgQgYUDF10VZsY27SgFKDJpmN5zU5uroNCo46kKjexGeb/fz/j4OI2NjbFh0JmE2+3G5XLxzDPPoFAoODk5YXd3l7m5OYxGI4WFhRQWFmbEYXh3d5f3vve9fPzjH+fWrVsPvd7Q0BBLS0sIglBHlODeC3znw6z5yKuuCU8iQY4ulQg4XQFwIrhcLiYnJ2MXW3zR4TIoFIrYRVJeXs7ff+Uudqe8XtD5lQ2e6uvgZZnW5Q6Xm6aa8qRE11hTgSkn54w/3tP9nRfEv8kQDkf7W5trK1m8P7+1qqwEU47hjC4uEURR5MXRaQY6W5hZ3ogN+mlvqmX70MbRgTwzz8b6WrwqE4s7D47P0WmoLylA1BjY9WnxR2C4vZbxg8tJ7jJTzcIcDd5giEqLHrNOxd6pj227j4pcHaObD0iu0Kjh0OGLkWFTUTSHeG/DTlmulsX9qEB4uC6fl1ZPGK7Nw+UP8WNvqsNqtbK0tIRer49dI1rtxUZ+n8/H+Pg4zc3NsQgskzg6OmJtbY2+vr4YkRUXF1NcXIwoijidTqxWK+Pj49HPfP9cjUZj2tHe/v4+3/Ed38Fv/MZv8Oyzz2bk/FUqFR//+Md529ve9k9E5SV/LIqi/As6AYQU1ZrMdfsS3YYmIicpqpJmQG5ubrK3t0dPT8+lIuDj42OOjo5obZVfoXzxxRe5ffs2giBgtVpZWFigq6uLnJycaHfCuaJDMhweHrK6ukpRaQVv+q4fld2hYMzRY9BrZclBJAz3tHNn4myU1lBdQa4ph9EEYl+FQkFPW+OZ2RBykGc2YczRUVVWyujMYsIhNcnQWFOB0+OjpqKce/MrSU0y49HX3cmaPYjHd7lBgVatZPjWU7gVOSCKhERArcPhi3DijroIR51I7OQZ1Jj1KnI0KrQqBSqlQDgisnjgwuF7kO4YqMqNVVMhqp+rLTCwfL94UZCjpsikY37fiUoBNfkG1qwenm0s4OvLx1Tl67EY1Lyrt4LvGIomz0VRxO12Y7VasVqtiKIYa/UyGo34fD4mJiZobW29llapRCSXDIFAIHauUvtWYWEh+fn5KTWdR0dHvPvd7+ZXfuVXeMtb3pKpjxCPjO2xb9TWVbJxCofDDA4OJv2iH6ZtbGdnh/39/Vjjv6QGl0NyoiiyubmJ1WqNvf4/fs97+S8f/xNZ5+Bye2murUqL6OZXNijKz+Xo5JSG6grMphzGknQzRCIRlta20soJApgMOgxaDSsb22mTHBA9v5pKHC6nbJJ7+tYwYxvHCcXG8bj1zDcwagWI/5tHI2mFALeqc1myelAICk48IU48UUJTKwTqi/Sx3JuEtlIjE+dydd0VZka3otbnA9UW/OEIU/fbwfqqLIxv2emtsrB06EIQRCrz9ARCEb598EHLkyAIGI1GjEYjtbW1BINBrFYr6+vrOBwOgsEgtbW11+LwkS7JAWg0GsrLyykvLycSiXB6esrR0RErKytoNBqKioooLCy80AVxfHzMe97zHn7pl37pukguo7gREZ0oinz961+PfbG1tbUpScfpdLK2tpZWZefu3bvodDpEUaSjowNRFGOj2eSQnDRvFqC1tTW2xQ2GQrzhO3+IxTQ0ZV0t9UlnOZzH64d7cbq9CSO4y1BeUojX58eWpHUL7tsdtTRyd2qOcDhCXq4Jc46Bjb1D2e/V1liL1e7kyBYlj86mOpweP5v7RwmPVygEnr79NHeWUrd+PffGtyQ11ewqMzC1fzGiFhDpqjBfILQKiw6nN3gmuuuvipJcjUWLUqWiIEcTq8y2lZrYOnFTmZeDQaNgdNPOMw0FjG7Z+evvv01NQWq3DrfbHcs3ezweTk5O0Gq1MSJ5mNkPcDWSSwWv14vVauXo6IhgMEh+fj7b29t0dHTw3ve+l5/+6Z/mne98KHlbKmQsorsR8hKXy4XH46Guro66OnlC1nQjumAwiNPpRKPR0NnZmTbJBYNBxsfHMRgMtLW1nS1WqFT8yv/3/bLPBWBn/wi9NnVxorO5nu6WRr58ZyLtYsbugZXy4kJUSSLj/o4WzDkGXh6fIXxflGs7dXJsd9DRlNpXT1AouD3QxeLmbozkAKaX1tg7POR2d9RIMx46nY7BW7dTkpxCIfC6N31TUpLrr7YwnYDkAJrzVRdIzqRTgSieIbn6QgNL+6d0l+WwdepHoxJiGrtcvQpfIESxWY9GGf15XYGB8S07P/QNDbJITsoFd3V1UVlZSXNzM0899RQtLS1EIhFmZmZ45ZVXWF5e5vT0NG1/uMPDw4yTHIBer6eqqor+/n4GBwcxmUx84hOf4NatWyiVShwOB0dHiR9kNw2PNKKTfLHisb+/z+rqKuFwmNe97nWy1/L7/UxNTTE4OJjyWOlpKtnS6PX6tPJxkllhfX09xcXFlx73oZ/5Vf7mX74i+zM81dvByxMXc6wKhUBvWzNuj/dM54FSqaCtoYbpRXnzGST0tTcyNne2olpalE95UWHSPJ5Wo6azuf7Spv9cUw7lpcXMrSaPZCtKCinMz2NycZ2CfAulNc0s7SS/QdQqFUOvfwuTSU01LUxsOxJKTAarzReKEkpBpKHQwOLhg+KRRa+iwhBhxyNg94ai8hBR5OS+99yt2jy2bV68gTARUUSvUaBVKTHpVHz6e59CqUi985ienqarqytpD6jU6mW1WnE4HJjN5lirV7LJeIeHh7EG/UzPaD0Pl8vFe97zHj784Q/T0dHB3//93xOJRPi5n/u563rLjEV0j43oJBGww+Ggu7ubu3fv8vTTT8teKxQKce/evZTl7OPjY+bn5+ns7GRjYwOj0UhFRYWssYoANpuN+fl5Ojo6MJvNSY/dPzrm9rd9GLcntbsJRIsG9VVlLG9G5RdqtYqOhhr2jk44uCSHV5AX1UHJdUWRECXV2eiwmZ52JuaW8cjobFAoFAx3t/LyuWJIZ0s9u0c2Tk7lDQMCeMNTA7gVBibWkrsNa7Vqep95CzNJTTVzLzXV7K8ynykyxM65RM/0fpTkBAFainQE/H5WT6ORrFKAxmJjzMXkqdo8Vo7cHLkCdJSbOHL5aSw0cnfjhL/8vts0lyTPszkcDmZmZuju7k7LjFLyrjs6OuL4+Bi1Wh2rjMYPs36UJOfxePj2b/923v/+9/P+97//Wt8rDq9OootEIgSDwZgI2GAw0NzcjCAIZyqiciCKIi+99FJScoyv3qrVatxuN7u7uxwfH6PT6SguLqawsPBSxfje3h5bW1t0d3fLzqH87v/6K37htz4h61iA8uKC2PjDlc0dWUWK9sZaFlY3Uybw46FUKnh2oJvtAyurm6nzYudxu7+Tl8ZmUCgV3Orp5JWpOdkFB4D+zjaW905we3201lVhzrUwvXVM4JyRqdFgoOXWG1g4SmKqWZHLzL4rYUdEV4WJmR3HBQIcqrZwd8NGfo6a+kIDa1Y3eaoQy6cPjhuozuXeZnSr21qcw57Dz6k3xECNhY1jNzUFBsY3T/nw6+v54Tcm73Sx2+3Mz8/T09OT0M4oHfh8Po6OjrBarfj9fgoKClAqlVit1kdCcl6vlxdeeIH3vOc9fO/3fu+1vtc5vHqJ7vT0lImJCWpqaigvf9Av+sorrzAwMCA70oKoXCQR0UUiERYWFggEAnR0RAe2nM/Hud1uDg8POTqKzhctKiqiqKgIvV6PKIqsrKzgcrno7OxM65xCoTBvfN8PM7+aujOhKC+XxroqVEoVXx2ZkP0eQFrzVAvycmmormBmaY26yjJmZI5YPI/nhns5cbqZTvP1fR2tTK3vX8g9WUw5tDXWsmP3s3viJNdsorbvOVaOLye5rgozc/vuhCTXXGxg/diDP3T2AdBdbiYQDqNTK5nedRCKiDRZFCzZHpBsc6GGJWtU3tJdqsfqjbBj91OVpycYjqDXKAiEIhg0Kv7y+26jUV2e3rbZbCwsLGSE5M4jHA6zurrK7u4uarUak8lEUVHRldxM5MDv9/O+972Pt73tbfzAD/xAxrsqUuDVSXQOh4ORkZGEIuCRkRG6uroSCiwvQyKiCwaDTExMkJeXR11dXazTIVlOTnpiHh4exirDZrOZ9vb2K42De/HeFO/6vp+69Pf1laXo9TrmVjeIRKJdGG0NNWkTUEttOQtJDCtVSiVDPe1MLa7EzEINOi11VeWy58lKGOhqZXljl5KiPE5OnVjtqbesWo2Gns527s0nzykKgsBT/d3kNw2w7QyzbQ8QTnCNd5SZWTxyJ3Qpqc7TceIO4Lxv5ZRvUFNh0WHWq9myec5M9Ko0Cuy7HxgBlJm1uPxh9FoluVolGkFk5sCLApG6fA3+sECJRc/KkZs//K4BOstzL/0sJycnLC4u0tvb+9CV1EQ4PDxkY2OD3t5eVCpVTPwrOQYXFhYmtWdPB4FAgPe///18wzd8Az/6oz/6qEkOXq1EFw6HcbvdCclMUorH5yBS4TzReTwexsfHY0UDqSorl6ykthyj0UgoFMLr9ZKfn09xcXHaPYLf93Mf5a/+6Uux/9dqNHS31rOzf8ju0cmF44sL8ggEQtidyaUg8TAa9FjMRrYTSDiiMyJcbCaYvpUO2RkNetqa6rg79cD12KDT0tlaz53Jy52Qi/LzKCwuYXEztY6vuroKbd0Q+45oJKdWClQVGMk36kGhxOaNkKNTs2X3EwiJCEL0DhAEUAgCZr2KEpMWhQCBUIR9h59Dp58ik4ZwROTY/UCInKsBQaHE7o0SokYpUJGnx6xTs3rkpqnYGKu4PlVnYcfmQUWEHUeQb+808+9fV39pgSDeCimdB7ZcHBwcsLm5SW9vb8LoTbJnt1qteL1e8vLyYvbs6T6wg8EgH/zgBxkeHuY//af/9DhIDl6tRCeKIoFLxvNNTU2lLaSMJzqpZayzsxOj0Zh2p4PL5WJ6epqmpqZY72E4HI71tTocDnJzcykuLiY/Pz/lhXNgPeHpb/swep2WxpoKZpfXUg6Z6e9oTtognwh1VWXsHx7HhmyXFORhMeekdB026LTUVZYxm6T5v62hllO3J2GfK8BARzPLW3ucnpsW1lxfg8Mf4UhGj25DQwOewlZcgcsvtY6qQtYdnJnzICFPr8KgUbBjP7vdNWqU5BvVbMRFcmpBpCJPz/rxg58N1eQREUXubdqpytNjdQbwBsM0l+QQjojsn/owapX0VOXxc8/XcGo7PlMgkNIdko4t0y4hElKR3HlI9uxHR0fYbDYMBkNMs5fq/EKhEB/60Ifo6Ojg537u5x4XycGTSHSzs7OUlZWRl5cnez2pgLGzs8P29nbsIkiX5CSvfqkdLBEikQh2u52joyNOTk7IycmJFTMuy+F95rP/wo/98m+nVTR4qrcjZX/pefS1NTK7vE5vRzPjc8uyuxpy9DpqK0ovkJ1SoeRWXwevTM7FtHWXobggj5LCfKbuz6EY7u1ien1P1jn09Q+wqy7HE7hcJ9dZXcjqKRfybhAlsyKjmrVzpppKAZpKjMztn91e95SbmNh5QL6D1Rb2HX627V60KoFSs56NYw85GgUVeXoWD1z0V1tQKQR+/C3NdFdaYq+NF9N6PB4ikQjt7e0UFBRknBjSJbnzkNrSpIIGXN7fKrn7VldX80u/9EuPk+Tg1Up0wKWOIwsLCzFvfLl4+eWXyc3Nxe/309nZGZvclQ7JbW5ucnh4SHd3t+wnsdQYLV04UkdHUVHRmS2LKIq8/d//+JltXypoNRrKiwtlt24pFAKtdVUU5ufzlTQLGhAlu5ryUuZWomRXVVaM3mBIq8sj6lXXjkpn4MWpy0cqxuP2s88x7zMRSjTF5j4ai01sedUk4Dh0KoHqPP2ZuQ4S+qpyGY1zHwEYqDLHKqr5BjXtZWZGNm34gtHFB6ot3NuwU2TUUF1g4N6Gja4KMzq1kp5KCz/+lsTW6Pv7+2xublJZWYnNZotp4KQCQTozQBJBIjlpkE0mEAgEYr3iUn+rzWajq6uLn/3ZnyU/P5+PfOQjV8pPZxhPHtGtrKxgNBplmw+GQiG+/OUvU1lZSVNTk6yiQzwikQiLi4uEQqErFx0keDyeWAUXiJHezs4OGzv7fN8v/o7safcAdZVl7B2e4Lsk+pXQUleFy+1l5/D4vptwa9oWTQB6nZba8lJyzSamFtdk6evikWvMoa6mit2jExprKxlf2sIfvNwr8Lk3fSPjNmVS5+DummKWbOGE4wxVgkhTcU5CU83BGssFU82OMhNzew5ytCpaSkysH3tQKwX2TqPb3d7KXMa3TmksyqHQpOHl1RNy9SpaSs2cuP383+97OmGVdXd3l93d3VhhAKIPN6lf9OTkBLVaHbse0i1OXAfJnYe0U/noRz/K3/zN36BUKvnJn/xJvuVbvuWMKuIx4dVLdIFAIGGLy/r6Omq1OuHw6fOQfOqAmEYO5BcdJB1fbm6u7JYzufD7/RwcHLC2Ft3KVVRU8NWxOX7yo/8jrXWe6u281M6poboChQBLG2crriqlkq7W+rRdS/ItJkrz8wiLIosb8k0AABpqKvCHxDOTzoryci8lvNd/0zsYPUhumNpdW8ziSThhdVWBSEuhlrkEOrtEkVxFrg5/KExdQQ5z+07c/hAd5Wamd6Nb2LJcHQ5PkKYSIzZ3AKvLjzsQ5nVNBYys2/mfHxikJ8E0L8kYore3N2nU5vV6OTo64ujoiHA4HNu1mM3mpNfdoyA5CZFIhJ/92Z8lEAjwIz/yI/zjP/4jL774In/xF3+R3bpeFZcR3dbWFqIoUl1dnfT1NpuN2dlZOjo6WF9fp6ioiOLiYtkk5/V6mZycpKamJja3MpOQLKfKysooLS3FarVyeHjIz/zm/+SOTN2bhP6OljNN/CWF+dSUl3B3cv7SP4xOq6G+qpzZlXVZ7zHc3c7i+han9wslAx3NjM4uy/rDD/e0M7WyFfOgO48o4VUxvrRJOAJPf+M7GdtL3jXSU1vC/HEooU4OpC2o/cLPq0wCO67ImXmuOWoFfVUWZvac2O63dA3FRXwqBVTnGSgwahnbtFFTYGDlyE1/tYXlQxfvGazkJ97ScuG9tra2sFqtdHd3p7U1lZyqrVYrTqeT3NxcioqKLlgi7e/vx3LO101yoijyC7/wC5ycnPAHf/AHD73VzjCePKLb3d3F7/dTV3d5I/nOzg5bW1v09PSg0Wg4PT1le3sbh8OBxWKhuLg4aSn99PSU2dlZ2tvbyc29XAt1VbjdbqampmhsbLyQazw4Oua5F34Qm0N+y5TFZESr0eD2+ehuaeTe9IKsJL/ZmENhfi6rW5dr7ArzLVSXlSSM/lrrq9g9suNwJa4Sq1QqhnraeTmJvCQeVWXFdA4+zbZfx6YjycjCulLmrMFLSW6wOveMvbmE6nwdx+4ALn8YtQAVRgGtWomoULEYF/l1VZiY3nHELurhmjx8oQiT26cM1Vq4u26jMEeNSqkkR6vkr77/4pZ1Y2MDm81Gd3f3Q6U74i2R4p1MRFHk4ODgkZHcr/zKr7CxscGf/MmfXInkPvjBD/K5z32O4uJipqenL/z+ox/9KH/2Z38GRHdSc3NzHB0dkZ+fH1NZKJVKVCoVIyMj51/+6iW6YDCYcKjN4eEhp6enNDU1XTwJUWRxcRGPx0NnZ2dsRquUj5PyDIeHh9hsNkwmE8XFxWeSwfv7+2xsbNDd3Z1xtTo86Int7Oy8VCLz2X/9Ot/zU/9V9ppajZrXDfUyMbfM0cnF+QfJUJRvQa1WsXt4cTDOUHcbS+s7nCbR7FWUFKLRaC8URSymHPLyLKzvJR64cx6F+fmU1EfbvwAKzQYaqisIqgys2sP47odgffWlzB5dTnJR5+CLJJdvUGPUKckzaPB4vGychvCHRfoqjIxtP3ioFBtVuAPRSV0QbSNz+IKsWT20lZpYOHCQZ1BTmqtnft/Jn33P8IUt69raGk6nM3YNZhJut5vV1VWsVmtMCiKZdV7H9lEURX7913+dubk5PvWpT12ZVL/yla9gNBr5ru/6roREF4/PfvazfOxjH+Nf//VfAaitrWVkZCRZAfLJMt6Ey22XQqEQk5OTmEwmenp6iEQiFyqr8YNBpIZoyQFYIrVQKJR2i5lcSJW3vr6+pAnnb3njM7z7G7/hjJA4EZRKBf0dLWzuHvKFr48w0NGcNtEdndipLC2mwGKODcQusJiprSxjREYVeOfAikGnZbCzmZH7W+62xlqOHR7ZJFdbU41oKo2RHIDV4cE6HY0itWoVLTVllNY04UJHXaEalz+EwxvEHXjwMBy4T3ImrZL8HA0mnRqdWoFSocAfCjOz62Dj5EHkNnjfaViCTiWgUhAjucZ8DVsnbk48Icx6FUcuHyUmLfVFRr6+cswHn6k9Q3KiKLK6unrmQZtpOJ1O/H4/r3vd6xBFEavVGhvGZLFYYlvcTLy3KIr8zu/8DhMTE3zmM595qHviueeeY319Xdaxn/70p3nhBfkzkTOJGxPR2e12dnZ2Yr2pEM2njY+PU1NTQ1lZWcz5RO4fOxwOMzk5GdPuqdXqmHd+JkSd0ohEu91OV1eXrAvG7nDy3As/yP7RRRGuQqGgr72Jnf0j9q1no5dbPe1npnDJRWNNJfvWY9oaalne3MGewoQzEW73dSIKCkbnVwmG5HkAdnW0sRfQ4vQkr+DevjXEtEN7wWpJq1KQq1fTUpLD+rGXE3cgRlQQza81FRuZ3TubCmgvNbKwf9bVpLfKzPjWKXkGNbUFBk6cPjZs0fNqzFfhCQtYDFpWjtxUWPT81fffRquO7gQkl51AIEB7e/u1RFd7e3vs7Owk3K7G6zdtNht6vV628DcRRFHk93//9/nSl77EX/7lX2bkPlhfX+ftb3970ojO4/FQWVnJ8vJybE5GXV0deXl5CILAhz/8YT70oQ+df9mrN6KTOyDHbrczMzNDe3t7bFh1Ovq4QCDA5OQkJSUlsWG4Xq+Xw8NDJiYmEASB4uLimLI9XUhuw4Ig0NPTI5t8LWYTv/lz/4H3/sh/jv1MEAT6O1qw2k4vbdS/MzlLe0MNsyubaZ3nqdPFYFcrY3PLOFJ0ZiRCjl5HMCJycmqnqbqc2RTecwDdnZ0sn0YIR5KT3LNP32b8RJnwaeoPRSjP1fHiiu2iFZMo0ll+cZxhpUXH5on3zPFS8UEqMCgFIUZyAzUWjp1ePP4AkVCIQCjCjz5bApEQoIylTMLh8GMhObi4W5HmUUiqA6k7IycnJ+X5iaLIH//xH/OFL3yBv/qrv7qWDo7L8NnPfpZnnnnmzDCgr33ta1RUVHB4eMjzzz9Pa2vrlYdep8KN2rpKEdvu7i4bGxv09fWh1WrTFgFfVhTQ6/XU1NRQU1OD3+/n6OiIubk5QqFQrHorxzdM2k7n5+dTU1OT9g3w/2/v3eOirPP+/+cMAzPAcIbhjIoc5AyKx7TUUssUqMxa783uLX9395q/yu6Oe1drbWt5r1vbluvWZsdtpVUsydBaK9t1U/EAkiAKCArI+TwwA3O4vn/QXDIcBxjwNM/Hw4cwc811fS4Y3vP5fN7v9+u1cHYyq++4jY8+20tidDhtag3HTw2+nBQEOFdRRYifz4Dy5D2RSCTMTIgmv7iU74/kMjHIDyeFnOp++mwHIjQkEL0RcekKkBwbyYXqugHbu+bNu5Hsc0OPb+7cueQMsgKOD+wuAelPb667Vq7Z7DFXhQzDT/6qJqb4Kqlu1RLl58KJC80kBl1a0gZ7KtB26alr1xHl78axsiZ+MSuQcE97fvzxR1GB2tHRkZiYmMsS5HrT24/CZGxTUlJCR0cHHh4e+Pj4DJiQ+/jjj8nMzCQzM3NMBAcGIz09vc+y1VRKplKpuOOOO8jOzh6zQDfuS9fBnMByc3Nxd3dHrVYTFxfXJ+lgCQ0NDRQVFYk9r5ag0+lE9RKtVou3tzcqlQoXF5c+1zW5OE2cOHHYzuo9addoWfPsK3zzw/Fhvc7H0x2pRDKgMCfAxEA/nBwVYrdDz9e6ujhTYoEe3czEWHLPnOs3y+vsqCBhymSOFRSLS1l7mR3T59zI8ZLqIc+dmDSVIs3A4g2xAS6cqVH3W0eX3I+doUwCYSpnMwMcb2d7wn27G/Q79UaC3B1pbO+io8uAg52E5InunDjfzAQvJ4pq1SyI9OG1lYk4yKQIgsCpU6fQ6XRIpVK0Wq0YRNzd3a2yT1ZVVcXFixdJSEiwyr5x795WZ2dn0bDaycmJ7du388knn/DFF18MSwTUEoZaura0tDBp0iTKy8vFa7e3t2M0GnFxcaG9vZ1FixbxwgsvcOutt/Z86bW3dAXE2qLExMR+kw5DUVFRQVVVlTgTtBR7e3vRCclgMFBfX8/58+dRq9WieokpAJ86dYqoqKhRW9U5OyrY8MiDHM4tsFiRGLqTDGETAmlt16Dp1cEgs5MSPTmEwtJKdPq+ZRx1jc20azSEBftRXN5/QHJUyImNDOPIIAmLdo2WH3LyCQlQ4eHmSunFOsLjkocMchIJzL1xASdqBi6RifZz4WxN/1JMicGuZkkGE/FBbqLiiFwmIS7QjVaNjkPnumevCpkEqQSxp3ZWqCeHzjUgl0lp1uhICnHnl/Mni0EuPz8fR0dHsa3QYDDQ1NREdXU1Z86cMdOAG0mQMgW5oYqNh4NUKsXLywsvLy8EQUCtVlNfX8/69espKSlBo9Gwc+dOqwe5n/3sZxw4cID6+nqCgoJ48cUX0em6f7///d//DcBnn33G4sWLza5dU1PDHXfcAXRPflatWtU7yFmVcZ/R9ecbYTL01Wq13HTTTcNOOgiCQFFREVqtlpiYGKu9eYxGo6he0tDQgMFgIDw8HH9/f6tl3rpLTl4Z9uuSorsb+E2/v5jwiag7tP3KMvXGXiYjMTqcoz8Wmj0+KTgAIxLOX7Tc/cvf14fQ0MkY7OScqmgasDzETiph1o0LyK0euK0tWCmhVgOd/QS5aP/uJEPv80+f0F3/5qN0YKK3E2dr1IR6O5PTo0MiKdiNnJ/6XGdN8uBoWfe+X1KIO0ajwI3hPqxdMFk0qnF2diY0NLTfMfYncz6cFq+xCHKDkZmZyZYtW7jnnnvYv38/NTU1HDx48EorDB6Iq7eOrnega2lp4dSpU0RHR1NQUMCMGTOGNYvT6/WcOnUKpVLJ5MmTx2Qvpby8nOrqaiZOnEhjYyONjY0olUqxVm+0S4/nX3uHt9Mzh/262Umx5BeVEh02iey808Nyj5JIJMxKiuFQTneb2czEGE6eLRuwy6E/osNDqVV30dTaneRwcZITEzGZOo2RC/WXlpH2dnYkz11AXs3AysHhKmcqm7X9KpmEejlxsUWDRmeerY8LcKFTb8Sph3Jw8gR3s6JiU7O+q8KOKf6uFFa10qrVkxjshs4gYG8n4eMHZiCVILYFTpw40eKfQX8tXiqVqt/6t4sXL1JVVTVuQW7v3r387ne/IysrS0wC6PX6MS9EtiLXRqCrqqqirKyMhIQE5HI5BQUFtLa2DrpH1hOtVkteXh7BwcH4+/tbe6gDzhRN6iW1tbXU19eL/hM+Pj7DltFpbGzkdGEhv//rHg4eyxvWa6cnROGkUPDP7OGrlpiYMy0OgwBHLOxyMDFrajwnS6ro6meJDBAxMRAvLy9K6jVETLuBU4MEucnezlS3aWnv7BvkfJzt6OjUo/5ptWsngYlezvgoHahTd1JSdymTHOWn5GzNpdKSSd5OVDZqCfFyRN2px1Uh42yNGh+lnAB3BaX17XyyZiah3k5icmmoFsTBMLV41dbW0t7ebpYcqK6uHtcgt3//fl5++WWysrKGpQh0hXH1Bjqj0UhXV5eZA5hUKsVgMIj/NzQ0UFNTQ3t7u/gJ2Vvh1+SwNGXKlGFp2FmKwWAQ92rCwsIGDbi9/SdMtXpD7ROaCo0TEhJo13Sy+P71XKgaeuk5KTgAR4WcguIyAOZMjeXQif4FAAYjxF+FVqfHUSFHL0BlTf8Cmz2RSqXMTk7icP7Q5tsuSiUxNy1Da5Ti7izHTiqlvUvgYmsnrT8FtQmejjR26GjT9g2YHo72uCqkoO/CXelIq1ZHRUsXjjKQSqQ0aS4FRn9XOe1detGv1UVuh9JBRpCnEznlzSQFu3G0rHumd8NkT3LLW3h4QRirZwVz8uRJfHx8xDIka9AzOVBbW4sgCISFhaFSqcbczOb777/n+eef58svvxxxwmyo1q4DBw6QmpoqtmzeeeedvPDCCwDs27ePRx99FIPBwJo1a3jmmYFtBYbg6g10Op2OEydOoFAoiIiIGFReyaTwW1NTQ1tbGx4eHqhUKnQ6HaWlpcTHxw9Let1SejbmBwUFDeu1PZcyRqNRLFvpPc7z58/T0NBAfHy8uJT48UwJy9Y8hWYAKSulkyNxUyZzNK8Qfa/M9ZykWHEZOiQSCbOTYjl26oyYNXWwlxEeEkB+aQUDvb+cHBVETZlC7tmhjX+8vDwJSl5EaUP/iRYvpZxIf3d0SNEbBYwCGI0CBqH7a5lEQpdOR3G9xuxN6GQvxUfpYKYcLLcDHxcHKpov/dySQ9zR6o2cuthKtL8LhVXd/q+zQz3Jv9hKuK8L798/lbyTJ/Hz87NINWckmKScwsPDxYb+3mZM1uTf//43Tz/9NHv27BmVzNJQrV0HDhxg8+bN7Nmzx+xxg8FAREQE//jHPwgKCmL69Ols376d6OjokQzj6s26ajQavL29CQwMxGAwDKoh1/MNYUoMFBUV0d7ejkqlQqPRoFAorNqSM1hjviU4OjoSEhJCSEgIXV1d1NXViY5kpiV5ZWUler2exMREs7HHRU7m/55Zy///4ut9zjsjPopzFVUDBrMfck5ZNLNTeXqgUnlxqJeKcZdOT37JBaJCQ6hvaetTJ+ev8sbZ3cuiIBcYGIjLlDkDBjkApaM9hXVamjV9M7ByOwlB7g4U15svd+0k3cvR/Is9uyG6TakLai7p/SUHuXC+sYM6dReeTvZUt2gwCjDBQ0FhdRt6o8BvUqI4mZtLYGDgmGx7wKU9uaSkJOzs7HBzcyM0NBStVkt9fT2nT59Gp9Ph5eWFj4/PkNJNQ3HkyBGeeuopMjMzR60lN5zWrp5kZ2cTFhYmJnPuvfdedu/ePdJAZzXGPdC5uLggk8nETofhBKmamhpcXFxITk6mpaWF2tpazp49i4uLC76+vn3kboaLJY35w8HBwYHAwEACAwPR6/XU1taSk5ODIAj4+/uLPhQ939z33H4zuQVFbNvR/UkZGhyAQiEnu1eGtD9+OHGK6bGRZgW+PZkaG0lJeRWnzg7synX63AWUTo7MjI8U9+0mBvrT0gW1lUNnY8PCJmMITOJiy8BdERO9XWjVSfoNcnYSmOAh50xd3yCZGOzG8V7lJdMneIjN/p5O9kSqnMg+39It1yQIeDpKKa7XEqFyptMg0NSh5bmlkdSXFRIcHDwmUl3QrbRjUiHp/Z5UKBQEBQURFBSEXq+noaGB8vLyQaWbhuL48eOsX7+ezz//3KpL8ME4dOgQCQkJBAQEsHnzZmJiYqisrDS7flBQEEeOHBmX8QzGuAe6zz77jBMnTpCWlkZUVJRFr9HpdOTl5eHt7U1ISAgSicSsLcYU9IqLi3F2dsbX1xdvb+9hvVEsbcwfKYIgcPHiRUJDQ/H396ehoYHKykpOnz4tLslNxagvrV9DyYVKOnU6si3wbejJ0VNnmJUYzZHcS32xCrkDCVERHLFQfVjdoeFIbgGJUWEoXd04XlRJ1yCKwSZi4+JocgunrX3gzO1Ebxda9RLRhcsMQSBS5Uh+Td8gN72fQuH4QFeOnW/CyUFKTIAblc0aztR2iJp0U0PcOHGhhXAPO6SGTs436Jk10Y1waS0TJkxEpVINeU8jwRTkEhIShnwPymQyfH198fX1NZNuKikpschkHeDkyZOsW7eOjIyMYWWMR8PUqVM5f/48SqWSrKws0tLSKCoanuDreDLugW7hwoW0tbXx0ksvUV5ezuLFi7njjjsGVIXo6OggLy9PtDDsjUQiwd3dHXd3d7NsaGlpKQqFQgx6A20A92zMnzp16pik3k1in6Ghofj4+ACICQvTpnVtbS1nzpzB1dUVlUrFWxse5861/zusIGficG4BsxJjOJJbwOQJgegNgsVBzoSdnR2OTs4cO3WWxKgwKupbqWoYWEElcVoylfZBdPaTVDAxyceFZp2Elv6CHBDr68iP/QS5xKC+hcLBngrKGtRMC3GnuL6dnAtNTPJWcvEnN7BIlZK8ilamT/RAqzPwY2UrSgcpKQEd6HRyWltbUSgUQ2b2h8twglxvpFIpHh4eeHh4IAgCHR0d1NXViX2tpm2cnoW3+fn5PPTQQ+zYsYOwsDCr3cdQuLq6il8vXbqUtWvXUl9fT2BgIOXll/qhKyoqxmz/cziMezKiJ62trezZs4eMjAyKi4u55ZZbSE1NZerUqUilUgoLC2lqahrxUlKtVoslIKZPTh8fH/HTsWdjfmRk5JjJ75jqBIcS++w5O21sbKSjS8//bN5GZY1lskg9kUikLJ43nR9O5KPuGLi0oz883F0IDAggv4c7mFQqISEilBatoY9M04w58yjSeTCIz83QQU4l58d+SlAiVM6cb+gwcwFzVdgRE+DK+YYOLv7k+9BdP9fc/byjDGd7KX5u3a5eRqNAs0bHfyU4sXp+9+/BZA5jSnIN1iNqKaMJckNh2u+tq6tDo9Gwa9cu4uLi2LJlC+np6WaqP9ZisNau6upqfH19kUgkZGdns2LFCs6fPy8mI7755hsCAwOZPn06f/vb30Y6vqs36zoQarWavXv3snPnTgoKCggNDaW4uJj9+/dbRQ24p4GNydG8rq4Ob2/vETXmW4Kp73Yk2WFTG8+JHwt46Nd/oHEY8kqBvj64u7pQUFxG+MQg1B1aqixs5g+fFIy6U99HJsqERCIhccpkNDqBs+U13LRoKTlNg8+CJ/m40NQlEUs/ehPj48Cp2r57ev5ucjo69WJw9FE6MNHLCa2+e4ZmIinYXMlkWogbaq2BMzVtRPu7UFDVxjRfGX/8WZKZegbQR7RVqVSKMkjDmd1XVFRQW1s7JkGuNzqdjnfeeYd3330Xo9HI3LlzWbFiBbfffrvVrtGztcvX17dPa9dbb73F1q1bkclkODo68tprr4key1lZWTz22GMYDAYeeOAB/vd//3ekw7j2Ap0Jo9HIr371K77//ntCQ0M5efIkc+fOJS0tjTlz5lhladnS0sLJkyeRyWRmGnXWTPVfvHiRyspKUfZ9NBSeO0/qQ89aJMM+KymWHwtLzJy83FyUTAzy52RhyaCvnZEYQ17xBYvk2iUSCUtuXUqX3J1arZSKtv516oLcFTTrpHQMsKKd4m1PYV1Xnzeam6MMZ3s7tDoDk3ycadPqKfrJZ/X4hUtBeJKXE1UtWtHcevYkD3GmlzzBg2Pnm4j0tONPq5IIUHkNek+mDxfTKsDS9q7xDHLQPdP62c9+xnvvvUdSUhLZ2dmcPXuW1atXj/m1x5lrN9AdPnyYzz//nI0bNyKVSuns7OSbb75h586dHDlyhNmzZ5OWlsa8efNGVHhpWkqaGvNNck21tbXDlmvqj557fsM1TxmMnIKz3PXwc6gHEADw8XAnwM+HvAGCWbf3agyHT/ZtFbOzs2NGUqzFHhByBwemzplP7vkezl9uzkwI8EFi78T5NoGWTiOhKlcaOum3GBhgsrsd55r1ZqKbdhJQucoJ93Gmrq3LrNNhWoibmTGOq8IOZ7m9aFsYG+DChYYOWrV6Jnk7U9HUQYSHHVtWTcXXe/hF5b3bu3rukZlWABUVFdTV1Vn1dz0Y5eXlrFy5knfeeYeZM2eO+fUuM9duoBsMnU7H999/z86dOzl48CDTpk0jLS2N+fPnW6RWYspmDbSUNMk11dTUiHVvvr6+FokaQneQKywsRBAEpkyZYvU9vx9O/Mg9j/66z4wrccpkii9cpF0ztB9r/JTJXLhYS/NPIpye7q74+/tZLOjp5upCaPwsCisHXgpLJDA7IQqpmy8SJEgk3T8bgwA6g4BWp0fo0oAAdlKQyewxSOxo0RqoV3cS7e/KyQrzxEe0f3d7l6mpXwKibaGrwo4oP1fKGtqpae3E0V6Kh5M9KrmBN1dNw9vT3aJ7GwydTic6umk0GnEJrFarx20md/HiRe6++27efPNN5s6dO6JzDNXx8Mknn7Bp0yYEQcDFxYWtW7eSkJAAYImZjbW5PgNdT/R6PQcPHmTnzp0cOHCA+Ph40tLSuPnmm/tdgpaXl1NTU0N8fLxFS0m9Xi/O9DQajdiKNlBRp8Fg4Mcff8TV1dXqXrEm1Go176d/xqvvZ6DTG/B0c2FScKCZJaIl+Hl74ubqgoCEVq2Omob+9+N64+/vi2tQNBfq+xfdNBEVNpE6O28z6fOeBCml1GuMaPV9315R3vYU1JmXpwS6K2jV6GjrIappqp+LD3SlslmDv5uCUz/t2yUEumBv0PDHVcl4uFvf7c1gMHD27Fnq6uqQyWRi7VtPMyZrU11dzd13383vf/975s+fP+LzDNXx8MMPPxAVFYWHhwd79+5lw4YNYh2cBWY21sYW6HpiMBg4fPgwO3fu5JtvviEyMpK0tDQWL16MQqFgx44dREdHj1jCyaRRV1tbK2rU+fr6isW+ppaxwMDAMXM3b2pq4syZM8TFxfH1v4/zzqeZlFXW0Ng8eNAZiNlT47CTycg5U2a2nzcQEeFhdDj60dA2uHZeXGQoFYIHWl3/ZTEBzlKaOwU6+nm+P1FNFwcpLo72YnYVIDagO7hN8HQit6JFlGoCiPVX4iLp5PVV03FzHX3Rd3/09HWVSqVi7VtDQ4PFtW/Doa6ujjvvvJNXX32VRYsWjfp8lng8AGLFQ2VlJWALdFcURqOR48ePs2PHDvbt24dOpyMqKootW7ZYJXtrNBpFhYrW1laUSiUtLS1ERkaKNXLWxlQXmJCQIG6KZx04xNoNr/cR3xwKB3t7IiYGkX+uAgAfTzcmBgdwNL+Igd5XSYmJXNAq6OgcPEmRFB1Bqc7FrBSkJ75OEtr1oO7s+3xS8CXxTBN2Epjgbs+5pkszPH9XB4I8nSmqUdOs0RHpq6T4p308b2d7ErzhlXtm4GKhuvRwMQW5gXxC2tvbxX09iUQi7uuNtCe7oaGBu+66iw0bNrB06dLRDh+wPNBt3ryZwsJC3n33XcAiMxtrYwt0Q1FXV8eKFSu46aabMBqNZGVl4e/vT2pqKrfffrtVFE+am5vF5WpHRweurq5iK5q19ucqKiqorq4mISGhT/Ilp6CI+554mbrGZovOFRLgi8zegdKKvkrAIf4+KF1c+pjfzJlzAz/WdqEfonB5WlwUZzscBxTe9HGU0GWU0KLtu5yN9nfhzE89qGbn7JV88FXaoZRBSXP3OdwdZdhJJDS0dyEBUsPlPH/XjDEReoChg1xvTImuuro6urq6ht3T2tzczJ133smzzz5LamqqNW4BsCzQfffdd6xdu5aDBw/i5dWdra6srDQzs3nzzTfHzOPhJ2yBbiiysrKQyWQsXrwY6N4MLygoYOfOnXz55Zd4eHiQmprKsmXLRjQVNyU2EhIScHR0RBAEsR6rsbGxXxPt4SAIAqWlpbS2thIXFzfgOcqravmPx1/iTOng7lzJcVEUllbQrhm8eDg2fCINbR1U1Tdx4/yb+ywl+2NGYiwFrQ79GtkAeCoAiR2N/dSYhHo7cbFZi0ZnHgCTJ1wysonwVSKXSbGTSMj9KUkhQWCCqx1lLd2vWx5qz4aVs66YINcbU0+rqUjZ3d0dlUo1YJFya2srd911F+vXr2fFihXWuAWRoQJdXl4ed9xxB3v37iUiIqLfYzZs2IBSqeSJJ56w6th6YQt0o8EkqLlz506++OILHB0dSU1NZfny5WK192BUVlZSVVU1YGKjp4l2Q0MDTk5O4r6NJXWAgiBw5swZjEajRdnbVnU7DzzzKv/qR7jTXiYjOT6KwyeHFgUwoZA7kBAXQwNKKlsGX67OmpbAj03SPr6sJtwcuiWg6tR9z+PnKkerM9DUYf5cjL8LZ2paiQlwo71TT3FdO9Mneoj7cHBJQt3ZQcrPp8i4abI7Wq3WzOPDWgmh8vJyUVLLGjP13kXKzs7O4oeivb09arWaFStW8Mtf/nJMDJ8HC3QXLlxg4cKFfPTRR2IBMFhsZmNtbIHOWphmThkZGezevRupVEpKSgqpqakEBASY/bGYHNvVajWxsbEWzdR6FqHW1dUhl8vFVrT+6gCNRiOnTp3CyclpWNLwOr2eJ179E+l7vhEf8/fxwtXVlbNlFRadA7p9Z4MmTOJ0WbdTWIC3O55entR12ZsJXQLMmZ40qGWhiwM4y+2pbu3b5O/haI/cXirWwJkI8lAQ5O5IWUM71a3d+4+xAa4U/KQnB92BsKCqlVAvR/6/WBm33jBNtMU0zZpaWlpGrATSkwsXLtDY2Gi1INebnu+P3bt3k5mZicFg4Oc//znr16+3+vWG6nhYs2YNGRkZTJgwAUAsIzl37lwfM5tRdDxYii3QjQWCIFBZWUlGRga7du1Cr9ezbNkyUlNT8fPzY8uWLSxdupQpU6aMeLbQU41YJpOJXRkODg7o9XpOnjyJSqUasdTOHz7Ywatvf0JCVDhlF2tpGYZp9YQgfwQHJZV1fctNpBIJkwJ9kDu5UtHRbdqd1zjwz8BZJuDhLDcTwzShkEkJcFdQUteO9CdpdC9newQJVDZpzIJfoLuCFo1e9Gv1UTqg0xuZPdGFOycamTEtacBZtcnhvqGhQbT/G0zgoTdjHeR6o9FoWLVqFZ6entTV1dHe3s6rr77KTTfdNObXvkKxBbqxRhAEampq2LVrF3//+98pKSlh+vTpPP/880RERFhlWaTRaKipqaGurg5BEOjs7GTSpEnDVjXuzVcHs1n/ylYam4duGTMRHxVJeVMHre1DWy/OXbSUZsEJuZ2Ag709Rqk9zZ1Galo7EZDgZCfg46rgfGPf/UCZBGZM8qDTYESrM1La0E57Z7fX6gRPR4pqLwVmZwc7PJwdqGjqHpOdBKb4uXD7FHdinNpISkqyKGj1nDU1NDQgk8nEDpiBCs3HO8h1dnayatUqli9fzi9/+UskEgmNjY0Yjcar2fNhtNgC3Xhh8p9cvXo1dnZ2ZGRk0NDQwG233UZqauqoZncmOjo6yM3NxdPTU9wL8fHxwdfXd8T9t3WNzTyz+S98+f3QooezkpPIKa4cMrMqlUqYt/ROcmr6b+mSScHPWYqvlwcdOgGdwUjXTwFNqzei7TIQE6A0a8AHQBBICHLr0w0RF+hq1ry/OMqHu2PdkWvqSUxMHLH3gkajEWfVgiD0kT8a7yDX1dXF6tWrWbhwIY8++uiYFJtfpdgC3Xhx7NgxWltbWbhwofhYY2MjmZmZZGRkUFlZKWrqxcTEDPsPw2TyExMTI2p8dXV1UVtbK/bf9mxFGy6Z3/7AM5v/QmNL39mdnZ2UmcnTOFIwsOKwCQcHe2YsvoO8moHr9hQyULk6Ud7afyCcFuJmZkVoIjnEvc/jvZMPaQn+PDDVnZb6btVea+kGmuSPamtr6ezsxN7eHqPRyNSpU8elrUun0/HAAw8wc+ZMnnzyyREHuaFauwRB4NFHHyUrKwsnJyc++OADpk6dCsCHH37Iyy+/DMBzzz3H/fffP/Ibsi62QHel0NLSwp49e9i1axclJSWipl5SUtKQQa+xsZGzZ88OKuNk6r+tra1Fq9WKQa8/39D+qKurIzfvFDsOnCDz20Pi485OjkRGTuFk8eBlKQBOjk7ELVzO6dqBS1MUMglB3m6U1Hf0+3ycn4K8qr7PTQvpK4+eEORKXkUrAt2zumdujcTXroPq6uoxtQssLS2ltrYWJycn1Gp1H+Vna6PX6/mv//ovYmJieO6550Y1kxuqtSsrK4s333yTrKwsjhw5wqOPPsqRI0dobGwkOTmZY8eOIZFImDZtGsePHx8TZ70RYAt0VyJqtZqsrCwyMjI4ffo0CxYsIDU1lenTp/f54+xpdWiJIAF0/2GYWtE6OjqG7L+tqqqioqJCXObt+1c2T/3uHaR2MpQePpRerBvymm5uboTOvpWShsGDXLCPG8V1/Qe5xEAlORV9W9Vi/Fw4U2NeKDzB05Hati7cHGWsvyWc5fH+VFRUiC1XYxXkzp8/T3NzM3FxcUilUjPl5+bm5lHXRfbGYDCwdu1aJkyYwG9+8xurLFcHKxt56KGHmD9/vliuEhkZyYEDB8R/b7/9dr/HXWauLhewoXweOzs7Wb16NcePH8fLy4tPP/103LTvrYlSqWTlypWsXLkSjUbD119/zfvvv88jjzzCvHnzSEtLY/bs2bz99tvExsZyww03DGsJJpPJ8PPzw8/PT/S/NZmqeHh44OvrK9aPXbhwgfr6erMl2K3zZjArIZptu7/j3c+/HfJ6Kl8VPvHzRxfkglzJLW/u87ifs5SS2lZ6dou5KGRIJRLWzJ3IAzdMRGFvx/nz52lqahpxoa4l9A5y0C1r7uXlhZeXl1ld5Llz50ZlWA7dJUSPPfYY/v7+vPTSS+OyJ9efaU1lZeWAj19rjHmgMxgMPPzww2Y+jykpKWb2Z9u2bcPDw4Pi4mLS09N5+umn+fTTT8d6aGOKqQg5NTVV1NTbvn07a9asQaVS8dxzz/XRhRsOPY2yTVaQVVVVnD59GqlUip2dnWiz1xN3VyX/c99yHrprEZ/sPci23d9SWdtXcikkJAR52EzK+ykPMaGQSQjxcaeorv8Slhh/JT9WtvRZFng62WOUSND28KaVAEvCnPnF3DAm+XkikUjEzpCxTAqUlZXR0tJiFuR6I5FIcHNzw83NjfDwcLFEKCcnR7TkVKlUFpkqGY1GnnjiCZRKJa+++uq4JDtswJj/lHv6PDo4OIg+jz3ZvXu3uAG6YsUKvvnmm1EFgSsNuVzO4sWLkclkpKamsnHjRvbt28cNN9zA2rVr+frrr+nqGtg5ayhM0vAmeR25XI5SqeTo0aPk5+eLZto9UTopeOiuW/jh/d/w5lO/IHbypU/1iIgIJJNmUNM28JiGCnLhKmeK69R9+lcdZVLcHe2pbesOoJN9nFl/cxhfPTKHdTdORF1XyeHDh8nOzqaxsXFA0yRrYEmQ6w9nZ2cmTZrEjBkziImJQSKRkJ+fT3Z2tlhQ3t/716SeLZFIeP3118c1yA1kWnOlmtlYmzGf0Vni89jzGJO+V0NDwzVVP6TRaJg1axYPPvhgtwz5kiVmmnrPPfccCQkJoqbecC0XjUYjBQUFyOVyEhMTkUgkotlOTU0NxcXFKJVKsRXNNNOT2dlx58KZ3LlwJv/KKWTXv3I5pvGhST1EkFO5m9W89WSChyPVLZo+Uk0SBCb7OFPdqmX1rBBSEgKICXDtcUT3+IqKimhra0OhUJCdnT1kX+hIKCsrE/uIR3NOhUJBcHAwwcHBojhnSUmJqGFoauIHePHFF2lvb+cvf/nLuM/kUlJSeOutt7j33ns5cuQIbm5u+Pv7s2TJEn71q1/R1NSd4f7666955ZVXxnVs48G42x1er7i4uLBmzRqzx2QyGfPnz2f+/PkYDAYOHTpERkYGL730ElFRUaSmprJ48eIhy0oMBgN5eXl4eHiY7W0OZgXp6Ogo7jOZ9gnnJU1hXtIUdAYjpypbyC5tJLu0gdzyZjp+EtFUyCRMULlzdoAg5+8qp61TZ2aEI5VAgJsjt0zxYfZkT+aEeiGz6/uHbupB1uv1TJ06FYlEYtYXajIrH21SwBTkrD1btLe3x9/fH39/f3EPtaSkhF/84hf4+fkhl8vZs2fPmAS5nq1dQUFBfVq7li5dSlZWFmFhYTg5OfH+++8D4OnpyfPPP8/06dMBeOGFF/oYCF0LjHnW9dChQ2zYsIGvvvoKQPy0ePbZZ8VjlixZwoYNG5g9ezZ6vR4/Pz9Rz+t6xGg0cuzYMXbu3MlXX33F5MmTSUlJ4bbbbutj+6jT6Th58iT+/v4WLzkEQaC9vZ2amhrq6+txcHAQg15/7VSdOj27/5nDuTawc3TjQrOWji4Dmi4DHV0GOrr0aHQGHOykTPRyxNXRnlBvZ0K9nZns48xELycU9oMHJZOQAXRnBPv73fcWSzAF6+G0dY1VkBsIQRDYtGkTx44dIywsjAMHDnDrrbfyf//3f2N+7WuAq6e8RK/XD+nzuGXLFn788Uf+/Oc/k56eLrZd9Wao7O0HH3zAk08+Kf7Br1u3rs8s6mrDaDSSl5fHjh072Lt3L4GBgaSkpHD77bfT3t5ORkYG99xzD76+viO+Rs/+255JDrlcLs4Wvby8CAkJseKdXUIQBE6fPo1MJiM8PNxifw7TuE2+vaZgPVC5TmlpKW1tbeMa5P74xz9y7Ngx0tPTsbe3F1sL/fz8xvz61wBXT6CD/n0eX3jhBZKTk0lJSUGr1XLfffeRk5ODp6cn6enphIaGmp3DZIzbM3u7fft2s+ztBx98wLFjx3jrrbesMewrDkEQyM/PZ+fOnezatYv6+npWrVrFo48+Koojjpbe7VFdXV0EBgaOWbmP6Z4UCsWw1Fp6Yxp3bW2tqOzb08LycgS5P//5z6KZ00hl1Yf6cF+/fj3fffcdcMm7uLm5GejOzMfFxQHdWfTMzMyR39Dl4eoKdNbAkiXwtR7oTBQUFLBq1Sqee+45zpw5w549e3BychI19VQq1aiX/TqdjhMnTuDi4oJGoxHt/nx9fa0mbmk0GsnPz8fZ2bnPB9to6G1haWdnh0QiGTe3LkEQ2LZtG/v27WPXrl3DTiyZsOTDvSdvvvkmOTk5vPfee0B3Xadabbnx+RXI1VUwbA0syd4CZGRk8M9//pOIiAhef/31EcsdXcnk5eXxt7/9TXzD/+pXvxI19X7+858jk8lETT1/f/9hB73Ozk5yc3MJDQ0VfTBMPaFnzpwZkRVkb4xGo5lrmjWRy+UEBQURFBREcXExjY2NODg4cPTo0SG7SazBxx9/zBdffEFmZuaIgxyYl2YBYmnWQIFu+/btvPjiiyO+3rXMVRPoLGH58uX87Gc/Qy6X8/bbb3P//ffz7bdDdwBcbdx7771m30skEkJDQ3nyySd54oknqKioICMjgwcffBCDwcDy5ctJTU0lODh4yD9urVZLbm4uERERZtk3BwcHse6qdxmFt7c3KpUKFxcXi4KHad/Rw8NDFHgcC0pLS9FoNCQnJyOVSvvtJjGVrVgr6G3fvp2///3vonL1aLD0wx26uztKS0vNxCe0Wi3JycnIZDKeeeYZ0tLSRjWeq5mrJtBZUtjYc59qzZo1PPXUU+M2visFiURCcHAwjz32GI8++ijV1dXs2rWLdevWoVaruf3220lNTe13P6yjo4O8vDymTJmCu7v7gNfoXUZRX19PWVkZ7e3t4ozJZAXZG1Nyw9vbe0xn2+fOnaO9vd1MUaZ3N0lTUxPV1dWcOXMGV1dXsWxlpHt4O3fu5KOPPmLPnj0jUpoZDenp6axYscJsaX7+/HkCAwM5d+4cCxcuJC4ujsmTJ4/ruK4Urpr+k+nTp1NUVERpaSldXV2kp6eTkpJidkxVVZX4dWZmJlFRUX3O88ADD6BSqYiNje33OoIg8MgjjxAWFkZ8fDwnTpyw7o2MIxKJBH9/fx5++GH279/PF198ga+vL0899RTz589n06ZNFBYWIggCx48f57vvviMmJmbQINcbOzs7fH19iY+PZ8aMGXh4eFBZ2d3dUFhYSGNjo9glYDAYyM3NHZWCsiWYgtxgiQdTL2t0dDSzZs0iMDCQxsZGjhw5Ql5eHjU1Nej1/ctN9UdmZiZvv/02u3fv7lMCNFKG07WQnp7epxHfdGxoaCjz588nJyfHKuO6GrlqkhEwdPb22WefJTMzE5lMhqenJ1u3bmXKlClm5xipnM21RmNjI7t372bXrl0UFxfT0dHBpk2bWLZsmdUMYJqamqipqaGlpQUXFxfa2toIDg4etYLyYPQMciNZjprUiE01hpYYUu/du5fNmzfz5ZdfWrXY1pLSLIDCwkJuvfVWSktLxXtuamrCyckJuVxOfX09s2fPHnR/7wrl+su6WpORyNn4+/uP9zDHhYMHD/Lwww9z//33c/DgQc6dO8eiRYtITU0lMTHRKkGvq6uL48ePI5fL6ezstLrkkQnTnqGp/9Qa9Fdj6OPjIyYZ/vGPf/Db3/6WrKysMWlZHOrDHbqtB7VaLa+++qr4uh9++IGHHnpIlJx67LHHePDBB60+vjHGFuhGw2CBbtmyZTzzzDPMnTsXgJtvvplNmzaRnJw83sMcF9avX8+TTz5JQEAAcElTb+fOnRQWFrJw4UJRU28kQU+n05GTk8PEiRNRqVRid0NNTY1oWjMcK8iBGIsg1xutVivW6j377LNERERw9OhRvvnmm1EVbNsYEKv9Iq+aPTobY8Prr78uBjm4pKn397//nSNHjjB//ny2bdvG7NmzeeKJJzh48CAGg2GQM16iq6uLnJwcJk2ahEqlAi5JHkVERDBr1iwmTZqEWq3m2LFj5ObmcvHiRbFH01LGI8hBdwN/SEgIycnJPPLII2Lr3fLly3n55ZevKcWda42rJus6XlwvsjWW4OjoSFpaGmlpaXR2drJ//362b9/O448/zpw5c0hLS+OGG27ot8/UVIsXFhY2YNeGRCLBxcUFFxcXwsLCRKeuEydOYG9vb2YFORDjFeR6cvjwYV555RW++OILgoODaW1t5ejRo9dtb/bVgG1G14uUlBQ++ugjBEHg8OHDopxNfwyVwT1w4ABubm4kJiaSmJjISy+9NJZDH1Pkcjm3334777//Pjk5OaxYsYLdu3dzww03iMKqJk298vJyjh49Snh4+LBa05RKJaGhocycOZMpU6aIPrfHjx+nvLwcrdZc6bikpAStVjuuQe748eOsX7+ezz//XMwcu7q6cvPNNw/rPPv27SMyMpKwsDCzvTUTH3zwAT4+PuJ759133xWf+/DDDwkPDyc8PJwPP/xwdDd0nXDd7dEN5VQuCALr1q1j3759opzNQPtzQ2VwDxw4wObNm9mzZ8+Y3tPlxKSpt2PHDr7//nsiIyPJzc1ly5Yt3HjjjVa5Rs+9MZM9oVarxWAwEB0dPW5B7uTJkzz00EPs2rWLsLCwEZ9nNH3bV7iZjbW5/lrArMX27dsHfV4ikbBlyxaLznXjjTdSVlZmhVFdvfTU1CsuLmbp0qXMnj2bp556ykxTbzT9saa9sZCQELRaLQUFBajVahQKBWVlZahUqjEv0M3Pz+ehhx5ix44dowpyMPzWrp589dVXLFq0SCxjWbRoEfv27btSzGyuWGxL1zHm0KFDJCQkcNttt5Gfn3+5hzNmCILA448/Tnp6On/961/Jzc3lf/7nf8jJyeGWW27hvvvuY8eOHbS19fWXHc41KioqkMvlzJs3j6SkJORyOWfPnuXIkSOUlJTQ1tZm9aRAYWEhDz74INu3bycyMnLU57PUkCYjI4P4+HhWrFgh7htfL2Y21ua6m9GNJ1OnTuX8+fMolUqysrJIS0ujqKjocg9rTJBIJHz++edmLlozZsxgxowZGI1GTp48yY4dO3jjjTcICgoiJSWFpUuXWtyFIQgCJSUldHZ2istVe3t7AgICCAgIEK0gz507J8qYW6N5v6ioiP/8z//k448/7lOoO5ZcL33b44VtRjeGuLq6olQqAVi6dKnYDH+tMli7VVJSEhs3buT48eNs3LiRiooKUlNTufPOO/noo49oaGgY8Lz9BbnemKwgExISmD59Om5ubly4cIHDhw9z5swZmpqahj3TKysr47777uODDz4gISFhWK8dDEv7tk0ComvWrOH48eMWv9ZGX2yBbgyprq4W/7iys7MxGo39ZiHLy8tZsGAB0dHRxMTE8MYbb/Q55lrpwZVIJMTGxrJhwways7N54403aGho4O677yY1NZVt27aJSQfobiU7e/YsXV1dFiceTB0McXFxzJw5E09PTy5evMjhw4c5ffo0DQ0NfVzRelNeXs6qVat49913mTp1qlXu3cRo+raXLFnC119/TVNTE01NTXz99dcsWbLEquO7JhEEYbB/Ngbh3nvvFfz8/ASZTCYEBgYK7777rrB161Zh69atgiAIwptvvilER0cL8fHxwsyZM4V///vf/Z7n4sWLwvHjxwVBEITW1lYhPDxcyM/PNzvmyy+/FG699VbBaDQKhw4dEmbMmDG2NzfOGI1Gobi4WNi0aZMwZ84c4aabbhI2b94s3HfffcKLL74oqNVqob29fVT/2trahAsXLgjHjh0T9u/fL2RnZwtlZWVCW1ub2XFFRUVCQkKC8K9//WvM7vfLL78UwsPDhdDQUOHll18WBEEQnn/+eWH37t2CIAjCM888I7535s+fL5w+fVp87bZt24TJkycLkydPFt57770xG+MVwFDxyeJ/1115ydVAamoq69atY9GiReJj11MPriAIXLhwgQceeICKigq8vb1JSUkhLS2NoKAgq5STCIIguos1NjaiUCjIz89nzpw5rF69mtdee4358+eP/mZsjAZbC9i1SllZGTk5OcycOdPs8esp2yaRSPj4448JCwujoKCAHTt24OzszNq1a7nlllt47bXXKCkpGVV2VSKR4OHhQWRkJLNmzUKlUnHw4EFuvvlmlEol1dXVo8oQ27iysGVdryDUajV33XUXf/jDH0TT4+uV++67j+DgYKRSKQEBAaxbt45169ZRW1vL559/zhNPPEFTUxO33XYbaWlpREREjHimJ5FIUCgUnD59mvfee4+QkBAyMjL49ttveeedd6x8ZzYuB7al6xWCTqdj2bJlLFmyhMcff7zP89fT0tVSTJp6GRkZVFVVsWTJEu644w6ioqKGpbTS1NTEXXfdxbPPPktqauoYjtjGMLEtXa8lBEHgwQcfJCoqqt8gB8Prwb1e8PT05Be/+AV79uzh22+/JTo6mo0bNzJv3jx+/etfk5OTM2R2taWlhZUrV/LEE0+MOsgN1b/62muvER0dTXx8PDfffDPnz58Xn7OzsxP7WntnYG1YgSGyFTbGgX/9618CIMTFxQkJCQlCQkKC8OWXX5plcI1Go7B27VohNDRUiI2NFY4ePdrnPBcuXBDmz58vREVFCdHR0cIf/vCHPsd89913gqurq3idF198cczvb7xpbW0V0tPThRUrVgjx8fHCY489Jnz33Xd9sqvV1dXCvHnzhL/97W+jvqZerxdCQ0OFkpISobOzU4iPj++TOf/222+F9vZ2QRAE4U9/+pOwcuVK8TlnZ+dRj+EaxGpZV1ugu4awpEzlu+++E26//fbLMbzLQkdHh7Br1y7hP/7jP4TY2Fjh4YcfFr7++muhurpaWLBggfDhhx9a5To//PCDsHjxYvH7jRs3Chs3bhzw+BMnTghz5swRv7cFun6xWqCzLV2vIfz9/cXiVhcXF6Kioq7ZzKylODo6cscdd/DXv/6VY8eOceutt/LJJ58QHR3NsmXLWL16tVWuM9ys+LZt27jtttvE703WhLNmzeLzzz+3yphsXMKWdb1GGahMBS4JDQQEBLB58+Zx7eG8nMjlcpYtW8ayZctQq9XjbklowhR0v//+e/ExmzXh2GILdNcgg5WpXE9CA4Nh6kG2Fpb2oO7fv5/f/va3fP/992Ivq+n1YG5NaAt0VmSIta2Nq4yuri5h8eLFwu9//3uLjp8wYYJQV1c3xqO69tHpdMKkSZOEc+fOicmIU6dOmR1z4sQJITQ0VDh79qzZ442NjYJWqxUEQRDq6uqEsLCwPnur1ym2PTobfREsKFOxVGgAuveNZsyYQUJCAjExMfz617/uc0xnZyf33HMPYWFhzJw587oVIpXJZLz11lssWbKEqKgoVq5cSUxMDC+88AKZmZkAPPnkk6jVau6++26zMpLTp0+TnJxMQkICCxYs4Jlnnrna/FeveGwFw9cQBw8eZN68ecTFxYkFsxs3buTChQtAt1T8W2+9xdatW5HJZDg6OvLaa68xZ86cfs8nCALt7e0olUp0Oh1z587ljTfeYNasWeIxf/rTn8jLy+PPf/4z6enpfPbZZ3z66adjf7M2rgdsvq42xpeOjg7mzp3L1q1bzRIcS5YsYcOGDcyePRu9Xo+fnx91dXU2Rywb1sDWGWFjfDAYDCQmJqJSqVi0aNGgYgMymQw3N7dBRTRt2Lgc2AKdjUGxs7MjNzeXiooKsrOz+3U7u5YZqq1rsD3KV155hbCwMCIjI/nqq6/GcdQ2emMLdDYswt3dnQULFrBv3z6zx3uWVej1elpaWobl5XolYzAYePjhh9m7dy8FBQVs376dgoICs2O2bduGh4cHxcXFrF+/nqeffhqAgoIC0tPTyc/PZ9++faxduxaDwXA5bsMGtkBnYxDq6upobm4GQKPR8I9//IMpU6aYHZOSkiKaKO/cuZOFCxf2uz9nSQZ3MNPmy0FPW0IHBwfRlrAnu3fv5v777wdgxYoVfPPNNwiCwO7du7n33nuRy+VMmjSJsLAwsrOzL8dt2MBWMGxjEKqqqrj//vsxGAwYjUZWrlzJsmXLeOGFF0hOTiYlJYUHH3yQ++67j7CwMDw9PUlPT+/3XHK5nG+//dYsg3vbbbeZZXAB7rnnnj6mzZeL/tq6jhw5MuAxPfcoKysrze7tWhZKvRqwBTobAxIfH09OTk6fx1966SXxa4VCwY4dO4Y8l0QiEbsRdDodOp3Olpm1MW7Ylq42xo2hMrjQv2nz5cKStq6B9ihttoRXFrZAZ2PcGCqDu3z5csrKysjLy2PRokXi3tflwhJbwoH2KFNSUkhPT6ezs5PS0lKKioqYMWPG5bgNG2DrdbVxeXjxxReF3/3udwM+r9frBVdX13EcUf8MZUuo0WiEFStWCJMnTxamT58ulJSUiK99+eWXhdDQUCEiIkLIysq6LOO/yrHZHdq4uqirq8Pe3h53d3c0Gg2LFy/m6aefZtmyZeIxVVVVojz8Z599xqZNmzh8+PDlGrKNy4/VNnFtyQgb44IlGdw//vGPZGZmIpPJ8PT05IMPPrjcw7ZxjWCb0dmwYeNKZdxmdLb8vw0bNq56bFlXGzZsXPPYAp0NGzaueWyBzoYNG9c8tkBnw4aNax5boLNhw8Y1jy3Q2bBh45rHFuhs2LBxzfP/APkrI2xZ1zF8AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "#这里设函数为y=2x+1\n",
    "x_data = [1.0,2.0,3.0]\n",
    "y_data = [3.0,5.0,7.0]\n",
    "\n",
    "def forward(x):\n",
    "    return x * w + b\n",
    "\n",
    "def loss(x,y):\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred-y)*(y_pred-y)  # *表示对应位置元素相乘\n",
    "\n",
    "mse_list = []\n",
    "W=np.arange(0.0,4,0.2)\n",
    "B=np.arange(0.0,2,0.2)\n",
    "[w,b]=np.meshgrid(W,B)\n",
    "\n",
    "l_sum = 0\n",
    "for x_val, y_val in zip(x_data, y_data):\n",
    "    y_pred_val = forward(x_val)\n",
    "    print(y_pred_val)\n",
    "    loss_val = loss(x_val, y_val)\n",
    "    l_sum += loss_val\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.plot_surface(w, b, l_sum/3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture_03_Gradient_Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 采用梯度下降更新参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict (before training) 4 4.0\n",
      "Epoch: 0 w= 1.0933333333333333 loss= 4.666666666666667\n",
      "Epoch: 1 w= 1.1779555555555554 loss= 3.8362074074074086\n",
      "Epoch: 2 w= 1.2546797037037036 loss= 3.1535329869958857\n",
      "Epoch: 3 w= 1.3242429313580246 loss= 2.592344272332262\n",
      "Epoch: 4 w= 1.3873135910979424 loss= 2.1310222071581117\n",
      "Epoch: 5 w= 1.4444976559288012 loss= 1.7517949663820642\n",
      "Epoch: 6 w= 1.4963445413754464 loss= 1.440053319920117\n",
      "Epoch: 7 w= 1.5433523841804047 loss= 1.1837878313441108\n",
      "Epoch: 8 w= 1.5859728283235668 loss= 0.9731262101573632\n",
      "Epoch: 9 w= 1.6246153643467005 loss= 0.7999529948031382\n",
      "Epoch: 10 w= 1.659651263674342 loss= 0.6575969151946154\n",
      "Epoch: 11 w= 1.6914171457314033 loss= 0.5405738908195378\n",
      "Epoch: 12 w= 1.7202182121298057 loss= 0.44437576375991855\n",
      "Epoch: 13 w= 1.7463311789976905 loss= 0.365296627844598\n",
      "Epoch: 14 w= 1.7700069356245727 loss= 0.3002900634939416\n",
      "Epoch: 15 w= 1.7914729549662791 loss= 0.2468517784170642\n",
      "Epoch: 16 w= 1.8109354791694263 loss= 0.2029231330489788\n",
      "Epoch: 17 w= 1.8285815011136133 loss= 0.16681183417217407\n",
      "Epoch: 18 w= 1.8445805610096762 loss= 0.1371267415488235\n",
      "Epoch: 19 w= 1.8590863753154396 loss= 0.11272427607497944\n",
      "Epoch: 20 w= 1.872238313619332 loss= 0.09266436490145864\n",
      "Epoch: 21 w= 1.8841627376815275 loss= 0.07617422636521683\n",
      "Epoch: 22 w= 1.8949742154979183 loss= 0.06261859959338009\n",
      "Epoch: 23 w= 1.904776622051446 loss= 0.051475271914629306\n",
      "Epoch: 24 w= 1.9136641373266443 loss= 0.04231496130368814\n",
      "Epoch: 25 w= 1.9217221511761575 loss= 0.03478477885657844\n",
      "Epoch: 26 w= 1.9290280837330496 loss= 0.02859463421027894\n",
      "Epoch: 27 w= 1.9356521292512983 loss= 0.023506060193480772\n",
      "Epoch: 28 w= 1.9416579305211772 loss= 0.01932302619282764\n",
      "Epoch: 29 w= 1.9471031903392007 loss= 0.015884386331668398\n",
      "Epoch: 30 w= 1.952040225907542 loss= 0.01305767153735723\n",
      "Epoch: 31 w= 1.9565164714895047 loss= 0.010733986344664803\n",
      "Epoch: 32 w= 1.9605749341504843 loss= 0.008823813841374291\n",
      "Epoch: 33 w= 1.9642546069631057 loss= 0.007253567147113681\n",
      "Epoch: 34 w= 1.9675908436465492 loss= 0.005962754575689583\n",
      "Epoch: 35 w= 1.970615698239538 loss= 0.004901649272531298\n",
      "Epoch: 36 w= 1.9733582330705144 loss= 0.004029373553099482\n",
      "Epoch: 37 w= 1.975844797983933 loss= 0.0033123241439168096\n",
      "Epoch: 38 w= 1.9780992835054327 loss= 0.0027228776607060357\n",
      "Epoch: 39 w= 1.980143350378259 loss= 0.002238326453885249\n",
      "Epoch: 40 w= 1.9819966376762883 loss= 0.001840003826269386\n",
      "Epoch: 41 w= 1.983676951493168 loss= 0.0015125649231412608\n",
      "Epoch: 42 w= 1.9852004360204722 loss= 0.0012433955919298103\n",
      "Epoch: 43 w= 1.9865817286585614 loss= 0.0010221264385926248\n",
      "Epoch: 44 w= 1.987834100650429 loss= 0.0008402333603648631\n",
      "Epoch: 45 w= 1.9889695845897222 loss= 0.0006907091659248264\n",
      "Epoch: 46 w= 1.9899990900280147 loss= 0.0005677936325753796\n",
      "Epoch: 47 w= 1.9909325082920666 loss= 0.0004667516012495216\n",
      "Epoch: 48 w= 1.9917788075181404 loss= 0.000383690560742734\n",
      "Epoch: 49 w= 1.9925461188164473 loss= 0.00031541069384432885\n",
      "Epoch: 50 w= 1.9932418143935788 loss= 0.0002592816085930997\n",
      "Epoch: 51 w= 1.9938725783835114 loss= 0.0002131410058905752\n",
      "Epoch: 52 w= 1.994444471067717 loss= 0.00017521137977565514\n",
      "Epoch: 53 w= 1.9949629871013967 loss= 0.0001440315413480261\n",
      "Epoch: 54 w= 1.9954331083052663 loss= 0.0001184003283899171\n",
      "Epoch: 55 w= 1.9958593515301082 loss= 9.733033217332803e-05\n",
      "Epoch: 56 w= 1.9962458120539648 loss= 8.000985883901657e-05\n",
      "Epoch: 57 w= 1.9965962029289281 loss= 6.57716599593935e-05\n",
      "Epoch: 58 w= 1.9969138906555615 loss= 5.406722767150764e-05\n",
      "Epoch: 59 w= 1.997201927527709 loss= 4.444566413387458e-05\n",
      "Epoch: 60 w= 1.9974630809584561 loss= 3.65363112808981e-05\n",
      "Epoch: 61 w= 1.9976998600690001 loss= 3.0034471708953996e-05\n",
      "Epoch: 62 w= 1.9979145397958935 loss= 2.4689670610172655e-05\n",
      "Epoch: 63 w= 1.9981091827482769 loss= 2.0296006560253656e-05\n",
      "Epoch: 64 w= 1.9982856590251044 loss= 1.6684219437262796e-05\n",
      "Epoch: 65 w= 1.9984456641827613 loss= 1.3715169898293847e-05\n",
      "Epoch: 66 w= 1.9985907355257035 loss= 1.1274479219506377e-05\n",
      "Epoch: 67 w= 1.9987222668766378 loss= 9.268123006398985e-06\n",
      "Epoch: 68 w= 1.9988415219681517 loss= 7.61880902783969e-06\n",
      "Epoch: 69 w= 1.9989496465844576 loss= 6.262999634617916e-06\n",
      "Epoch: 70 w= 1.9990476795699081 loss= 5.1484640551938914e-06\n",
      "Epoch: 71 w= 1.9991365628100501 loss= 4.232266273994499e-06\n",
      "Epoch: 72 w= 1.999217150281112 loss= 3.479110977946351e-06\n",
      "Epoch: 73 w= 1.999290216254875 loss= 2.859983851026929e-06\n",
      "Epoch: 74 w= 1.9993564627377531 loss= 2.3510338359374262e-06\n",
      "Epoch: 75 w= 1.9994165262155628 loss= 1.932654303533636e-06\n",
      "Epoch: 76 w= 1.999470983768777 loss= 1.5887277332523938e-06\n",
      "Epoch: 77 w= 1.9995203586170245 loss= 1.3060048068548734e-06\n",
      "Epoch: 78 w= 1.9995651251461022 loss= 1.0735939958924364e-06\n",
      "Epoch: 79 w= 1.9996057134657994 loss= 8.825419799121559e-07\n",
      "Epoch: 80 w= 1.9996425135423248 loss= 7.254887315754342e-07\n",
      "Epoch: 81 w= 1.999675878945041 loss= 5.963839812987369e-07\n",
      "Epoch: 82 w= 1.999706130243504 loss= 4.902541385825727e-07\n",
      "Epoch: 83 w= 1.9997335580874436 loss= 4.0301069098738336e-07\n",
      "Epoch: 84 w= 1.9997584259992822 loss= 3.312926995781724e-07\n",
      "Epoch: 85 w= 1.9997809729060159 loss= 2.723373231729343e-07\n",
      "Epoch: 86 w= 1.9998014154347876 loss= 2.2387338352920307e-07\n",
      "Epoch: 87 w= 1.9998199499942075 loss= 1.8403387118941732e-07\n",
      "Epoch: 88 w= 1.9998367546614149 loss= 1.5128402140063082e-07\n",
      "Epoch: 89 w= 1.9998519908930161 loss= 1.2436218932547864e-07\n",
      "Epoch: 90 w= 1.9998658050763347 loss= 1.0223124683409346e-07\n",
      "Epoch: 91 w= 1.9998783299358769 loss= 8.403862850836479e-08\n",
      "Epoch: 92 w= 1.9998896858085284 loss= 6.908348768398496e-08\n",
      "Epoch: 93 w= 1.9998999817997325 loss= 5.678969725349543e-08\n",
      "Epoch: 94 w= 1.9999093168317574 loss= 4.66836551287917e-08\n",
      "Epoch: 95 w= 1.9999177805941268 loss= 3.8376039345125727e-08\n",
      "Epoch: 96 w= 1.9999254544053418 loss= 3.154680994333735e-08\n",
      "Epoch: 97 w= 1.9999324119941766 loss= 2.593287985380858e-08\n",
      "Epoch: 98 w= 1.9999387202080534 loss= 2.131797981222471e-08\n",
      "Epoch: 99 w= 1.9999444396553017 loss= 1.752432687141379e-08\n",
      "Predict (after training) 4 7.999777758621207\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "\n",
    "w = 1.0  # 随机初始化\n",
    "\n",
    "def forward(x):\n",
    "    return x*w \n",
    "\n",
    "def cost(xs, ys):\n",
    "    cost = 0\n",
    "    for x, y in zip(xs, ys):\n",
    "        y_pred = forward(x)\n",
    "        cost += (y_pred - y) ** 2\n",
    "    return cost / len(xs)  # MSE\n",
    "\n",
    "def gradient(xs, ys):\n",
    "    grad = 0\n",
    "    for x, y in zip(xs, ys):\n",
    "        grad += 2*x*(x*w-y)\n",
    "    return grad / len(xs)\n",
    "\n",
    "print('Predict (before training)', 4, forward(4))\n",
    "cost_list = []\n",
    "for epoch in range(100):  # 训练100个epoch\n",
    "    cost_val = cost(x_data, y_data)  # 参数更新之前计算损失函数\n",
    "    cost_list.append(cost_val)\n",
    "    grad_val = gradient(x_data, y_data)\n",
    "    w -= 0.01*grad_val  # 学习率设置为0.01\n",
    "    print('Epoch:', epoch, 'w=', w, 'loss=', cost_val)\n",
    "print('Predict (after training)', 4, forward(4))\n",
    "plt.plot(cost_list)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 采用随机梯度下降更新参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict (before training) 4 4.0\n",
      "\tgrad: 1.0 2.0 -2.0\n",
      "\tgrad: 2.0 4.0 -7.84\n",
      "\tgrad: 3.0 6.0 -16.2288\n",
      "progress: 0 w= 1.260688 loss= 9.131170340095998\n",
      "\tgrad: 1.0 2.0 -1.478624\n",
      "\tgrad: 2.0 4.0 -5.796206079999999\n",
      "\tgrad: 3.0 6.0 -11.998146585599997\n",
      "progress: 1 w= 1.453417766656 loss= 4.990935477534164\n",
      "\tgrad: 1.0 2.0 -1.093164466688\n",
      "\tgrad: 2.0 4.0 -4.285204709416961\n",
      "\tgrad: 3.0 6.0 -8.87037374849311\n",
      "progress: 2 w= 1.5959051959019805 loss= 2.727956659786429\n",
      "\tgrad: 1.0 2.0 -0.8081896081960389\n",
      "\tgrad: 2.0 4.0 -3.1681032641284723\n",
      "\tgrad: 3.0 6.0 -6.557973756745939\n",
      "progress: 3 w= 1.701247862192685 loss= 1.4910526435717042\n",
      "\tgrad: 1.0 2.0 -0.59750427561463\n",
      "\tgrad: 2.0 4.0 -2.3422167604093502\n",
      "\tgrad: 3.0 6.0 -4.848388694047353\n",
      "progress: 4 w= 1.7791289594933983 loss= 0.814982883956898\n",
      "\tgrad: 1.0 2.0 -0.44174208101320334\n",
      "\tgrad: 2.0 4.0 -1.7316289575717576\n",
      "\tgrad: 3.0 6.0 -3.584471942173538\n",
      "progress: 5 w= 1.836707389300983 loss= 0.4454551648502959\n",
      "\tgrad: 1.0 2.0 -0.3265852213980338\n",
      "\tgrad: 2.0 4.0 -1.2802140678802925\n",
      "\tgrad: 3.0 6.0 -2.650043120512205\n",
      "progress: 6 w= 1.8792758133988885 loss= 0.24347787885849426\n",
      "\tgrad: 1.0 2.0 -0.241448373202223\n",
      "\tgrad: 2.0 4.0 -0.946477622952715\n",
      "\tgrad: 3.0 6.0 -1.9592086795121197\n",
      "progress: 7 w= 1.910747160155559 loss= 0.13308068279633564\n",
      "\tgrad: 1.0 2.0 -0.17850567968888198\n",
      "\tgrad: 2.0 4.0 -0.6997422643804168\n",
      "\tgrad: 3.0 6.0 -1.4484664872674653\n",
      "progress: 8 w= 1.9340143044689266 loss= 0.07273953681776574\n",
      "\tgrad: 1.0 2.0 -0.13197139106214673\n",
      "\tgrad: 2.0 4.0 -0.5173278529636143\n",
      "\tgrad: 3.0 6.0 -1.0708686556346834\n",
      "progress: 9 w= 1.9512159834655312 loss= 0.03975813848626224\n",
      "\tgrad: 1.0 2.0 -0.09756803306893769\n",
      "\tgrad: 2.0 4.0 -0.38246668963023644\n",
      "\tgrad: 3.0 6.0 -0.7917060475345892\n",
      "progress: 10 w= 1.9639333911678687 loss= 0.02173109212742138\n",
      "\tgrad: 1.0 2.0 -0.07213321766426262\n",
      "\tgrad: 2.0 4.0 -0.2827622132439096\n",
      "\tgrad: 3.0 6.0 -0.5853177814148953\n",
      "progress: 11 w= 1.9733355232910992 loss= 0.011877828868010278\n",
      "\tgrad: 1.0 2.0 -0.05332895341780164\n",
      "\tgrad: 2.0 4.0 -0.2090494973977819\n",
      "\tgrad: 3.0 6.0 -0.4327324596134101\n",
      "progress: 12 w= 1.9802866323953892 loss= 0.006492210229954897\n",
      "\tgrad: 1.0 2.0 -0.039426735209221686\n",
      "\tgrad: 2.0 4.0 -0.15455280202014876\n",
      "\tgrad: 3.0 6.0 -0.3199243001817109\n",
      "progress: 13 w= 1.9854256707695 loss= 0.003548526766827499\n",
      "\tgrad: 1.0 2.0 -0.02914865846100012\n",
      "\tgrad: 2.0 4.0 -0.11426274116712065\n",
      "\tgrad: 3.0 6.0 -0.2365238742159388\n",
      "progress: 14 w= 1.9892250235079405 loss= 0.0019395616852935693\n",
      "\tgrad: 1.0 2.0 -0.021549952984118992\n",
      "\tgrad: 2.0 4.0 -0.08447581569774698\n",
      "\tgrad: 3.0 6.0 -0.17486493849433593\n",
      "progress: 15 w= 1.9920339305797026 loss= 0.0010601299576561939\n",
      "\tgrad: 1.0 2.0 -0.015932138840594856\n",
      "\tgrad: 2.0 4.0 -0.062453984255132156\n",
      "\tgrad: 3.0 6.0 -0.12927974740812687\n",
      "progress: 16 w= 1.994110589284741 loss= 0.000579448199890608\n",
      "\tgrad: 1.0 2.0 -0.011778821430517894\n",
      "\tgrad: 2.0 4.0 -0.046172980007630926\n",
      "\tgrad: 3.0 6.0 -0.09557806861579543\n",
      "progress: 17 w= 1.9956458879852805 loss= 0.0003167160912033633\n",
      "\tgrad: 1.0 2.0 -0.008708224029438938\n",
      "\tgrad: 2.0 4.0 -0.03413623819540135\n",
      "\tgrad: 3.0 6.0 -0.07066201306448505\n",
      "progress: 18 w= 1.9967809527381737 loss= 0.00017311138846592646\n",
      "\tgrad: 1.0 2.0 -0.006438094523652627\n",
      "\tgrad: 2.0 4.0 -0.02523733053271826\n",
      "\tgrad: 3.0 6.0 -0.052241274202728505\n",
      "progress: 19 w= 1.9976201197307648 loss= 9.461960932498085e-05\n",
      "\tgrad: 1.0 2.0 -0.004759760538470381\n",
      "\tgrad: 2.0 4.0 -0.01865826131080439\n",
      "\tgrad: 3.0 6.0 -0.03862260091336722\n",
      "progress: 20 w= 1.998240525958391 loss= 5.171739738298014e-05\n",
      "\tgrad: 1.0 2.0 -0.0035189480832178432\n",
      "\tgrad: 2.0 4.0 -0.01379427648621423\n",
      "\tgrad: 3.0 6.0 -0.028554152326460525\n",
      "progress: 21 w= 1.99869919972735 loss= 2.8267810564328208e-05\n",
      "\tgrad: 1.0 2.0 -0.002601600545300009\n",
      "\tgrad: 2.0 4.0 -0.01019827413757568\n",
      "\tgrad: 3.0 6.0 -0.021110427464781978\n",
      "progress: 22 w= 1.9990383027488265 loss= 1.5450683029998435e-05\n",
      "\tgrad: 1.0 2.0 -0.001923394502346909\n",
      "\tgrad: 2.0 4.0 -0.007539706449199102\n",
      "\tgrad: 3.0 6.0 -0.01560719234984198\n",
      "progress: 23 w= 1.9992890056818404 loss= 8.445068837224808e-06\n",
      "\tgrad: 1.0 2.0 -0.0014219886363191492\n",
      "\tgrad: 2.0 4.0 -0.005574195454370212\n",
      "\tgrad: 3.0 6.0 -0.011538584590544687\n",
      "progress: 24 w= 1.999474353368653 loss= 4.61592458579276e-06\n",
      "\tgrad: 1.0 2.0 -0.0010512932626940419\n",
      "\tgrad: 2.0 4.0 -0.004121069589761106\n",
      "\tgrad: 3.0 6.0 -0.008530614050808794\n",
      "progress: 25 w= 1.9996113831376856 loss= 2.522982369050795e-06\n",
      "\tgrad: 1.0 2.0 -0.0007772337246287897\n",
      "\tgrad: 2.0 4.0 -0.0030467562005451754\n",
      "\tgrad: 3.0 6.0 -0.006306785335127074\n",
      "progress: 26 w= 1.9997126908902887 loss= 1.379017337962252e-06\n",
      "\tgrad: 1.0 2.0 -0.0005746182194226179\n",
      "\tgrad: 2.0 4.0 -0.002252503420136165\n",
      "\tgrad: 3.0 6.0 -0.00466268207967957\n",
      "progress: 27 w= 1.9997875889274812 loss= 7.537463764030389e-07\n",
      "\tgrad: 1.0 2.0 -0.0004248221450375844\n",
      "\tgrad: 2.0 4.0 -0.0016653028085471533\n",
      "\tgrad: 3.0 6.0 -0.0034471768136938863\n",
      "progress: 28 w= 1.9998429619451539 loss= 4.119843777895263e-07\n",
      "\tgrad: 1.0 2.0 -0.00031407610969225175\n",
      "\tgrad: 2.0 4.0 -0.0012311783499932005\n",
      "\tgrad: 3.0 6.0 -0.0025485391844828342\n",
      "progress: 29 w= 1.9998838998815958 loss= 2.2518334131447684e-07\n",
      "\tgrad: 1.0 2.0 -0.00023220023680847746\n",
      "\tgrad: 2.0 4.0 -0.0009102249282886277\n",
      "\tgrad: 3.0 6.0 -0.0018841656015560204\n",
      "progress: 30 w= 1.9999141657892625 loss= 1.230812136072453e-07\n",
      "\tgrad: 1.0 2.0 -0.00017166842147497974\n",
      "\tgrad: 2.0 4.0 -0.0006729402121816719\n",
      "\tgrad: 3.0 6.0 -0.0013929862392156878\n",
      "progress: 31 w= 1.9999365417379913 loss= 6.72740046159769e-08\n",
      "\tgrad: 1.0 2.0 -0.0001269165240174175\n",
      "\tgrad: 2.0 4.0 -0.0004975127741477792\n",
      "\tgrad: 3.0 6.0 -0.0010298514424817995\n",
      "progress: 32 w= 1.9999530845453979 loss= 3.677077568883698e-08\n",
      "\tgrad: 1.0 2.0 -9.383090920422887e-05\n",
      "\tgrad: 2.0 4.0 -0.00036781716408107457\n",
      "\tgrad: 3.0 6.0 -0.0007613815296476645\n",
      "progress: 33 w= 1.9999653148414271 loss= 2.009825269786531e-08\n",
      "\tgrad: 1.0 2.0 -6.937031714571162e-05\n",
      "\tgrad: 2.0 4.0 -0.0002719316432120422\n",
      "\tgrad: 3.0 6.0 -0.0005628985014531906\n",
      "progress: 34 w= 1.999974356846045 loss= 1.0985347846020229e-08\n",
      "\tgrad: 1.0 2.0 -5.1286307909848006e-05\n",
      "\tgrad: 2.0 4.0 -0.00020104232700646207\n",
      "\tgrad: 3.0 6.0 -0.0004161576169003922\n",
      "progress: 35 w= 1.9999810417085633 loss= 6.004395959775294e-09\n",
      "\tgrad: 1.0 2.0 -3.7916582873442906e-05\n",
      "\tgrad: 2.0 4.0 -0.0001486330048638962\n",
      "\tgrad: 3.0 6.0 -0.0003076703200690645\n",
      "progress: 36 w= 1.9999859839076413 loss= 3.2818961535760077e-09\n",
      "\tgrad: 1.0 2.0 -2.8032184717474706e-05\n",
      "\tgrad: 2.0 4.0 -0.0001098861640933535\n",
      "\tgrad: 3.0 6.0 -0.00022746435967313516\n",
      "progress: 37 w= 1.9999896377347262 loss= 1.7938261292475793e-09\n",
      "\tgrad: 1.0 2.0 -2.0724530547688857e-05\n",
      "\tgrad: 2.0 4.0 -8.124015974608767e-05\n",
      "\tgrad: 3.0 6.0 -0.00016816713067413502\n",
      "progress: 38 w= 1.999992339052936 loss= 9.804734918933698e-10\n",
      "\tgrad: 1.0 2.0 -1.5321894128117464e-05\n",
      "\tgrad: 2.0 4.0 -6.006182498197177e-05\n",
      "\tgrad: 3.0 6.0 -0.00012432797771566584\n",
      "progress: 39 w= 1.9999943361699042 loss= 5.359093909486216e-10\n",
      "\tgrad: 1.0 2.0 -1.1327660191629008e-05\n",
      "\tgrad: 2.0 4.0 -4.4404427951505454e-05\n",
      "\tgrad: 3.0 6.0 -9.191716585732479e-05\n",
      "progress: 40 w= 1.9999958126624442 loss= 2.929185517711759e-10\n",
      "\tgrad: 1.0 2.0 -8.37467511161094e-06\n",
      "\tgrad: 2.0 4.0 -3.282872643772805e-05\n",
      "\tgrad: 3.0 6.0 -6.795546372551087e-05\n",
      "progress: 41 w= 1.999996904251097 loss= 1.6010407620189493e-10\n",
      "\tgrad: 1.0 2.0 -6.191497806007362e-06\n",
      "\tgrad: 2.0 4.0 -2.4270671399762023e-05\n",
      "\tgrad: 3.0 6.0 -5.0240289795056015e-05\n",
      "progress: 42 w= 1.999997711275687 loss= 8.751004353779433e-11\n",
      "\tgrad: 1.0 2.0 -4.5774486259198e-06\n",
      "\tgrad: 2.0 4.0 -1.794359861406747e-05\n",
      "\tgrad: 3.0 6.0 -3.714324913239864e-05\n",
      "progress: 43 w= 1.9999983079186507 loss= 4.7831435036272696e-11\n",
      "\tgrad: 1.0 2.0 -3.3841626985164908e-06\n",
      "\tgrad: 2.0 4.0 -1.326591777761621e-05\n",
      "\tgrad: 3.0 6.0 -2.7460449796734565e-05\n",
      "progress: 44 w= 1.9999987490239537 loss= 2.614381258124446e-11\n",
      "\tgrad: 1.0 2.0 -2.5019520926150562e-06\n",
      "\tgrad: 2.0 4.0 -9.807652203264183e-06\n",
      "\tgrad: 3.0 6.0 -2.0301840059744336e-05\n",
      "progress: 45 w= 1.9999990751383971 loss= 1.4289743472838837e-11\n",
      "\tgrad: 1.0 2.0 -1.8497232057157476e-06\n",
      "\tgrad: 2.0 4.0 -7.250914967116273e-06\n",
      "\tgrad: 3.0 6.0 -1.5009393983689279e-05\n",
      "progress: 46 w= 1.9999993162387186 loss= 7.810519902420936e-12\n",
      "\tgrad: 1.0 2.0 -1.3675225627451937e-06\n",
      "\tgrad: 2.0 4.0 -5.3606884460322135e-06\n",
      "\tgrad: 3.0 6.0 -1.109662508014253e-05\n",
      "progress: 47 w= 1.9999994944870796 loss= 4.269091410874813e-12\n",
      "\tgrad: 1.0 2.0 -1.0110258408246864e-06\n",
      "\tgrad: 2.0 4.0 -3.963221296032771e-06\n",
      "\tgrad: 3.0 6.0 -8.20386808086937e-06\n",
      "progress: 48 w= 1.9999996262682318 loss= 2.3334095170724104e-12\n",
      "\tgrad: 1.0 2.0 -7.474635363990956e-07\n",
      "\tgrad: 2.0 4.0 -2.930057062755509e-06\n",
      "\tgrad: 3.0 6.0 -6.065218119744031e-06\n",
      "progress: 49 w= 1.999999723695619 loss= 1.2754001845445623e-12\n",
      "\tgrad: 1.0 2.0 -5.526087618612507e-07\n",
      "\tgrad: 2.0 4.0 -2.166226346744793e-06\n",
      "\tgrad: 3.0 6.0 -4.484088535150477e-06\n",
      "progress: 50 w= 1.9999997957248556 loss= 6.971110807809687e-13\n",
      "\tgrad: 1.0 2.0 -4.08550288710785e-07\n",
      "\tgrad: 2.0 4.0 -1.6015171322436572e-06\n",
      "\tgrad: 3.0 6.0 -3.3151404608133817e-06\n",
      "progress: 51 w= 1.9999998489769344 loss= 3.810285310612767e-13\n",
      "\tgrad: 1.0 2.0 -3.020461312175371e-07\n",
      "\tgrad: 2.0 4.0 -1.1840208351543424e-06\n",
      "\tgrad: 3.0 6.0 -2.4509231284497446e-06\n",
      "progress: 52 w= 1.9999998883468353 loss= 2.0826342583935095e-13\n",
      "\tgrad: 1.0 2.0 -2.2330632942768602e-07\n",
      "\tgrad: 2.0 4.0 -8.753608113920563e-07\n",
      "\tgrad: 3.0 6.0 -1.811996877876254e-06\n",
      "progress: 53 w= 1.9999999174534755 loss= 1.1383308862014303e-13\n",
      "\tgrad: 1.0 2.0 -1.6509304900935717e-07\n",
      "\tgrad: 2.0 4.0 -6.471647520100987e-07\n",
      "\tgrad: 3.0 6.0 -1.3396310407642886e-06\n",
      "progress: 54 w= 1.999999938972364 loss= 6.221914359741133e-14\n",
      "\tgrad: 1.0 2.0 -1.220552721115098e-07\n",
      "\tgrad: 2.0 4.0 -4.784566662863199e-07\n",
      "\tgrad: 3.0 6.0 -9.904052991061008e-07\n",
      "progress: 55 w= 1.9999999548815364 loss= 3.400787836254813e-14\n",
      "\tgrad: 1.0 2.0 -9.023692726373156e-08\n",
      "\tgrad: 2.0 4.0 -3.5372875473171916e-07\n",
      "\tgrad: 3.0 6.0 -7.322185204827747e-07\n",
      "progress: 56 w= 1.9999999666433785 loss= 1.8588102038943167e-14\n",
      "\tgrad: 1.0 2.0 -6.671324292994996e-08\n",
      "\tgrad: 2.0 4.0 -2.615159129248923e-07\n",
      "\tgrad: 3.0 6.0 -5.413379398078177e-07\n",
      "progress: 57 w= 1.9999999753390494 loss= 1.0159926345146978e-14\n",
      "\tgrad: 1.0 2.0 -4.932190122985958e-08\n",
      "\tgrad: 2.0 4.0 -1.9334185274999527e-07\n",
      "\tgrad: 3.0 6.0 -4.002176350326181e-07\n",
      "progress: 58 w= 1.9999999817678633 loss= 5.553235233228262e-15\n",
      "\tgrad: 1.0 2.0 -3.6464273378555845e-08\n",
      "\tgrad: 2.0 4.0 -1.429399514307761e-07\n",
      "\tgrad: 3.0 6.0 -2.9588569994132286e-07\n",
      "progress: 59 w= 1.9999999865207625 loss= 3.0352997458740945e-15\n",
      "\tgrad: 1.0 2.0 -2.6958475007887728e-08\n",
      "\tgrad: 2.0 4.0 -1.0567722164012139e-07\n",
      "\tgrad: 3.0 6.0 -2.1875184863517916e-07\n",
      "progress: 60 w= 1.999999990034638 loss= 1.6590409281392764e-15\n",
      "\tgrad: 1.0 2.0 -1.993072418216002e-08\n",
      "\tgrad: 2.0 4.0 -7.812843882959442e-08\n",
      "\tgrad: 3.0 6.0 -1.617258700292723e-07\n",
      "progress: 61 w= 1.9999999926324883 loss= 9.068022795449514e-16\n",
      "\tgrad: 1.0 2.0 -1.473502342363986e-08\n",
      "\tgrad: 2.0 4.0 -5.7761292637792394e-08\n",
      "\tgrad: 3.0 6.0 -1.195658771990793e-07\n",
      "progress: 62 w= 1.99999999455311 loss= 4.956420488952487e-16\n",
      "\tgrad: 1.0 2.0 -1.0893780100218464e-08\n",
      "\tgrad: 2.0 4.0 -4.270361841918202e-08\n",
      "\tgrad: 3.0 6.0 -8.839649012770678e-08\n",
      "progress: 63 w= 1.9999999959730488 loss= 2.7090914819461653e-16\n",
      "\tgrad: 1.0 2.0 -8.05390243385773e-09\n",
      "\tgrad: 2.0 4.0 -3.1571296688071016e-08\n",
      "\tgrad: 3.0 6.0 -6.53525820126788e-08\n",
      "progress: 64 w= 1.9999999970228268 loss= 1.480741124443087e-16\n",
      "\tgrad: 1.0 2.0 -5.9543463493128e-09\n",
      "\tgrad: 2.0 4.0 -2.334103754719763e-08\n",
      "\tgrad: 3.0 6.0 -4.8315948575350376e-08\n",
      "progress: 65 w= 1.9999999977989402 loss= 8.093467319454633e-17\n",
      "\tgrad: 1.0 2.0 -4.402119557767037e-09\n",
      "\tgrad: 2.0 4.0 -1.725630838222969e-08\n",
      "\tgrad: 3.0 6.0 -3.5720557178819945e-08\n",
      "progress: 66 w= 1.9999999983727301 loss= 4.4237452103093086e-17\n",
      "\tgrad: 1.0 2.0 -3.254539748809293e-09\n",
      "\tgrad: 2.0 4.0 -1.2757796596929438e-08\n",
      "\tgrad: 3.0 6.0 -2.6408640607655798e-08\n",
      "progress: 67 w= 1.9999999987969397 loss= 2.417940731628089e-17\n",
      "\tgrad: 1.0 2.0 -2.406120636067044e-09\n",
      "\tgrad: 2.0 4.0 -9.431992964437086e-09\n",
      "\tgrad: 3.0 6.0 -1.9524227568012975e-08\n",
      "progress: 68 w= 1.999999999110563 loss= 1.321603818914294e-17\n",
      "\tgrad: 1.0 2.0 -1.7788739370416806e-09\n",
      "\tgrad: 2.0 4.0 -6.97318647269185e-09\n",
      "\tgrad: 3.0 6.0 -1.4434496264925656e-08\n",
      "progress: 69 w= 1.9999999993424284 loss= 7.223653526452133e-18\n",
      "\tgrad: 1.0 2.0 -1.3151431055291596e-09\n",
      "\tgrad: 2.0 4.0 -5.155360582875801e-09\n",
      "\tgrad: 3.0 6.0 -1.067159693945996e-08\n",
      "progress: 70 w= 1.9999999995138495 loss= 3.9483193314682906e-18\n",
      "\tgrad: 1.0 2.0 -9.72300906454393e-10\n",
      "\tgrad: 2.0 4.0 -3.811418736177075e-09\n",
      "\tgrad: 3.0 6.0 -7.88963561149103e-09\n",
      "progress: 71 w= 1.9999999996405833 loss= 2.1580806069463956e-18\n",
      "\tgrad: 1.0 2.0 -7.18833437218791e-10\n",
      "\tgrad: 2.0 4.0 -2.8178277489132597e-09\n",
      "\tgrad: 3.0 6.0 -5.832902161273523e-09\n",
      "progress: 72 w= 1.999999999734279 loss= 1.1795680215816471e-18\n",
      "\tgrad: 1.0 2.0 -5.314420015167798e-10\n",
      "\tgrad: 2.0 4.0 -2.0832526814729135e-09\n",
      "\tgrad: 3.0 6.0 -4.31233715403323e-09\n",
      "progress: 73 w= 1.9999999998035491 loss= 6.4473110851989965e-19\n",
      "\tgrad: 1.0 2.0 -3.92901711165905e-10\n",
      "\tgrad: 2.0 4.0 -1.5401742103904326e-09\n",
      "\tgrad: 3.0 6.0 -3.188159070077745e-09\n",
      "progress: 74 w= 1.9999999998547615 loss= 3.5239871381328163e-19\n",
      "\tgrad: 1.0 2.0 -2.9047697580608656e-10\n",
      "\tgrad: 2.0 4.0 -1.1386696030513122e-09\n",
      "\tgrad: 3.0 6.0 -2.3570478902001923e-09\n",
      "progress: 75 w= 1.9999999998926234 loss= 1.9261504048240074e-19\n",
      "\tgrad: 1.0 2.0 -2.1475310418850313e-10\n",
      "\tgrad: 2.0 4.0 -8.418314934033333e-10\n",
      "\tgrad: 3.0 6.0 -1.7425900722400911e-09\n",
      "progress: 76 w= 1.9999999999206153 loss= 1.0527977803310672e-19\n",
      "\tgrad: 1.0 2.0 -1.5876944203796484e-10\n",
      "\tgrad: 2.0 4.0 -6.223768167501476e-10\n",
      "\tgrad: 3.0 6.0 -1.2883241140571045e-09\n",
      "progress: 77 w= 1.9999999999413098 loss= 5.754429955693564e-20\n",
      "\tgrad: 1.0 2.0 -1.17380327679939e-10\n",
      "\tgrad: 2.0 4.0 -4.601314884666863e-10\n",
      "\tgrad: 3.0 6.0 -9.524754318590567e-10\n",
      "progress: 78 w= 1.9999999999566096 loss= 3.1452826708032987e-20\n",
      "\tgrad: 1.0 2.0 -8.678080476443029e-11\n",
      "\tgrad: 2.0 4.0 -3.4018121652934497e-10\n",
      "\tgrad: 3.0 6.0 -7.041780492045291e-10\n",
      "progress: 79 w= 1.9999999999679208 loss= 1.7191656109647926e-20\n",
      "\tgrad: 1.0 2.0 -6.415845632545825e-11\n",
      "\tgrad: 2.0 4.0 -2.5150193039280566e-10\n",
      "\tgrad: 3.0 6.0 -5.206075570640678e-10\n",
      "progress: 80 w= 1.9999999999762834 loss= 9.396758983838199e-21\n",
      "\tgrad: 1.0 2.0 -4.743316850408519e-11\n",
      "\tgrad: 2.0 4.0 -1.8593837580738182e-10\n",
      "\tgrad: 3.0 6.0 -3.8489211817704927e-10\n",
      "progress: 81 w= 1.999999999982466 loss= 5.136032805157672e-21\n",
      "\tgrad: 1.0 2.0 -3.5067948545020045e-11\n",
      "\tgrad: 2.0 4.0 -1.3746692673066718e-10\n",
      "\tgrad: 3.0 6.0 -2.845563784603655e-10\n",
      "progress: 82 w= 1.9999999999870368 loss= 2.8073414984553174e-21\n",
      "\tgrad: 1.0 2.0 -2.5926372160256506e-11\n",
      "\tgrad: 2.0 4.0 -1.0163070385260653e-10\n",
      "\tgrad: 3.0 6.0 -2.1037571684701106e-10\n",
      "progress: 83 w= 1.999999999990416 loss= 1.5344657811957726e-21\n",
      "\tgrad: 1.0 2.0 -1.9167778475548403e-11\n",
      "\tgrad: 2.0 4.0 -7.51381179497912e-11\n",
      "\tgrad: 3.0 6.0 -1.5553425214420713e-10\n",
      "progress: 84 w= 1.9999999999929146 loss= 8.386855712615821e-22\n",
      "\tgrad: 1.0 2.0 -1.4170886686315498e-11\n",
      "\tgrad: 2.0 4.0 -5.555023108172463e-11\n",
      "\tgrad: 3.0 6.0 -1.1499068364173581e-10\n",
      "progress: 85 w= 1.9999999999947617 loss= 4.584004440146043e-22\n",
      "\tgrad: 1.0 2.0 -1.0476508549572827e-11\n",
      "\tgrad: 2.0 4.0 -4.106759377009439e-11\n",
      "\tgrad: 3.0 6.0 -8.500933290633839e-11\n",
      "progress: 86 w= 1.9999999999961273 loss= 2.5055063379082294e-22\n",
      "\tgrad: 1.0 2.0 -7.745359908994942e-12\n",
      "\tgrad: 2.0 4.0 -3.036149109902908e-11\n",
      "\tgrad: 3.0 6.0 -6.285105769165966e-11\n",
      "progress: 87 w= 1.999999999997137 loss= 1.3693547355931303e-22\n",
      "\tgrad: 1.0 2.0 -5.726086271806707e-12\n",
      "\tgrad: 2.0 4.0 -2.2446045022661565e-11\n",
      "\tgrad: 3.0 6.0 -4.646416584819235e-11\n",
      "progress: 88 w= 1.9999999999978835 loss= 7.484131529060059e-23\n",
      "\tgrad: 1.0 2.0 -4.233058348290797e-12\n",
      "\tgrad: 2.0 4.0 -1.659294923683774e-11\n",
      "\tgrad: 3.0 6.0 -3.4351188560322043e-11\n",
      "progress: 89 w= 1.9999999999984353 loss= 4.090151225674099e-23\n",
      "\tgrad: 1.0 2.0 -3.1294966618133913e-12\n",
      "\tgrad: 2.0 4.0 -1.226752033289813e-11\n",
      "\tgrad: 3.0 6.0 -2.539835008974478e-11\n",
      "progress: 90 w= 1.9999999999988431 loss= 2.2361520788848633e-23\n",
      "\tgrad: 1.0 2.0 -2.3137047833188262e-12\n",
      "\tgrad: 2.0 4.0 -9.070078021977679e-12\n",
      "\tgrad: 3.0 6.0 -1.8779644506139448e-11\n",
      "progress: 91 w= 1.9999999999991447 loss= 1.2222275007963959e-23\n",
      "\tgrad: 1.0 2.0 -1.7106316363424412e-12\n",
      "\tgrad: 2.0 4.0 -6.7057470687359455e-12\n",
      "\tgrad: 3.0 6.0 -1.3882228699912957e-11\n",
      "progress: 92 w= 1.9999999999993676 loss= 6.680541397586452e-24\n",
      "\tgrad: 1.0 2.0 -1.2647660696529783e-12\n",
      "\tgrad: 2.0 4.0 -4.957811938766099e-12\n",
      "\tgrad: 3.0 6.0 -1.0263789818054647e-11\n",
      "progress: 93 w= 1.9999999999995324 loss= 3.6539335536669686e-24\n",
      "\tgrad: 1.0 2.0 -9.352518759442319e-13\n",
      "\tgrad: 2.0 4.0 -3.666400516522117e-12\n",
      "\tgrad: 3.0 6.0 -7.58859641791787e-12\n",
      "progress: 94 w= 1.9999999999996543 loss= 1.997419675061985e-24\n",
      "\tgrad: 1.0 2.0 -6.914468997365475e-13\n",
      "\tgrad: 2.0 4.0 -2.7107205369247822e-12\n",
      "\tgrad: 3.0 6.0 -5.611511255665391e-12\n",
      "progress: 95 w= 1.9999999999997444 loss= 1.091085548139986e-24\n",
      "\tgrad: 1.0 2.0 -5.111466805374221e-13\n",
      "\tgrad: 2.0 4.0 -2.0037305148434825e-12\n",
      "\tgrad: 3.0 6.0 -4.1460168631601846e-12\n",
      "progress: 96 w= 1.999999999999811 loss= 5.963228352228142e-25\n",
      "\tgrad: 1.0 2.0 -3.779199175824033e-13\n",
      "\tgrad: 2.0 4.0 -1.4814816040598089e-12\n",
      "\tgrad: 3.0 6.0 -3.064215547965432e-12\n",
      "progress: 97 w= 1.9999999999998603 loss= 3.26058694663643e-25\n",
      "\tgrad: 1.0 2.0 -2.793321129956894e-13\n",
      "\tgrad: 2.0 4.0 -1.0942358130705543e-12\n",
      "\tgrad: 3.0 6.0 -2.2648549702353193e-12\n",
      "progress: 98 w= 1.9999999999998967 loss= 1.7819519823469544e-25\n",
      "\tgrad: 1.0 2.0 -2.0650148258027912e-13\n",
      "\tgrad: 2.0 4.0 -8.100187187665142e-13\n",
      "\tgrad: 3.0 6.0 -1.6786572132332367e-12\n",
      "progress: 99 w= 1.9999999999999236 loss= 9.755053953963032e-26\n",
      "Predict (after training) 4 7.9999999999996945\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "\n",
    "def forward(x):  # 前向传播函数\n",
    "    return x*w \n",
    "\n",
    "def loss(x, y):  # 随机梯度下降每次只选择一个训练样本\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred-y)**2\n",
    "\n",
    "def gradient(x, y):\n",
    "    return 2*x*(x*w-y)\n",
    "\n",
    "w = 1.0  # 随机初始化参数\n",
    "cost_list = []\n",
    "print('Predict (before training)', 4, forward(4))\n",
    "\n",
    "for epoch in range(100):\n",
    "    cost = 0\n",
    "    for x, y in zip(x_data, y_data):  # 一个训练样本为一个batch\n",
    "        grad = gradient(x, y)\n",
    "        w -= 0.01*grad\n",
    "        print('\\tgrad:', x, y, grad)\n",
    "        cost += loss(x, y)\n",
    "    cost_list.append(cost)\n",
    "    print('progress:', epoch, 'w=', w, 'loss=', cost)\n",
    "print('Predict (after training)', 4, forward(4))\n",
    "plt.plot(cost_list)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture_04_Back_Propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict (before training) 4 4.0\n",
      "\tgrad: 1.0 2.0 -2.0\n",
      "\tgrad: 2.0 4.0 -7.840000152587891\n",
      "\tgrad: 3.0 6.0 -16.228801727294922\n",
      "progress: 0 7.315943717956543\n",
      "\tgrad: 1.0 2.0 -1.478623867034912\n",
      "\tgrad: 2.0 4.0 -5.796205520629883\n",
      "\tgrad: 3.0 6.0 -11.998146057128906\n",
      "progress: 1 3.9987640380859375\n",
      "\tgrad: 1.0 2.0 -1.0931644439697266\n",
      "\tgrad: 2.0 4.0 -4.285204887390137\n",
      "\tgrad: 3.0 6.0 -8.870372772216797\n",
      "progress: 2 2.1856532096862793\n",
      "\tgrad: 1.0 2.0 -0.8081896305084229\n",
      "\tgrad: 2.0 4.0 -3.1681032180786133\n",
      "\tgrad: 3.0 6.0 -6.557973861694336\n",
      "progress: 3 1.1946394443511963\n",
      "\tgrad: 1.0 2.0 -0.5975041389465332\n",
      "\tgrad: 2.0 4.0 -2.3422164916992188\n",
      "\tgrad: 3.0 6.0 -4.848389625549316\n",
      "progress: 4 0.6529689431190491\n",
      "\tgrad: 1.0 2.0 -0.4417421817779541\n",
      "\tgrad: 2.0 4.0 -1.7316293716430664\n",
      "\tgrad: 3.0 6.0 -3.58447265625\n",
      "progress: 5 0.35690122842788696\n",
      "\tgrad: 1.0 2.0 -0.3265852928161621\n",
      "\tgrad: 2.0 4.0 -1.2802143096923828\n",
      "\tgrad: 3.0 6.0 -2.650045394897461\n",
      "progress: 6 0.195076122879982\n",
      "\tgrad: 1.0 2.0 -0.24144840240478516\n",
      "\tgrad: 2.0 4.0 -0.9464778900146484\n",
      "\tgrad: 3.0 6.0 -1.9592113494873047\n",
      "progress: 7 0.10662525147199631\n",
      "\tgrad: 1.0 2.0 -0.17850565910339355\n",
      "\tgrad: 2.0 4.0 -0.699742317199707\n",
      "\tgrad: 3.0 6.0 -1.4484672546386719\n",
      "progress: 8 0.0582793727517128\n",
      "\tgrad: 1.0 2.0 -0.1319713592529297\n",
      "\tgrad: 2.0 4.0 -0.5173273086547852\n",
      "\tgrad: 3.0 6.0 -1.070866584777832\n",
      "progress: 9 0.03185431286692619\n",
      "\tgrad: 1.0 2.0 -0.09756779670715332\n",
      "\tgrad: 2.0 4.0 -0.3824653625488281\n",
      "\tgrad: 3.0 6.0 -0.7917022705078125\n",
      "progress: 10 0.017410902306437492\n",
      "\tgrad: 1.0 2.0 -0.07213282585144043\n",
      "\tgrad: 2.0 4.0 -0.2827606201171875\n",
      "\tgrad: 3.0 6.0 -0.5853137969970703\n",
      "progress: 11 0.009516451507806778\n",
      "\tgrad: 1.0 2.0 -0.053328514099121094\n",
      "\tgrad: 2.0 4.0 -0.2090473175048828\n",
      "\tgrad: 3.0 6.0 -0.43272972106933594\n",
      "progress: 12 0.005201528314501047\n",
      "\tgrad: 1.0 2.0 -0.039426326751708984\n",
      "\tgrad: 2.0 4.0 -0.15455150604248047\n",
      "\tgrad: 3.0 6.0 -0.3199195861816406\n",
      "progress: 13 0.0028430151287466288\n",
      "\tgrad: 1.0 2.0 -0.029148340225219727\n",
      "\tgrad: 2.0 4.0 -0.11426162719726562\n",
      "\tgrad: 3.0 6.0 -0.23652076721191406\n",
      "progress: 14 0.0015539465239271522\n",
      "\tgrad: 1.0 2.0 -0.021549701690673828\n",
      "\tgrad: 2.0 4.0 -0.08447456359863281\n",
      "\tgrad: 3.0 6.0 -0.17486286163330078\n",
      "progress: 15 0.0008493617060594261\n",
      "\tgrad: 1.0 2.0 -0.01593184471130371\n",
      "\tgrad: 2.0 4.0 -0.062453269958496094\n",
      "\tgrad: 3.0 6.0 -0.12927818298339844\n",
      "progress: 16 0.00046424579340964556\n",
      "\tgrad: 1.0 2.0 -0.011778593063354492\n",
      "\tgrad: 2.0 4.0 -0.046172142028808594\n",
      "\tgrad: 3.0 6.0 -0.09557533264160156\n",
      "progress: 17 0.0002537401160225272\n",
      "\tgrad: 1.0 2.0 -0.00870823860168457\n",
      "\tgrad: 2.0 4.0 -0.03413581848144531\n",
      "\tgrad: 3.0 6.0 -0.07066154479980469\n",
      "progress: 18 0.00013869594840798527\n",
      "\tgrad: 1.0 2.0 -0.006437778472900391\n",
      "\tgrad: 2.0 4.0 -0.025236129760742188\n",
      "\tgrad: 3.0 6.0 -0.052239418029785156\n",
      "progress: 19 7.580435340059921e-05\n",
      "\tgrad: 1.0 2.0 -0.004759550094604492\n",
      "\tgrad: 2.0 4.0 -0.018657684326171875\n",
      "\tgrad: 3.0 6.0 -0.038620948791503906\n",
      "progress: 20 4.143271507928148e-05\n",
      "\tgrad: 1.0 2.0 -0.003518819808959961\n",
      "\tgrad: 2.0 4.0 -0.0137939453125\n",
      "\tgrad: 3.0 6.0 -0.028553009033203125\n",
      "progress: 21 2.264650902361609e-05\n",
      "\tgrad: 1.0 2.0 -0.00260162353515625\n",
      "\tgrad: 2.0 4.0 -0.010198593139648438\n",
      "\tgrad: 3.0 6.0 -0.021108627319335938\n",
      "progress: 22 1.2377059647405986e-05\n",
      "\tgrad: 1.0 2.0 -0.0019233226776123047\n",
      "\tgrad: 2.0 4.0 -0.0075397491455078125\n",
      "\tgrad: 3.0 6.0 -0.0156097412109375\n",
      "progress: 23 6.768445018678904e-06\n",
      "\tgrad: 1.0 2.0 -0.0014221668243408203\n",
      "\tgrad: 2.0 4.0 -0.0055751800537109375\n",
      "\tgrad: 3.0 6.0 -0.011541366577148438\n",
      "progress: 24 3.7000872907810844e-06\n",
      "\tgrad: 1.0 2.0 -0.0010514259338378906\n",
      "\tgrad: 2.0 4.0 -0.0041217803955078125\n",
      "\tgrad: 3.0 6.0 -0.008531570434570312\n",
      "progress: 25 2.021880391112063e-06\n",
      "\tgrad: 1.0 2.0 -0.0007772445678710938\n",
      "\tgrad: 2.0 4.0 -0.0030469894409179688\n",
      "\tgrad: 3.0 6.0 -0.006305694580078125\n",
      "progress: 26 1.1044940038118511e-06\n",
      "\tgrad: 1.0 2.0 -0.0005745887756347656\n",
      "\tgrad: 2.0 4.0 -0.0022525787353515625\n",
      "\tgrad: 3.0 6.0 -0.0046634674072265625\n",
      "progress: 27 6.041091182851233e-07\n",
      "\tgrad: 1.0 2.0 -0.0004248619079589844\n",
      "\tgrad: 2.0 4.0 -0.0016651153564453125\n",
      "\tgrad: 3.0 6.0 -0.003444671630859375\n",
      "progress: 28 3.296045179013163e-07\n",
      "\tgrad: 1.0 2.0 -0.0003139972686767578\n",
      "\tgrad: 2.0 4.0 -0.0012311935424804688\n",
      "\tgrad: 3.0 6.0 -0.0025491714477539062\n",
      "progress: 29 1.805076408345485e-07\n",
      "\tgrad: 1.0 2.0 -0.00023221969604492188\n",
      "\tgrad: 2.0 4.0 -0.0009107589721679688\n",
      "\tgrad: 3.0 6.0 -0.0018854141235351562\n",
      "progress: 30 9.874406714516226e-08\n",
      "\tgrad: 1.0 2.0 -0.00017189979553222656\n",
      "\tgrad: 2.0 4.0 -0.0006742477416992188\n",
      "\tgrad: 3.0 6.0 -0.00139617919921875\n",
      "progress: 31 5.4147676564753056e-08\n",
      "\tgrad: 1.0 2.0 -0.0001270771026611328\n",
      "\tgrad: 2.0 4.0 -0.0004978179931640625\n",
      "\tgrad: 3.0 6.0 -0.00102996826171875\n",
      "progress: 32 2.9467628337442875e-08\n",
      "\tgrad: 1.0 2.0 -9.393692016601562e-05\n",
      "\tgrad: 2.0 4.0 -0.0003681182861328125\n",
      "\tgrad: 3.0 6.0 -0.0007610321044921875\n",
      "progress: 33 1.6088051779661328e-08\n",
      "\tgrad: 1.0 2.0 -6.937980651855469e-05\n",
      "\tgrad: 2.0 4.0 -0.00027179718017578125\n",
      "\tgrad: 3.0 6.0 -0.000560760498046875\n",
      "progress: 34 8.734787115827203e-09\n",
      "\tgrad: 1.0 2.0 -5.125999450683594e-05\n",
      "\tgrad: 2.0 4.0 -0.00020122528076171875\n",
      "\tgrad: 3.0 6.0 -0.0004177093505859375\n",
      "progress: 35 4.8466972657479346e-09\n",
      "\tgrad: 1.0 2.0 -3.790855407714844e-05\n",
      "\tgrad: 2.0 4.0 -0.000148773193359375\n",
      "\tgrad: 3.0 6.0 -0.000308990478515625\n",
      "progress: 36 2.6520865503698587e-09\n",
      "\tgrad: 1.0 2.0 -2.8133392333984375e-05\n",
      "\tgrad: 2.0 4.0 -0.000110626220703125\n",
      "\tgrad: 3.0 6.0 -0.0002288818359375\n",
      "progress: 37 1.4551915228366852e-09\n",
      "\tgrad: 1.0 2.0 -2.09808349609375e-05\n",
      "\tgrad: 2.0 4.0 -8.20159912109375e-05\n",
      "\tgrad: 3.0 6.0 -0.00016880035400390625\n",
      "progress: 38 7.914877642178908e-10\n",
      "\tgrad: 1.0 2.0 -1.5497207641601562e-05\n",
      "\tgrad: 2.0 4.0 -6.103515625e-05\n",
      "\tgrad: 3.0 6.0 -0.000125885009765625\n",
      "progress: 39 4.4019543565809727e-10\n",
      "\tgrad: 1.0 2.0 -1.1444091796875e-05\n",
      "\tgrad: 2.0 4.0 -4.482269287109375e-05\n",
      "\tgrad: 3.0 6.0 -9.1552734375e-05\n",
      "progress: 40 2.3283064365386963e-10\n",
      "\tgrad: 1.0 2.0 -8.344650268554688e-06\n",
      "\tgrad: 2.0 4.0 -3.24249267578125e-05\n",
      "\tgrad: 3.0 6.0 -6.580352783203125e-05\n",
      "progress: 41 1.2028067430946976e-10\n",
      "\tgrad: 1.0 2.0 -5.9604644775390625e-06\n",
      "\tgrad: 2.0 4.0 -2.288818359375e-05\n",
      "\tgrad: 3.0 6.0 -4.57763671875e-05\n",
      "progress: 42 5.820766091346741e-11\n",
      "\tgrad: 1.0 2.0 -4.291534423828125e-06\n",
      "\tgrad: 2.0 4.0 -1.71661376953125e-05\n",
      "\tgrad: 3.0 6.0 -3.719329833984375e-05\n",
      "progress: 43 3.842615114990622e-11\n",
      "\tgrad: 1.0 2.0 -3.337860107421875e-06\n",
      "\tgrad: 2.0 4.0 -1.33514404296875e-05\n",
      "\tgrad: 3.0 6.0 -2.86102294921875e-05\n",
      "progress: 44 2.2737367544323206e-11\n",
      "\tgrad: 1.0 2.0 -2.6226043701171875e-06\n",
      "\tgrad: 2.0 4.0 -1.049041748046875e-05\n",
      "\tgrad: 3.0 6.0 -2.288818359375e-05\n",
      "progress: 45 1.4551915228366852e-11\n",
      "\tgrad: 1.0 2.0 -1.9073486328125e-06\n",
      "\tgrad: 2.0 4.0 -7.62939453125e-06\n",
      "\tgrad: 3.0 6.0 -1.430511474609375e-05\n",
      "progress: 46 5.6843418860808015e-12\n",
      "\tgrad: 1.0 2.0 -1.430511474609375e-06\n",
      "\tgrad: 2.0 4.0 -5.7220458984375e-06\n",
      "\tgrad: 3.0 6.0 -1.1444091796875e-05\n",
      "progress: 47 3.637978807091713e-12\n",
      "\tgrad: 1.0 2.0 -1.1920928955078125e-06\n",
      "\tgrad: 2.0 4.0 -4.76837158203125e-06\n",
      "\tgrad: 3.0 6.0 -1.1444091796875e-05\n",
      "progress: 48 3.637978807091713e-12\n",
      "\tgrad: 1.0 2.0 -9.5367431640625e-07\n",
      "\tgrad: 2.0 4.0 -3.814697265625e-06\n",
      "\tgrad: 3.0 6.0 -8.58306884765625e-06\n",
      "progress: 49 2.0463630789890885e-12\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 50 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 51 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 52 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 53 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 54 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 55 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 56 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 57 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 58 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 59 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 60 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 61 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 62 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 63 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 64 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 65 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 66 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 67 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 68 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 69 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 70 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 71 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 72 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 73 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 74 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 75 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 76 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 77 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 78 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 79 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 80 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 81 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 82 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 83 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 84 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 85 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 86 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 87 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 88 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 89 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 90 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 91 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 92 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 93 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 94 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 95 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 96 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 97 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 98 9.094947017729282e-13\n",
      "\tgrad: 1.0 2.0 -7.152557373046875e-07\n",
      "\tgrad: 2.0 4.0 -2.86102294921875e-06\n",
      "\tgrad: 3.0 6.0 -5.7220458984375e-06\n",
      "progress: 99 9.094947017729282e-13\n",
      "predict (after training) 4 7.999998569488525\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "\n",
    "w = torch.Tensor([1.0])\n",
    "w.requires_grad = True\n",
    "\n",
    "def forward(x):\n",
    "    return x*w\n",
    "\n",
    "def loss(x, y):  # 构建计算图\n",
    "    y_pred = forward(x)\n",
    "    return (y_pred-y)**2\n",
    "\n",
    "print('predict (before training)', 4, forward(4).item())  # .item()是将只有一个元素的tensor转换为标量，防止构建新的计算图\n",
    "cost_list = []\n",
    "for epoch in range(100):\n",
    "    cost = 0\n",
    "    for x, y in zip(x_data, y_data):\n",
    "        l = loss(x, y)  # 前向传播，构建计算图，计算每个阶段的梯度\n",
    "        cost += l.item()\n",
    "        l.backward()  # 反向传播，计算loss函数对每个tensor的梯度\n",
    "        print('\\tgrad:', x, y, w.grad.item())\n",
    "        w.data = w.data - 0.01*w.grad.data\n",
    "        w.grad.data.zero_()  # 梯度清零\n",
    "    print('progress:', epoch, l.item())\n",
    "    cost_list.append(cost)\n",
    "print('predict (after training)', 4, forward(4).item())\n",
    "plt.plot(cost_list)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture_05_Linear_Regression_with_Pytorch\n",
    "1. Prepare dataset\n",
    "2. Design model using Class\n",
    "    - inherit from nn.Module\n",
    "3. Contruct loss and optimizer\n",
    "    - using Pytorch API\n",
    "4. Training cycle\n",
    "    - forward, backward, update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 27.322418212890625\n",
      "1 12.167768478393555\n",
      "2 5.421281814575195\n",
      "3 2.417874813079834\n",
      "4 1.0807783603668213\n",
      "5 0.4854779839515686\n",
      "6 0.22040456533432007\n",
      "7 0.10234016180038452\n",
      "8 0.04972021281719208\n",
      "9 0.026235705241560936\n",
      "10 0.015722069889307022\n",
      "11 0.010983538813889027\n",
      "12 0.008816840127110481\n",
      "13 0.007795875426381826\n",
      "14 0.007285709492862225\n",
      "15 0.007003778591752052\n",
      "16 0.00682419678196311\n",
      "17 0.006691022776067257\n",
      "18 0.006579240784049034\n",
      "19 0.006477737333625555\n",
      "20 0.0063814870081841946\n",
      "21 0.006288429722189903\n",
      "22 0.006197432056069374\n",
      "23 0.006108101457357407\n",
      "24 0.006020155269652605\n",
      "25 0.005933643784373999\n",
      "26 0.005848324857652187\n",
      "27 0.005764260422438383\n",
      "28 0.005681401118636131\n",
      "29 0.005599768832325935\n",
      "30 0.005519308149814606\n",
      "31 0.0054399557411670685\n",
      "32 0.005361785646528006\n",
      "33 0.005284714046865702\n",
      "34 0.0052087814547121525\n",
      "35 0.005133919417858124\n",
      "36 0.005060143303126097\n",
      "37 0.00498742051422596\n",
      "38 0.0049157701432704926\n",
      "39 0.004845104180276394\n",
      "40 0.0047754812985658646\n",
      "41 0.004706833977252245\n",
      "42 0.004639217630028725\n",
      "43 0.004572499543428421\n",
      "44 0.004506803583353758\n",
      "45 0.004442053847014904\n",
      "46 0.004378186073154211\n",
      "47 0.004315279424190521\n",
      "48 0.004253261722624302\n",
      "49 0.004192152060568333\n",
      "50 0.0041318777948617935\n",
      "51 0.0040724920108914375\n",
      "52 0.0040139914490282536\n",
      "53 0.003956309054046869\n",
      "54 0.0038994397036731243\n",
      "55 0.0038433948066085577\n",
      "56 0.00378817250020802\n",
      "57 0.003733731573447585\n",
      "58 0.003680076450109482\n",
      "59 0.003627158235758543\n",
      "60 0.0035750558599829674\n",
      "61 0.003523651510477066\n",
      "62 0.0034730255138128996\n",
      "63 0.0034231022000312805\n",
      "64 0.0033739039208739996\n",
      "65 0.003325415076687932\n",
      "66 0.003277633571997285\n",
      "67 0.003230544738471508\n",
      "68 0.003184097120538354\n",
      "69 0.0031383372843265533\n",
      "70 0.0030932242516428232\n",
      "71 0.003048790618777275\n",
      "72 0.003004984464496374\n",
      "73 0.002961777150630951\n",
      "74 0.002919217571616173\n",
      "75 0.002877279184758663\n",
      "76 0.0028359084390103817\n",
      "77 0.0027951558586210012\n",
      "78 0.0027549988590180874\n",
      "79 0.002715388545766473\n",
      "80 0.0026763747446238995\n",
      "81 0.0026379269547760487\n",
      "82 0.002599993022158742\n",
      "83 0.0025626416318118572\n",
      "84 0.0025257908273488283\n",
      "85 0.0024894974194467068\n",
      "86 0.002453712746500969\n",
      "87 0.0024184631183743477\n",
      "88 0.0023837070912122726\n",
      "89 0.002349464688450098\n",
      "90 0.0023156770039349794\n",
      "91 0.0022823840845376253\n",
      "92 0.002249612007290125\n",
      "93 0.002217269968241453\n",
      "94 0.0021854285150766373\n",
      "95 0.0021540294401347637\n",
      "96 0.002123047597706318\n",
      "97 0.002092537470161915\n",
      "98 0.002062446204945445\n",
      "99 0.0020327959209680557\n",
      "100 0.0020036136265844107\n",
      "101 0.0019748171325773\n",
      "102 0.0019464263459667563\n",
      "103 0.0019184565171599388\n",
      "104 0.0018908950733020902\n",
      "105 0.0018637101165950298\n",
      "106 0.001836917595937848\n",
      "107 0.001810531597584486\n",
      "108 0.001784501364454627\n",
      "109 0.0017588703194633126\n",
      "110 0.0017335821175947785\n",
      "111 0.0017086765728890896\n",
      "112 0.001684126676991582\n",
      "113 0.0016599188093096018\n",
      "114 0.001636063912883401\n",
      "115 0.0016125439433380961\n",
      "116 0.001589364605024457\n",
      "117 0.0015665245009586215\n",
      "118 0.0015440096613019705\n",
      "119 0.0015218302141875029\n",
      "120 0.0014999473933130503\n",
      "121 0.0014784042723476887\n",
      "122 0.001457154517993331\n",
      "123 0.001436189515516162\n",
      "124 0.0014155692188069224\n",
      "125 0.0013952238950878382\n",
      "126 0.0013751831138506532\n",
      "127 0.0013554190518334508\n",
      "128 0.0013359159929677844\n",
      "129 0.001316737849265337\n",
      "130 0.0012978167505934834\n",
      "131 0.0012791480403393507\n",
      "132 0.0012607804965227842\n",
      "133 0.001242655678652227\n",
      "134 0.0012247932609170675\n",
      "135 0.001207194640301168\n",
      "136 0.0011898365337401628\n",
      "137 0.001172732561826706\n",
      "138 0.0011558977421373129\n",
      "139 0.0011392562882974744\n",
      "140 0.001122904010117054\n",
      "141 0.0011067511513829231\n",
      "142 0.0010908584808930755\n",
      "143 0.0010751874651759863\n",
      "144 0.0010597424115985632\n",
      "145 0.0010445058578625321\n",
      "146 0.0010294944513589144\n",
      "147 0.001014692592434585\n",
      "148 0.0010001036571338773\n",
      "149 0.000985723570920527\n",
      "150 0.0009715635096654296\n",
      "151 0.0009576075244694948\n",
      "152 0.0009438383858650923\n",
      "153 0.0009302770486101508\n",
      "154 0.0009169097756966949\n",
      "155 0.0009037319105118513\n",
      "156 0.0008907440351322293\n",
      "157 0.000877931946888566\n",
      "158 0.0008653230033814907\n",
      "159 0.0008528893231414258\n",
      "160 0.000840642605908215\n",
      "161 0.0008285538642667234\n",
      "162 0.000816653948277235\n",
      "163 0.0008049061289057136\n",
      "164 0.0007933286833576858\n",
      "165 0.0007819317979738116\n",
      "166 0.0007706916076131165\n",
      "167 0.0007596224895678461\n",
      "168 0.0007487098919227719\n",
      "169 0.0007379488088190556\n",
      "170 0.0007273457013070583\n",
      "171 0.0007169033633545041\n",
      "172 0.0007065905956551433\n",
      "173 0.0006964353378862143\n",
      "174 0.0006864260649308562\n",
      "175 0.000676559517160058\n",
      "176 0.0006668432033620775\n",
      "177 0.0006572509300895035\n",
      "178 0.0006478057475760579\n",
      "179 0.00063849869184196\n",
      "180 0.0006293100886978209\n",
      "181 0.0006202771328389645\n",
      "182 0.0006113640847615898\n",
      "183 0.0006025740294717252\n",
      "184 0.0005939128459431231\n",
      "185 0.0005853833281435072\n",
      "186 0.0005769775598309934\n",
      "187 0.0005686715012416244\n",
      "188 0.0005605020560324192\n",
      "189 0.000552449724636972\n",
      "190 0.0005445153801701963\n",
      "191 0.0005366848781704903\n",
      "192 0.0005289706750772893\n",
      "193 0.0005213600816205144\n",
      "194 0.0005138665437698364\n",
      "195 0.0005064874421805143\n",
      "196 0.0004992078756913543\n",
      "197 0.00049202999798581\n",
      "198 0.000484962307382375\n",
      "199 0.00047798966988921165\n",
      "200 0.0004711167421191931\n",
      "201 0.0004643549327738583\n",
      "202 0.0004576743522193283\n",
      "203 0.00045110887731425464\n",
      "204 0.0004446227103471756\n",
      "205 0.00043823159649036825\n",
      "206 0.00043192965677008033\n",
      "207 0.00042572012171149254\n",
      "208 0.00041961512761190534\n",
      "209 0.00041358021553605795\n",
      "210 0.0004076330515090376\n",
      "211 0.0004017662431579083\n",
      "212 0.0003959928872063756\n",
      "213 0.00039031123742461205\n",
      "214 0.0003847049083560705\n",
      "215 0.00037917192094027996\n",
      "216 0.0003737189690582454\n",
      "217 0.0003683400573208928\n",
      "218 0.00036305555840954185\n",
      "219 0.0003578312462195754\n",
      "220 0.0003526873770169914\n",
      "221 0.000347622437402606\n",
      "222 0.0003426270268391818\n",
      "223 0.0003377093526069075\n",
      "224 0.00033285332028754056\n",
      "225 0.0003280650416854769\n",
      "226 0.0003233517345506698\n",
      "227 0.00031870105885900557\n",
      "228 0.00031412579119205475\n",
      "229 0.00030961533775553107\n",
      "230 0.0003051537787541747\n",
      "231 0.0003007795021403581\n",
      "232 0.00029645836912095547\n",
      "233 0.0002921938430517912\n",
      "234 0.00028799520805478096\n",
      "235 0.00028385542100295424\n",
      "236 0.0002797742490656674\n",
      "237 0.0002757516340352595\n",
      "238 0.0002717863826546818\n",
      "239 0.00026788603281602263\n",
      "240 0.00026404173695482314\n",
      "241 0.00026023603277280927\n",
      "242 0.00025649936287663877\n",
      "243 0.00025280637782998383\n",
      "244 0.0002491823397576809\n",
      "245 0.00024560411111451685\n",
      "246 0.0002420662494841963\n",
      "247 0.00023858860367909074\n",
      "248 0.00023516331566497684\n",
      "249 0.0002317769540240988\n",
      "250 0.00022844898921903223\n",
      "251 0.00022516473836731166\n",
      "252 0.00022192893084138632\n",
      "253 0.00021874275989830494\n",
      "254 0.00021560014283750206\n",
      "255 0.00021249806741252542\n",
      "256 0.00020944286370649934\n",
      "257 0.0002064318978227675\n",
      "258 0.00020346806559246033\n",
      "259 0.00020054950437042862\n",
      "260 0.0001976626954274252\n",
      "261 0.0001948264252860099\n",
      "262 0.0001920247304951772\n",
      "263 0.00018926493066828698\n",
      "264 0.00018654021550901234\n",
      "265 0.00018386439478490502\n",
      "266 0.0001812228001654148\n",
      "267 0.00017861858941614628\n",
      "268 0.00017604825552552938\n",
      "269 0.00017352181021124125\n",
      "270 0.00017102847050409764\n",
      "271 0.0001685675379121676\n",
      "272 0.00016615288041066378\n",
      "273 0.00016375680570490658\n",
      "274 0.0001614072680240497\n",
      "275 0.0001590890169609338\n",
      "276 0.00015679519856348634\n",
      "277 0.00015454585081897676\n",
      "278 0.0001523260143585503\n",
      "279 0.00015013365191407502\n",
      "280 0.00014798194752074778\n",
      "281 0.00014584892778657377\n",
      "282 0.00014376032049767673\n",
      "283 0.00014168850611895323\n",
      "284 0.00013965234393253922\n",
      "285 0.00013764729374088347\n",
      "286 0.0001356608117930591\n",
      "287 0.00013371428940445185\n",
      "288 0.0001317978894803673\n",
      "289 0.0001298969582421705\n",
      "290 0.00012803383287973702\n",
      "291 0.00012619105109479278\n",
      "292 0.0001243794395122677\n",
      "293 0.00012259575305506587\n",
      "294 0.00012083006004104391\n",
      "295 0.0001190980983665213\n",
      "296 0.00011738242756109685\n",
      "297 0.0001156961006927304\n",
      "298 0.0001140334497904405\n",
      "299 0.0001123954716604203\n",
      "300 0.00011078188981628045\n",
      "301 0.0001091890808311291\n",
      "302 0.00010761927114799619\n",
      "303 0.00010606951400404796\n",
      "304 0.0001045503158820793\n",
      "305 0.00010304178431397304\n",
      "306 0.00010156560165341944\n",
      "307 0.00010010530240833759\n",
      "308 9.867001790553331e-05\n",
      "309 9.724224219098687e-05\n",
      "310 9.584819053998217e-05\n",
      "311 9.447720367461443e-05\n",
      "312 9.31158137973398e-05\n",
      "313 9.177684842143208e-05\n",
      "314 9.045752813108265e-05\n",
      "315 8.915900980355218e-05\n",
      "316 8.787942351773381e-05\n",
      "317 8.661097672302276e-05\n",
      "318 8.537055691704154e-05\n",
      "319 8.414201874984428e-05\n",
      "320 8.293481369037181e-05\n",
      "321 8.174029790097848e-05\n",
      "322 8.056564547587186e-05\n",
      "323 7.940521027194336e-05\n",
      "324 7.826835644664243e-05\n",
      "325 7.714174716966227e-05\n",
      "326 7.603521225973964e-05\n",
      "327 7.494045712519437e-05\n",
      "328 7.386539073195308e-05\n",
      "329 7.28040249668993e-05\n",
      "330 7.176093640737236e-05\n",
      "331 7.072831795085222e-05\n",
      "332 6.970973481656983e-05\n",
      "333 6.87098508933559e-05\n",
      "334 6.77212665323168e-05\n",
      "335 6.674649921478704e-05\n",
      "336 6.57861091895029e-05\n",
      "337 6.484109326265752e-05\n",
      "338 6.391221540980041e-05\n",
      "339 6.298981315921992e-05\n",
      "340 6.20878636254929e-05\n",
      "341 6.119627505540848e-05\n",
      "342 6.031385782989673e-05\n",
      "343 5.944949225522578e-05\n",
      "344 5.859693555976264e-05\n",
      "345 5.775208046543412e-05\n",
      "346 5.6920813221950084e-05\n",
      "347 5.610232983599417e-05\n",
      "348 5.5296903155976906e-05\n",
      "349 5.4501808335771784e-05\n",
      "350 5.372099985834211e-05\n",
      "351 5.295025766827166e-05\n",
      "352 5.218614387558773e-05\n",
      "353 5.1435086788842455e-05\n",
      "354 5.069712642580271e-05\n",
      "355 4.997127689421177e-05\n",
      "356 4.9249250878347084e-05\n",
      "357 4.854299913858995e-05\n",
      "358 4.7845463996054605e-05\n",
      "359 4.715637624030933e-05\n",
      "360 4.6483382902806625e-05\n",
      "361 4.581562461680733e-05\n",
      "362 4.515601904131472e-05\n",
      "363 4.45060504716821e-05\n",
      "364 4.386579166748561e-05\n",
      "365 4.323647954151966e-05\n",
      "366 4.261646608938463e-05\n",
      "367 4.2002804548246786e-05\n",
      "368 4.1396968299522996e-05\n",
      "369 4.080462531419471e-05\n",
      "370 4.0217481000581756e-05\n",
      "371 3.963660492445342e-05\n",
      "372 3.907102654920891e-05\n",
      "373 3.85111452487763e-05\n",
      "374 3.795369411818683e-05\n",
      "375 3.740972897503525e-05\n",
      "376 3.687216303660534e-05\n",
      "377 3.63409380952362e-05\n",
      "378 3.5821565688820556e-05\n",
      "379 3.530352842062712e-05\n",
      "380 3.4796452382579446e-05\n",
      "381 3.429731077631004e-05\n",
      "382 3.3804477425292134e-05\n",
      "383 3.331873449496925e-05\n",
      "384 3.284099875600077e-05\n",
      "385 3.236837073927745e-05\n",
      "386 3.190261486452073e-05\n",
      "387 3.1441548344446346e-05\n",
      "388 3.099434616160579e-05\n",
      "389 3.0545856134267524e-05\n",
      "390 3.010653381352313e-05\n",
      "391 2.9676564736291766e-05\n",
      "392 2.9246395570226014e-05\n",
      "393 2.882840999518521e-05\n",
      "394 2.8413283871486783e-05\n",
      "395 2.8005781132378615e-05\n",
      "396 2.7604733986663632e-05\n",
      "397 2.7206890081288293e-05\n",
      "398 2.6815392629941925e-05\n",
      "399 2.642971958266571e-05\n",
      "400 2.6048919608001597e-05\n",
      "401 2.567662340879906e-05\n",
      "402 2.530686469981447e-05\n",
      "403 2.4940803996287286e-05\n",
      "404 2.458634480717592e-05\n",
      "405 2.4233280782937072e-05\n",
      "406 2.388376378803514e-05\n",
      "407 2.354002936044708e-05\n",
      "408 2.3202566808322445e-05\n",
      "409 2.2869071472086944e-05\n",
      "410 2.2541164071299136e-05\n",
      "411 2.221617251052521e-05\n",
      "412 2.1898165869060904e-05\n",
      "413 2.1582047338597476e-05\n",
      "414 2.1272247977321967e-05\n",
      "415 2.0965759176760912e-05\n",
      "416 2.0665716874646023e-05\n",
      "417 2.0369281628518365e-05\n",
      "418 2.007642251555808e-05\n",
      "419 1.9786592019954696e-05\n",
      "420 1.9502585928421468e-05\n",
      "421 1.9222034097765572e-05\n",
      "422 1.8946935597341508e-05\n",
      "423 1.8673439626581967e-05\n",
      "424 1.8406175513518974e-05\n",
      "425 1.8138487575924955e-05\n",
      "426 1.7881480744108558e-05\n",
      "427 1.7622287487029098e-05\n",
      "428 1.736958438414149e-05\n",
      "429 1.7120877600973472e-05\n",
      "430 1.687444091658108e-05\n",
      "431 1.6631682228762656e-05\n",
      "432 1.639163019717671e-05\n",
      "433 1.6156707715708762e-05\n",
      "434 1.5923718819976784e-05\n",
      "435 1.5694949979661033e-05\n",
      "436 1.5470923244720325e-05\n",
      "437 1.5247148439812008e-05\n",
      "438 1.50269179357565e-05\n",
      "439 1.4812652807449922e-05\n",
      "440 1.4598261259379797e-05\n",
      "441 1.4391493095899932e-05\n",
      "442 1.4182809536578134e-05\n",
      "443 1.3979562027088832e-05\n",
      "444 1.3778214452031534e-05\n",
      "445 1.3582181964011397e-05\n",
      "446 1.338426136499038e-05\n",
      "447 1.3193278391554486e-05\n",
      "448 1.3002415471419226e-05\n",
      "449 1.2818350114685018e-05\n",
      "450 1.2631675417651422e-05\n",
      "451 1.2450776921468787e-05\n",
      "452 1.227057509822771e-05\n",
      "453 1.2095626516384073e-05\n",
      "454 1.1919726603082381e-05\n",
      "455 1.1750992598535959e-05\n",
      "456 1.1580399586819112e-05\n",
      "457 1.1415469089115504e-05\n",
      "458 1.1249869203311391e-05\n",
      "459 1.1089350664406084e-05\n",
      "460 1.0930373719020281e-05\n",
      "461 1.0772258065117057e-05\n",
      "462 1.061775219568517e-05\n",
      "463 1.0465400919201784e-05\n",
      "464 1.0315738109056838e-05\n",
      "465 1.0166873835260049e-05\n",
      "466 1.0020658010034822e-05\n",
      "467 9.876686817733571e-06\n",
      "468 9.733850674820133e-06\n",
      "469 9.594662515155505e-06\n",
      "470 9.456568477617111e-06\n",
      "471 9.31983049667906e-06\n",
      "472 9.188051080855075e-06\n",
      "473 9.053454050444998e-06\n",
      "474 8.924533176468685e-06\n",
      "475 8.797230293566827e-06\n",
      "476 8.67024118633708e-06\n",
      "477 8.545961463823915e-06\n",
      "478 8.42308236315148e-06\n",
      "479 8.299840374093037e-06\n",
      "480 8.182573765225243e-06\n",
      "481 8.06416392151732e-06\n",
      "482 7.948747224872932e-06\n",
      "483 7.833918061805889e-06\n",
      "484 7.721298970864154e-06\n",
      "485 7.609974090883043e-06\n",
      "486 7.501369509554934e-06\n",
      "487 7.393073246930726e-06\n",
      "488 7.286346772161778e-06\n",
      "489 7.18320097803371e-06\n",
      "490 7.07908930053236e-06\n",
      "491 6.978270903346129e-06\n",
      "492 6.876501174701843e-06\n",
      "493 6.777671387681039e-06\n",
      "494 6.680834303551819e-06\n",
      "495 6.585140909010079e-06\n",
      "496 6.490731720987242e-06\n",
      "497 6.397518518497236e-06\n",
      "498 6.304980161075946e-06\n",
      "499 6.213623237272259e-06\n",
      "500 6.126168045739178e-06\n",
      "501 6.037120328983292e-06\n",
      "502 5.951064849796239e-06\n",
      "503 5.863869319000514e-06\n",
      "504 5.780178980785422e-06\n",
      "505 5.6985486480698455e-06\n",
      "506 5.616327143798117e-06\n",
      "507 5.53504560230067e-06\n",
      "508 5.455240170704201e-06\n",
      "509 5.376686658564722e-06\n",
      "510 5.29937278770376e-06\n",
      "511 5.223748757998692e-06\n",
      "512 5.1490628720785026e-06\n",
      "513 5.074784894532058e-06\n",
      "514 5.001892077416414e-06\n",
      "515 4.930171144224005e-06\n",
      "516 4.858391548623331e-06\n",
      "517 4.7884122977848165e-06\n",
      "518 4.720137894764775e-06\n",
      "519 4.652417828765465e-06\n",
      "520 4.584627731674118e-06\n",
      "521 4.520114089245908e-06\n",
      "522 4.455690032045823e-06\n",
      "523 4.390389221953228e-06\n",
      "524 4.327566784922965e-06\n",
      "525 4.2667556954256725e-06\n",
      "526 4.203694970783545e-06\n",
      "527 4.1438242988078855e-06\n",
      "528 4.083794920006767e-06\n",
      "529 4.025195266876835e-06\n",
      "530 3.967425072914921e-06\n",
      "531 3.91041612601839e-06\n",
      "532 3.854790520563256e-06\n",
      "533 3.7992242596374126e-06\n",
      "534 3.744455625565024e-06\n",
      "535 3.690418225232861e-06\n",
      "536 3.6375502077135025e-06\n",
      "537 3.585614422263461e-06\n",
      "538 3.5335051506990567e-06\n",
      "539 3.4834044981835177e-06\n",
      "540 3.4324782518524444e-06\n",
      "541 3.3839567095128587e-06\n",
      "542 3.335675273774541e-06\n",
      "543 3.2870559607545147e-06\n",
      "544 3.2395262223872123e-06\n",
      "545 3.1932263482303824e-06\n",
      "546 3.148031737509882e-06\n",
      "547 3.1018803383631166e-06\n",
      "548 3.0577471079595853e-06\n",
      "549 3.01327327179024e-06\n",
      "550 2.9700768209295347e-06\n",
      "551 2.928386720668641e-06\n",
      "552 2.885411504394142e-06\n",
      "553 2.8446156647987664e-06\n",
      "554 2.8032345653628e-06\n",
      "555 2.763413249340374e-06\n",
      "556 2.7234452772972872e-06\n",
      "557 2.6842451461561723e-06\n",
      "558 2.6452810288901674e-06\n",
      "559 2.6080097086378373e-06\n",
      "560 2.5709102828841424e-06\n",
      "561 2.5334759357065195e-06\n",
      "562 2.4973248855530983e-06\n",
      "563 2.4610242235212354e-06\n",
      "564 2.4254422896774486e-06\n",
      "565 2.3912864435260417e-06\n",
      "566 2.356793629587628e-06\n",
      "567 2.3224631604534807e-06\n",
      "568 2.289219992235303e-06\n",
      "569 2.2568281110579846e-06\n",
      "570 2.224104036940844e-06\n",
      "571 2.192048441429506e-06\n",
      "572 2.160353915314772e-06\n",
      "573 2.1294843008945463e-06\n",
      "574 2.0989634776924504e-06\n",
      "575 2.068787125608651e-06\n",
      "576 2.038746970356442e-06\n",
      "577 2.009050376727828e-06\n",
      "578 1.9806350337603362e-06\n",
      "579 1.9518934095685836e-06\n",
      "580 1.924692924148985e-06\n",
      "581 1.8970429209730355e-06\n",
      "582 1.8692353478400037e-06\n",
      "583 1.8427774648444029e-06\n",
      "584 1.8160385479859542e-06\n",
      "585 1.7897275483846897e-06\n",
      "586 1.7642259990680031e-06\n",
      "587 1.7395595932612196e-06\n",
      "588 1.713849314910476e-06\n",
      "589 1.6889737253222847e-06\n",
      "590 1.6653273178235395e-06\n",
      "591 1.6409180716436822e-06\n",
      "592 1.6173910353245446e-06\n",
      "593 1.5940715911710868e-06\n",
      "594 1.5716494772277656e-06\n",
      "595 1.5488794815610163e-06\n",
      "596 1.5258451639965642e-06\n",
      "597 1.504479996583541e-06\n",
      "598 1.4830536656518234e-06\n",
      "599 1.4613597159041092e-06\n",
      "600 1.4404523653865908e-06\n",
      "601 1.4200771829564474e-06\n",
      "602 1.3995033896208042e-06\n",
      "603 1.3792162008030573e-06\n",
      "604 1.3594162737717852e-06\n",
      "605 1.339995378657477e-06\n",
      "606 1.3212145404395415e-06\n",
      "607 1.301870497627533e-06\n",
      "608 1.283294068343821e-06\n",
      "609 1.2644266007555416e-06\n",
      "610 1.2466722409953945e-06\n",
      "611 1.229140252689831e-06\n",
      "612 1.2105806490581017e-06\n",
      "613 1.1941301636397839e-06\n",
      "614 1.17637364382972e-06\n",
      "615 1.1599709068832453e-06\n",
      "616 1.1424094736867119e-06\n",
      "617 1.126770484916051e-06\n",
      "618 1.110259972847416e-06\n",
      "619 1.0942344488285016e-06\n",
      "620 1.0788392046379158e-06\n",
      "621 1.0630737961037084e-06\n",
      "622 1.0477222076588077e-06\n",
      "623 1.0326002666261047e-06\n",
      "624 1.0181453262703144e-06\n",
      "625 1.0035007562692044e-06\n",
      "626 9.889624834613642e-07\n",
      "627 9.74932163444464e-07\n",
      "628 9.610022289052722e-07\n",
      "629 9.470027748648135e-07\n",
      "630 9.336397965853394e-07\n",
      "631 9.200373938256234e-07\n",
      "632 9.065064432434156e-07\n",
      "633 8.934605943977658e-07\n",
      "634 8.807546691969037e-07\n",
      "635 8.681670919941098e-07\n",
      "636 8.5567012320098e-07\n",
      "637 8.431040896539344e-07\n",
      "638 8.309751819979283e-07\n",
      "639 8.190912694772123e-07\n",
      "640 8.074761694842891e-07\n",
      "641 7.960220500535797e-07\n",
      "642 7.848301493140752e-07\n",
      "643 7.733081019978272e-07\n",
      "644 7.623027613590239e-07\n",
      "645 7.512001047871308e-07\n",
      "646 7.40354266781651e-07\n",
      "647 7.296610533558123e-07\n",
      "648 7.195142757154827e-07\n",
      "649 7.092183977874811e-07\n",
      "650 6.991668897171621e-07\n",
      "651 6.888008101668674e-07\n",
      "652 6.789673534512985e-07\n",
      "653 6.695375986964791e-07\n",
      "654 6.597018114007369e-07\n",
      "655 6.49938215246948e-07\n",
      "656 6.408524768630741e-07\n",
      "657 6.314611482594046e-07\n",
      "658 6.227356266208517e-07\n",
      "659 6.137972832220839e-07\n",
      "660 6.04991328145843e-07\n",
      "661 5.963163971500762e-07\n",
      "662 5.877933517695055e-07\n",
      "663 5.790446948594763e-07\n",
      "664 5.710629693567171e-07\n",
      "665 5.625703352052369e-07\n",
      "666 5.542279382098059e-07\n",
      "667 5.468504014061182e-07\n",
      "668 5.391808031163237e-07\n",
      "669 5.308869504005997e-07\n",
      "670 5.232044486547238e-07\n",
      "671 5.15849023940973e-07\n",
      "672 5.084219196760387e-07\n",
      "673 5.009654273635533e-07\n",
      "674 4.940339408676664e-07\n",
      "675 4.865628966399527e-07\n",
      "676 4.802564603778592e-07\n",
      "677 4.727103828372492e-07\n",
      "678 4.6631572558908374e-07\n",
      "679 4.5939287929286365e-07\n",
      "680 4.532849402494321e-07\n",
      "681 4.462856963982631e-07\n",
      "682 4.398794999360689e-07\n",
      "683 4.3396096316428157e-07\n",
      "684 4.2730226823550765e-07\n",
      "685 4.213554802845465e-07\n",
      "686 4.154506427767046e-07\n",
      "687 4.0947560364656965e-07\n",
      "688 4.0319315530723543e-07\n",
      "689 3.977288542955648e-07\n",
      "690 3.923019562535046e-07\n",
      "691 3.8633402255072724e-07\n",
      "692 3.805382107202604e-07\n",
      "693 3.7533601471295697e-07\n",
      "694 3.698875730151485e-07\n",
      "695 3.6460204455579515e-07\n",
      "696 3.5947670085079153e-07\n",
      "697 3.5398949194132e-07\n",
      "698 3.4911118973468547e-07\n",
      "699 3.4426676620569197e-07\n",
      "700 3.3918496455953573e-07\n",
      "701 3.341411343171785e-07\n",
      "702 3.295187980256742e-07\n",
      "703 3.247135396122758e-07\n",
      "704 3.201404297215049e-07\n",
      "705 3.155184913339326e-07\n",
      "706 3.112380113634572e-07\n",
      "707 3.0661658456665464e-07\n",
      "708 3.0218944857551833e-07\n",
      "709 2.978580937451625e-07\n",
      "710 2.938577381428331e-07\n",
      "711 2.8942952212673845e-07\n",
      "712 2.853460614460346e-07\n",
      "713 2.8129159090894973e-07\n",
      "714 2.773120399979234e-07\n",
      "715 2.731178483372787e-07\n",
      "716 2.690618430278846e-07\n",
      "717 2.654537638591137e-07\n",
      "718 2.6155908017244656e-07\n",
      "719 2.5776603251870256e-07\n",
      "720 2.542502670621616e-07\n",
      "721 2.5042390916496515e-07\n",
      "722 2.469589048814669e-07\n",
      "723 2.432883547953679e-07\n",
      "724 2.397449634372606e-07\n",
      "725 2.3649620572996355e-07\n",
      "726 2.3300276552618016e-07\n",
      "727 2.2967469703871757e-07\n",
      "728 2.2637073016085196e-07\n",
      "729 2.2309086489258334e-07\n",
      "730 2.197796789005224e-07\n",
      "731 2.1680502015897218e-07\n",
      "732 2.1351445411710301e-07\n",
      "733 2.1050237819508766e-07\n",
      "734 2.0763123131928296e-07\n",
      "735 2.0475346218518098e-07\n",
      "736 2.015950713030179e-07\n",
      "737 1.987596220942578e-07\n",
      "738 1.9598269318521488e-07\n",
      "739 1.9322534683396952e-07\n",
      "740 1.9037283038869646e-07\n",
      "741 1.8754180075575277e-07\n",
      "742 1.8493211939585308e-07\n",
      "743 1.8242764099341002e-07\n",
      "744 1.7965680854103994e-07\n",
      "745 1.7703003152291785e-07\n",
      "746 1.743365487527626e-07\n",
      "747 1.719770921226882e-07\n",
      "748 1.69550460782375e-07\n",
      "749 1.6716444406483788e-07\n",
      "750 1.648546685828478e-07\n",
      "751 1.6245543577042554e-07\n",
      "752 1.601085841684835e-07\n",
      "753 1.5774431005866063e-07\n",
      "754 1.555120689999967e-07\n",
      "755 1.532160922579351e-07\n",
      "756 1.5101625194802182e-07\n",
      "757 1.4891084276769107e-07\n",
      "758 1.4677563342502253e-07\n",
      "759 1.44700152304722e-07\n",
      "760 1.4267250492139283e-07\n",
      "761 1.4045247098692926e-07\n",
      "762 1.384110106528169e-07\n",
      "763 1.3650340235926706e-07\n",
      "764 1.3453377789574006e-07\n",
      "765 1.3281221811212163e-07\n",
      "766 1.3084837746646372e-07\n",
      "767 1.287847908315598e-07\n",
      "768 1.2700691343070503e-07\n",
      "769 1.2528279569323786e-07\n",
      "770 1.2352967360129696e-07\n",
      "771 1.2169698493380565e-07\n",
      "772 1.1987805237367866e-07\n",
      "773 1.1823317436210345e-07\n",
      "774 1.1669881416764838e-07\n",
      "775 1.1498661933728727e-07\n",
      "776 1.1313052539208002e-07\n",
      "777 1.1162956070620567e-07\n",
      "778 1.1013874257059797e-07\n",
      "779 1.0838978425908863e-07\n",
      "780 1.0676905048967456e-07\n",
      "781 1.0549007356530637e-07\n",
      "782 1.0380654202890582e-07\n",
      "783 1.0224800917058019e-07\n",
      "784 1.0095062918935582e-07\n",
      "785 9.935894240697962e-08\n",
      "786 9.804382727907068e-08\n",
      "787 9.66557536230539e-08\n",
      "788 9.524190147658373e-08\n",
      "789 9.387419197537383e-08\n",
      "790 9.254291910565371e-08\n",
      "791 9.12211959303022e-08\n",
      "792 8.99349998917387e-08\n",
      "793 8.869267276168102e-08\n",
      "794 8.732099843200558e-08\n",
      "795 8.612232704763301e-08\n",
      "796 8.490668790273048e-08\n",
      "797 8.358995273738401e-08\n",
      "798 8.247570804087445e-08\n",
      "799 8.131094375585235e-08\n",
      "800 8.005572738056799e-08\n",
      "801 7.896541376339883e-08\n",
      "802 7.77532278561921e-08\n",
      "803 7.664608858704014e-08\n",
      "804 7.560335291145748e-08\n",
      "805 7.434670123984688e-08\n",
      "806 7.344455354996171e-08\n",
      "807 7.235394150484353e-08\n",
      "808 7.121646206087462e-08\n",
      "809 7.0234250415524e-08\n",
      "810 6.943588459762395e-08\n",
      "811 6.830606480434653e-08\n",
      "812 6.73973090670188e-08\n",
      "813 6.649503347944119e-08\n",
      "814 6.536004093504744e-08\n",
      "815 6.440480149194627e-08\n",
      "816 6.354470372116339e-08\n",
      "817 6.271994834605721e-08\n",
      "818 6.185621259646723e-08\n",
      "819 6.08117289857546e-08\n",
      "820 6.002596819598693e-08\n",
      "821 5.9181104461458744e-08\n",
      "822 5.83422661293298e-08\n",
      "823 5.75094531996001e-08\n",
      "824 5.668266567226965e-08\n",
      "825 5.586190354733844e-08\n",
      "826 5.504716682480648e-08\n",
      "827 5.417787463102286e-08\n",
      "828 5.350314324914507e-08\n",
      "829 5.275279590932769e-08\n",
      "830 5.193425067773205e-08\n",
      "831 5.121474089264666e-08\n",
      "832 5.037674100094591e-08\n",
      "833 4.9686889269651147e-08\n",
      "834 4.893770721992041e-08\n",
      "835 4.823925792152295e-08\n",
      "836 4.756464022648288e-08\n",
      "837 4.689502475230256e-08\n",
      "838 4.6254911012511e-08\n",
      "839 4.5594617859023856e-08\n",
      "840 4.498242844874767e-08\n",
      "841 4.431853994901758e-08\n",
      "842 4.367211658973247e-08\n",
      "843 4.3072887478956545e-08\n",
      "844 4.249579887982691e-08\n",
      "845 4.1826993424365355e-08\n",
      "846 4.124080987821799e-08\n",
      "847 4.0717281990509946e-08\n",
      "848 4.01032593799755e-08\n",
      "849 3.954660598992632e-08\n",
      "850 3.894150779615302e-08\n",
      "851 3.843281604076765e-08\n",
      "852 3.7875906855333596e-08\n",
      "853 3.7374206840468105e-08\n",
      "854 3.6786104828934185e-08\n",
      "855 3.62415022436835e-08\n",
      "856 3.5767087069871195e-08\n",
      "857 3.523018676787615e-08\n",
      "858 3.469752130058623e-08\n",
      "859 3.423333794216887e-08\n",
      "860 3.3708374758134596e-08\n",
      "861 3.320373309634306e-08\n",
      "862 3.274891469118302e-08\n",
      "863 3.237124701627181e-08\n",
      "864 3.186075048233761e-08\n",
      "865 3.137012072329526e-08\n",
      "866 3.0897808755980805e-08\n",
      "867 3.0429248454311164e-08\n",
      "868 3.00099287642297e-08\n",
      "869 2.960314304800704e-08\n",
      "870 2.916476660175249e-08\n",
      "871 2.87885200123128e-08\n",
      "872 2.8356055281619774e-08\n",
      "873 2.7941396751884895e-08\n",
      "874 2.751058048033883e-08\n",
      "875 2.7102373678644653e-08\n",
      "876 2.67880437831991e-08\n",
      "877 2.6403370156913297e-08\n",
      "878 2.6017531240540848e-08\n",
      "879 2.5578472673259967e-08\n",
      "880 2.527303877286613e-08\n",
      "881 2.494527961971471e-08\n",
      "882 2.4570240952925815e-08\n",
      "883 2.4216220140260702e-08\n",
      "884 2.3806094873179973e-08\n",
      "885 2.3542511939922406e-08\n",
      "886 2.320923897514149e-08\n",
      "887 2.2878353433952725e-08\n",
      "888 2.249250030672556e-08\n",
      "889 2.2236534391595342e-08\n",
      "890 2.194275339206797e-08\n",
      "891 2.1582039266831998e-08\n",
      "892 2.127553955233452e-08\n",
      "893 2.0988181859138422e-08\n",
      "894 2.070278526389302e-08\n",
      "895 2.043168478849111e-08\n",
      "896 2.0083930962755403e-08\n",
      "897 1.9816980056930333e-08\n",
      "898 1.9539655227163166e-08\n",
      "899 1.927639914356405e-08\n",
      "900 1.8938990820061008e-08\n",
      "901 1.867988430603873e-08\n",
      "902 1.8422625203129428e-08\n",
      "903 1.8120616118721955e-08\n",
      "904 1.7850766198534984e-08\n",
      "905 1.768790980349877e-08\n",
      "906 1.7376422078996256e-08\n",
      "907 1.7094819781959814e-08\n",
      "908 1.6907861777326616e-08\n",
      "909 1.66295563985841e-08\n",
      "910 1.6397635249632003e-08\n",
      "911 1.6182426065824984e-08\n",
      "912 1.5921457929835015e-08\n",
      "913 1.5694311628067226e-08\n",
      "914 1.550921524540172e-08\n",
      "915 1.517088321634219e-08\n",
      "916 1.5031403677312483e-08\n",
      "917 1.4804072634433396e-08\n",
      "918 1.458556653233245e-08\n",
      "919 1.4417494753615756e-08\n",
      "920 1.4115414614934707e-08\n",
      "921 1.3991567016091722e-08\n",
      "922 1.3785680152977875e-08\n",
      "923 1.3608882909466047e-08\n",
      "924 1.3379249708123098e-08\n",
      "925 1.3218951266935619e-08\n",
      "926 1.3005148957745405e-08\n",
      "927 1.2803695881302701e-08\n",
      "928 1.268649896246643e-08\n",
      "929 1.2447586072994454e-08\n",
      "930 1.229251722634217e-08\n",
      "931 1.2096691648366686e-08\n",
      "932 1.1953616763094033e-08\n",
      "933 1.1760519669223868e-08\n",
      "934 1.1628870311142236e-08\n",
      "935 1.1471740890556248e-08\n",
      "936 1.1282565992587479e-08\n",
      "937 1.1144322797917994e-08\n",
      "938 1.0908991043834249e-08\n",
      "939 1.0843010045391566e-08\n",
      "940 1.0640462733135791e-08\n",
      "941 1.0506312264624285e-08\n",
      "942 1.034597119087266e-08\n",
      "943 1.0243013548461022e-08\n",
      "944 1.0037595643552777e-08\n",
      "945 9.983125437429408e-09\n",
      "946 9.780151799532177e-09\n",
      "947 9.68003632806358e-09\n",
      "948 9.480416451879137e-09\n",
      "949 9.381722065882059e-09\n",
      "950 9.238490861207538e-09\n",
      "951 9.152373081633414e-09\n",
      "952 8.966537734522717e-09\n",
      "953 8.870543410921528e-09\n",
      "954 8.698819442543027e-09\n",
      "955 8.604104095866205e-09\n",
      "956 8.467125667266373e-09\n",
      "957 8.384418492823897e-09\n",
      "958 8.2255979805268e-09\n",
      "959 8.133440587698715e-09\n",
      "960 7.977462246344658e-09\n",
      "961 7.88658383044094e-09\n",
      "962 7.733447660029924e-09\n",
      "963 7.642896093784657e-09\n",
      "964 7.513904165534768e-09\n",
      "965 7.403627932944801e-09\n",
      "966 7.294261195056606e-09\n",
      "967 7.175060545705492e-09\n",
      "968 7.106166322046192e-09\n",
      "969 6.977487032600038e-09\n",
      "970 6.899384175085288e-09\n",
      "971 6.800760843361786e-09\n",
      "972 6.6958278921447345e-09\n",
      "973 6.6083885030820966e-09\n",
      "974 6.494985882454785e-09\n",
      "975 6.445830535994901e-09\n",
      "976 6.314124334494409e-09\n",
      "977 6.255845619307365e-09\n",
      "978 6.1189666666905396e-09\n",
      "979 6.0258145140323904e-09\n",
      "980 5.985214102111058e-09\n",
      "981 5.867164531991875e-09\n",
      "982 5.802192504233972e-09\n",
      "983 5.6858198149711825e-09\n",
      "984 5.602501573775953e-09\n",
      "985 5.548372428165749e-09\n",
      "986 5.4898237067391165e-09\n",
      "987 5.376548983804241e-09\n",
      "988 5.329468422132777e-09\n",
      "989 5.224208621257276e-09\n",
      "990 5.1380766308284365e-09\n",
      "991 5.107096967549296e-09\n",
      "992 5.003542469239619e-09\n",
      "993 4.9338524377162685e-09\n",
      "994 4.889727733825566e-09\n",
      "995 4.769901806866983e-09\n",
      "996 4.7398316382896155e-09\n",
      "997 4.671917963605665e-09\n",
      "998 4.578978973768244e-09\n",
      "999 4.544077114587708e-09\n",
      "w= 2.000044822692871\n",
      "b= -0.0001018988186842762\n",
      "y_pred= 8.000077247619629\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "# torch中训练都是采用的mini-batch的形式，所以x_data和y_data都是批量的数据样本和数据样本所对应的标签\n",
    "x_data = torch.Tensor([[1.0], [2.0], [3.0]])\n",
    "y_data = torch.Tensor([[2.0], [4.0], [6.0]])\n",
    "\n",
    "class LinearModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "\n",
    "model = LinearModel()\n",
    "criterion = torch.nn.MSELoss(size_average=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# training cycle\n",
    "for epoch in range(1000):\n",
    "    y_pred = model(x_data)\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    print(epoch, loss.item())\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "# output weight and bias\n",
    "print('w=', model.linear.weight.item())\n",
    "print('b=', model.linear.bias.item())\n",
    "\n",
    "# Test Model\n",
    "x_test = torch.Tensor([[4.0]])\n",
    "y_test = model(x_test)\n",
    "print('y_pred=', y_test.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- exercise\n",
    "    - Try different optimizer in linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 0 loss= 46.67709732055664\n",
      "epoch= 1 loss= 42.534996032714844\n",
      "epoch= 2 loss= 38.59195327758789\n",
      "epoch= 3 loss= 34.851139068603516\n",
      "epoch= 4 loss= 31.31512451171875\n",
      "epoch= 5 loss= 27.985877990722656\n",
      "epoch= 6 loss= 24.864675521850586\n",
      "epoch= 7 loss= 21.952035903930664\n",
      "epoch= 8 loss= 19.24767303466797\n",
      "epoch= 9 loss= 16.750417709350586\n",
      "epoch= 10 loss= 14.458176612854004\n",
      "epoch= 11 loss= 12.367890357971191\n",
      "epoch= 12 loss= 10.475485801696777\n",
      "epoch= 13 loss= 8.775863647460938\n",
      "epoch= 14 loss= 7.262878894805908\n",
      "epoch= 15 loss= 5.929358959197998\n",
      "epoch= 16 loss= 4.767119884490967\n",
      "epoch= 17 loss= 3.767026901245117\n",
      "epoch= 18 loss= 2.9190616607666016\n",
      "epoch= 19 loss= 2.212418556213379\n",
      "epoch= 20 loss= 1.6356292963027954\n",
      "epoch= 21 loss= 1.176705002784729\n",
      "epoch= 22 loss= 0.8233003616333008\n",
      "epoch= 23 loss= 0.562894880771637\n",
      "epoch= 24 loss= 0.38298091292381287\n",
      "epoch= 25 loss= 0.27126389741897583\n",
      "epoch= 26 loss= 0.21585078537464142\n",
      "epoch= 27 loss= 0.2054356187582016\n",
      "epoch= 28 loss= 0.22946542501449585\n",
      "epoch= 29 loss= 0.27828314900398254\n",
      "epoch= 30 loss= 0.3432431221008301\n",
      "epoch= 31 loss= 0.41679200530052185\n",
      "epoch= 32 loss= 0.49251845479011536\n",
      "epoch= 33 loss= 0.5651652812957764\n",
      "epoch= 34 loss= 0.6306107044219971\n",
      "epoch= 35 loss= 0.6858187317848206\n",
      "epoch= 36 loss= 0.7287622094154358\n",
      "epoch= 37 loss= 0.7583277225494385\n",
      "epoch= 38 loss= 0.7742020487785339\n",
      "epoch= 39 loss= 0.7767488360404968\n",
      "epoch= 40 loss= 0.7668842673301697\n",
      "epoch= 41 loss= 0.7459457516670227\n",
      "epoch= 42 loss= 0.7155720591545105\n",
      "epoch= 43 loss= 0.6775867342948914\n",
      "epoch= 44 loss= 0.6338950991630554\n",
      "epoch= 45 loss= 0.5863929390907288\n",
      "epoch= 46 loss= 0.5368890166282654\n",
      "epoch= 47 loss= 0.48704397678375244\n",
      "epoch= 48 loss= 0.4383230209350586\n",
      "epoch= 49 loss= 0.3919638395309448\n",
      "epoch= 50 loss= 0.34895798563957214\n",
      "epoch= 51 loss= 0.31004515290260315\n",
      "epoch= 52 loss= 0.2757178843021393\n",
      "epoch= 53 loss= 0.24623608589172363\n",
      "epoch= 54 loss= 0.2216479331254959\n",
      "epoch= 55 loss= 0.2018185257911682\n",
      "epoch= 56 loss= 0.18646003305912018\n",
      "epoch= 57 loss= 0.17516469955444336\n",
      "epoch= 58 loss= 0.1674390584230423\n",
      "epoch= 59 loss= 0.16273559629917145\n",
      "epoch= 60 loss= 0.16048301756381989\n",
      "epoch= 61 loss= 0.16011331975460052\n",
      "epoch= 62 loss= 0.16108427941799164\n",
      "epoch= 63 loss= 0.16289876401424408\n",
      "epoch= 64 loss= 0.1651180535554886\n",
      "epoch= 65 loss= 0.16737127304077148\n",
      "epoch= 66 loss= 0.1693604588508606\n",
      "epoch= 67 loss= 0.17086128890514374\n",
      "epoch= 68 loss= 0.17172139883041382\n",
      "epoch= 69 loss= 0.17185454070568085\n",
      "epoch= 70 loss= 0.1712328940629959\n",
      "epoch= 71 loss= 0.16987864673137665\n",
      "epoch= 72 loss= 0.16785390675067902\n",
      "epoch= 73 loss= 0.16524982452392578\n",
      "epoch= 74 loss= 0.1621781587600708\n",
      "epoch= 75 loss= 0.15876008570194244\n",
      "epoch= 76 loss= 0.1551191359758377\n",
      "epoch= 77 loss= 0.15137380361557007\n",
      "epoch= 78 loss= 0.14763212203979492\n",
      "epoch= 79 loss= 0.14398722350597382\n",
      "epoch= 80 loss= 0.14051441848278046\n",
      "epoch= 81 loss= 0.13727062940597534\n",
      "epoch= 82 loss= 0.134293794631958\n",
      "epoch= 83 loss= 0.13160328567028046\n",
      "epoch= 84 loss= 0.12920258939266205\n",
      "epoch= 85 loss= 0.1270807981491089\n",
      "epoch= 86 loss= 0.12521637976169586\n",
      "epoch= 87 loss= 0.1235785260796547\n",
      "epoch= 88 loss= 0.12213162332773209\n",
      "epoch= 89 loss= 0.1208372712135315\n",
      "epoch= 90 loss= 0.11965649574995041\n",
      "epoch= 91 loss= 0.11855246871709824\n",
      "epoch= 92 loss= 0.11749172955751419\n",
      "epoch= 93 loss= 0.11644536256790161\n",
      "epoch= 94 loss= 0.11539005488157272\n",
      "epoch= 95 loss= 0.11430831998586655\n",
      "epoch= 96 loss= 0.11318830400705338\n",
      "epoch= 97 loss= 0.11202362924814224\n",
      "epoch= 98 loss= 0.11081249266862869\n",
      "epoch= 99 loss= 0.1095573902130127\n",
      "epoch= 100 loss= 0.10826387256383896\n",
      "epoch= 101 loss= 0.10693946480751038\n",
      "epoch= 102 loss= 0.10559353977441788\n",
      "epoch= 103 loss= 0.1042354628443718\n",
      "epoch= 104 loss= 0.10287511348724365\n",
      "epoch= 105 loss= 0.10152091830968857\n",
      "epoch= 106 loss= 0.10018066316843033\n",
      "epoch= 107 loss= 0.09886030107736588\n",
      "epoch= 108 loss= 0.09756457060575485\n",
      "epoch= 109 loss= 0.09629625082015991\n",
      "epoch= 110 loss= 0.09505677968263626\n",
      "epoch= 111 loss= 0.0938461646437645\n",
      "epoch= 112 loss= 0.0926632285118103\n",
      "epoch= 113 loss= 0.09150584787130356\n",
      "epoch= 114 loss= 0.09037155658006668\n",
      "epoch= 115 loss= 0.08925702422857285\n",
      "epoch= 116 loss= 0.08815944939851761\n",
      "epoch= 117 loss= 0.0870756283402443\n",
      "epoch= 118 loss= 0.0860028862953186\n",
      "epoch= 119 loss= 0.08493868261575699\n",
      "epoch= 120 loss= 0.08388151973485947\n",
      "epoch= 121 loss= 0.08282968401908875\n",
      "epoch= 122 loss= 0.08178264647722244\n",
      "epoch= 123 loss= 0.08073986321687698\n",
      "epoch= 124 loss= 0.07970140129327774\n",
      "epoch= 125 loss= 0.07866768538951874\n",
      "epoch= 126 loss= 0.07763911783695221\n",
      "epoch= 127 loss= 0.07661686837673187\n",
      "epoch= 128 loss= 0.07560145109891891\n",
      "epoch= 129 loss= 0.0745939314365387\n",
      "epoch= 130 loss= 0.07359505444765091\n",
      "epoch= 131 loss= 0.07260533422231674\n",
      "epoch= 132 loss= 0.07162544876337051\n",
      "epoch= 133 loss= 0.07065600901842117\n",
      "epoch= 134 loss= 0.06969695538282394\n",
      "epoch= 135 loss= 0.0687485784292221\n",
      "epoch= 136 loss= 0.06781069934368134\n",
      "epoch= 137 loss= 0.06688333302736282\n",
      "epoch= 138 loss= 0.06596603244543076\n",
      "epoch= 139 loss= 0.06505880504846573\n",
      "epoch= 140 loss= 0.06416118144989014\n",
      "epoch= 141 loss= 0.06327280402183533\n",
      "epoch= 142 loss= 0.06239365041255951\n",
      "epoch= 143 loss= 0.06152314320206642\n",
      "epoch= 144 loss= 0.06066126748919487\n",
      "epoch= 145 loss= 0.05980789288878441\n",
      "epoch= 146 loss= 0.05896281078457832\n",
      "epoch= 147 loss= 0.05812600255012512\n",
      "epoch= 148 loss= 0.05729742348194122\n",
      "epoch= 149 loss= 0.05647711083292961\n",
      "epoch= 150 loss= 0.05566514655947685\n",
      "epoch= 151 loss= 0.05486157909035683\n",
      "epoch= 152 loss= 0.05406630411744118\n",
      "epoch= 153 loss= 0.05327951908111572\n",
      "epoch= 154 loss= 0.05250127986073494\n",
      "epoch= 155 loss= 0.051731571555137634\n",
      "epoch= 156 loss= 0.05097035691142082\n",
      "epoch= 157 loss= 0.05021769925951958\n",
      "epoch= 158 loss= 0.04947357252240181\n",
      "epoch= 159 loss= 0.048737917095422745\n",
      "epoch= 160 loss= 0.04801075533032417\n",
      "epoch= 161 loss= 0.04729190468788147\n",
      "epoch= 162 loss= 0.04658135771751404\n",
      "epoch= 163 loss= 0.04587910696864128\n",
      "epoch= 164 loss= 0.04518510401248932\n",
      "epoch= 165 loss= 0.04449905455112457\n",
      "epoch= 166 loss= 0.043821126222610474\n",
      "epoch= 167 loss= 0.04315115883946419\n",
      "epoch= 168 loss= 0.042489081621170044\n",
      "epoch= 169 loss= 0.04183489456772804\n",
      "epoch= 170 loss= 0.04118843004107475\n",
      "epoch= 171 loss= 0.04054970666766167\n",
      "epoch= 172 loss= 0.03991878777742386\n",
      "epoch= 173 loss= 0.03929554298520088\n",
      "epoch= 174 loss= 0.038679882884025574\n",
      "epoch= 175 loss= 0.03807181864976883\n",
      "epoch= 176 loss= 0.03747129067778587\n",
      "epoch= 177 loss= 0.03687825798988342\n",
      "epoch= 178 loss= 0.03629268705844879\n",
      "epoch= 179 loss= 0.035714514553546906\n",
      "epoch= 180 loss= 0.0351436585187912\n",
      "epoch= 181 loss= 0.034580085426568985\n",
      "epoch= 182 loss= 0.03402381017804146\n",
      "epoch= 183 loss= 0.033474747091531754\n",
      "epoch= 184 loss= 0.03293272852897644\n",
      "epoch= 185 loss= 0.03239782154560089\n",
      "epoch= 186 loss= 0.03186991438269615\n",
      "epoch= 187 loss= 0.031348954886198044\n",
      "epoch= 188 loss= 0.030834900215268135\n",
      "epoch= 189 loss= 0.030327683314681053\n",
      "epoch= 190 loss= 0.029827171936631203\n",
      "epoch= 191 loss= 0.02933350019156933\n",
      "epoch= 192 loss= 0.02884632535278797\n",
      "epoch= 193 loss= 0.028365852311253548\n",
      "epoch= 194 loss= 0.027891887351870537\n",
      "epoch= 195 loss= 0.02742444910109043\n",
      "epoch= 196 loss= 0.026963381096720695\n",
      "epoch= 197 loss= 0.026508668437600136\n",
      "epoch= 198 loss= 0.026060303673148155\n",
      "epoch= 199 loss= 0.025618158280849457\n",
      "epoch= 200 loss= 0.025182267650961876\n",
      "epoch= 201 loss= 0.024752439931035042\n",
      "epoch= 202 loss= 0.024328701198101044\n",
      "epoch= 203 loss= 0.02391103468835354\n",
      "epoch= 204 loss= 0.02349931001663208\n",
      "epoch= 205 loss= 0.023093407973647118\n",
      "epoch= 206 loss= 0.02269342727959156\n",
      "epoch= 207 loss= 0.022299164906144142\n",
      "epoch= 208 loss= 0.02191067673265934\n",
      "epoch= 209 loss= 0.021527795121073723\n",
      "epoch= 210 loss= 0.021150579676032066\n",
      "epoch= 211 loss= 0.020778851583600044\n",
      "epoch= 212 loss= 0.02041260339319706\n",
      "epoch= 213 loss= 0.02005181461572647\n",
      "epoch= 214 loss= 0.019696423783898354\n",
      "epoch= 215 loss= 0.019346287474036217\n",
      "epoch= 216 loss= 0.0190014336258173\n",
      "epoch= 217 loss= 0.01866176724433899\n",
      "epoch= 218 loss= 0.01832723058760166\n",
      "epoch= 219 loss= 0.01799776777625084\n",
      "epoch= 220 loss= 0.01767331175506115\n",
      "epoch= 221 loss= 0.01735386811196804\n",
      "epoch= 222 loss= 0.017039334401488304\n",
      "epoch= 223 loss= 0.01672964356839657\n",
      "epoch= 224 loss= 0.016424721106886864\n",
      "epoch= 225 loss= 0.01612461358308792\n",
      "epoch= 226 loss= 0.0158290546387434\n",
      "epoch= 227 loss= 0.015538248233497143\n",
      "epoch= 228 loss= 0.015251989476382732\n",
      "epoch= 229 loss= 0.01497019361704588\n",
      "epoch= 230 loss= 0.014692944474518299\n",
      "epoch= 231 loss= 0.01442005205899477\n",
      "epoch= 232 loss= 0.01415152009576559\n",
      "epoch= 233 loss= 0.013887271285057068\n",
      "epoch= 234 loss= 0.01362729910761118\n",
      "epoch= 235 loss= 0.013371528126299381\n",
      "epoch= 236 loss= 0.013119899667799473\n",
      "epoch= 237 loss= 0.012872334569692612\n",
      "epoch= 238 loss= 0.012628813274204731\n",
      "epoch= 239 loss= 0.012389292009174824\n",
      "epoch= 240 loss= 0.012153728865087032\n",
      "epoch= 241 loss= 0.011922004632651806\n",
      "epoch= 242 loss= 0.011694114655256271\n",
      "epoch= 243 loss= 0.011470003984868526\n",
      "epoch= 244 loss= 0.011249649338424206\n",
      "epoch= 245 loss= 0.01103299017995596\n",
      "epoch= 246 loss= 0.010819949209690094\n",
      "epoch= 247 loss= 0.010610508732497692\n",
      "epoch= 248 loss= 0.010404587723314762\n",
      "epoch= 249 loss= 0.010202162899076939\n",
      "epoch= 250 loss= 0.010003174655139446\n",
      "epoch= 251 loss= 0.009807555936276913\n",
      "epoch= 252 loss= 0.009615343995392323\n",
      "epoch= 253 loss= 0.00942639634013176\n",
      "epoch= 254 loss= 0.009240721352398396\n",
      "epoch= 255 loss= 0.009058249182999134\n",
      "epoch= 256 loss= 0.008878917433321476\n",
      "epoch= 257 loss= 0.008702713064849377\n",
      "epoch= 258 loss= 0.008529609069228172\n",
      "epoch= 259 loss= 0.008359510451555252\n",
      "epoch= 260 loss= 0.008192439563572407\n",
      "epoch= 261 loss= 0.008028244599699974\n",
      "epoch= 262 loss= 0.007867016829550266\n",
      "epoch= 263 loss= 0.0077086202800273895\n",
      "epoch= 264 loss= 0.007553020026534796\n",
      "epoch= 265 loss= 0.00740024633705616\n",
      "epoch= 266 loss= 0.007250180933624506\n",
      "epoch= 267 loss= 0.0071027870289981365\n",
      "epoch= 268 loss= 0.006958086043596268\n",
      "epoch= 269 loss= 0.0068159862421453\n",
      "epoch= 270 loss= 0.0066764564253389835\n",
      "epoch= 271 loss= 0.006539440248161554\n",
      "epoch= 272 loss= 0.0064049470238387585\n",
      "epoch= 273 loss= 0.006272910628467798\n",
      "epoch= 274 loss= 0.006143280770629644\n",
      "epoch= 275 loss= 0.006016064435243607\n",
      "epoch= 276 loss= 0.005891167093068361\n",
      "epoch= 277 loss= 0.005768595729023218\n",
      "epoch= 278 loss= 0.005648285616189241\n",
      "epoch= 279 loss= 0.005530232563614845\n",
      "epoch= 280 loss= 0.00541435182094574\n",
      "epoch= 281 loss= 0.005300675984472036\n",
      "epoch= 282 loss= 0.005189111921936274\n",
      "epoch= 283 loss= 0.005079662427306175\n",
      "epoch= 284 loss= 0.004972280468791723\n",
      "epoch= 285 loss= 0.004866921808570623\n",
      "epoch= 286 loss= 0.004763568285852671\n",
      "epoch= 287 loss= 0.004662182182073593\n",
      "epoch= 288 loss= 0.004562729503959417\n",
      "epoch= 289 loss= 0.004465168807655573\n",
      "epoch= 290 loss= 0.004369512666016817\n",
      "epoch= 291 loss= 0.004275687504559755\n",
      "epoch= 292 loss= 0.004183665383607149\n",
      "epoch= 293 loss= 0.00409342348575592\n",
      "epoch= 294 loss= 0.004004944581538439\n",
      "epoch= 295 loss= 0.003918163012713194\n",
      "epoch= 296 loss= 0.003833099501207471\n",
      "epoch= 297 loss= 0.0037497018929570913\n",
      "epoch= 298 loss= 0.0036679187323898077\n",
      "epoch= 299 loss= 0.003587778890505433\n",
      "epoch= 300 loss= 0.0035092018079012632\n",
      "epoch= 301 loss= 0.0034321683924645185\n",
      "epoch= 302 loss= 0.003356669098138809\n",
      "epoch= 303 loss= 0.0032826766837388277\n",
      "epoch= 304 loss= 0.003210156224668026\n",
      "epoch= 305 loss= 0.003139110980555415\n",
      "epoch= 306 loss= 0.0030694513116031885\n",
      "epoch= 307 loss= 0.0030012193601578474\n",
      "epoch= 308 loss= 0.002934369258582592\n",
      "epoch= 309 loss= 0.00286884349770844\n",
      "epoch= 310 loss= 0.0028046586085110903\n",
      "epoch= 311 loss= 0.002741770585998893\n",
      "epoch= 312 loss= 0.002680174307897687\n",
      "epoch= 313 loss= 0.002619820646941662\n",
      "epoch= 314 loss= 0.002560720779001713\n",
      "epoch= 315 loss= 0.002502828137949109\n",
      "epoch= 316 loss= 0.0024461322464048862\n",
      "epoch= 317 loss= 0.0023905858397483826\n",
      "epoch= 318 loss= 0.002336211036890745\n",
      "epoch= 319 loss= 0.0022829535882920027\n",
      "epoch= 320 loss= 0.002230792073532939\n",
      "epoch= 321 loss= 0.0021797281224280596\n",
      "epoch= 322 loss= 0.002129726577550173\n",
      "epoch= 323 loss= 0.002080774400383234\n",
      "epoch= 324 loss= 0.00203285226598382\n",
      "epoch= 325 loss= 0.0019859399180859327\n",
      "epoch= 326 loss= 0.0019399984739720821\n",
      "epoch= 327 loss= 0.0018950491212308407\n",
      "epoch= 328 loss= 0.0018510404042899609\n",
      "epoch= 329 loss= 0.0018079794244840741\n",
      "epoch= 330 loss= 0.0017658346332609653\n",
      "epoch= 331 loss= 0.001724580186419189\n",
      "epoch= 332 loss= 0.0016842162003740668\n",
      "epoch= 333 loss= 0.0016447141533717513\n",
      "epoch= 334 loss= 0.0016060513444244862\n",
      "epoch= 335 loss= 0.0015682369703426957\n",
      "epoch= 336 loss= 0.0015312372706830502\n",
      "epoch= 337 loss= 0.0014950447948649526\n",
      "epoch= 338 loss= 0.001459609717130661\n",
      "epoch= 339 loss= 0.0014249728992581367\n",
      "epoch= 340 loss= 0.0013910853303968906\n",
      "epoch= 341 loss= 0.0013579368824139237\n",
      "epoch= 342 loss= 0.0013255164958536625\n",
      "epoch= 343 loss= 0.0012938029831275344\n",
      "epoch= 344 loss= 0.0012627961114048958\n",
      "epoch= 345 loss= 0.0012324628187343478\n",
      "epoch= 346 loss= 0.001202810206450522\n",
      "epoch= 347 loss= 0.0011738118482753634\n",
      "epoch= 348 loss= 0.001145463902503252\n",
      "epoch= 349 loss= 0.0011177380802109838\n",
      "epoch= 350 loss= 0.0010906325187534094\n",
      "epoch= 351 loss= 0.0010641278931871057\n",
      "epoch= 352 loss= 0.0010382343316450715\n",
      "epoch= 353 loss= 0.0010128987487405539\n",
      "epoch= 354 loss= 0.0009881517617031932\n",
      "epoch= 355 loss= 0.0009639666532166302\n",
      "epoch= 356 loss= 0.0009403200820088387\n",
      "epoch= 357 loss= 0.0009172078571282327\n",
      "epoch= 358 loss= 0.0008946166490204632\n",
      "epoch= 359 loss= 0.0008725500083528459\n",
      "epoch= 360 loss= 0.0008509866893291473\n",
      "epoch= 361 loss= 0.0008299173205159605\n",
      "epoch= 362 loss= 0.0008093251963146031\n",
      "epoch= 363 loss= 0.0007892110734246671\n",
      "epoch= 364 loss= 0.0007695572567172348\n",
      "epoch= 365 loss= 0.0007503565866500139\n",
      "epoch= 366 loss= 0.0007316027767956257\n",
      "epoch= 367 loss= 0.0007132785394787788\n",
      "epoch= 368 loss= 0.0006953804404474795\n",
      "epoch= 369 loss= 0.0006779043469578028\n",
      "epoch= 370 loss= 0.0006608297699131072\n",
      "epoch= 371 loss= 0.0006441664299927652\n",
      "epoch= 372 loss= 0.0006278830696828663\n",
      "epoch= 373 loss= 0.0006119873723946512\n",
      "epoch= 374 loss= 0.0005964550073258579\n",
      "epoch= 375 loss= 0.0005812988383695483\n",
      "epoch= 376 loss= 0.0005664982018060982\n",
      "epoch= 377 loss= 0.0005520462873391807\n",
      "epoch= 378 loss= 0.0005379393696784973\n",
      "epoch= 379 loss= 0.0005241622566245496\n",
      "epoch= 380 loss= 0.0005107242031954229\n",
      "epoch= 381 loss= 0.0004975974443368614\n",
      "epoch= 382 loss= 0.00048479324323125184\n",
      "epoch= 383 loss= 0.0004722906742244959\n",
      "epoch= 384 loss= 0.00046008615754544735\n",
      "epoch= 385 loss= 0.00044818539754487574\n",
      "epoch= 386 loss= 0.0004365657514426857\n",
      "epoch= 387 loss= 0.0004252217768225819\n",
      "epoch= 388 loss= 0.0004141549579799175\n",
      "epoch= 389 loss= 0.00040335857192985713\n",
      "epoch= 390 loss= 0.00039283049409277737\n",
      "epoch= 391 loss= 0.00038254857645370066\n",
      "epoch= 392 loss= 0.0003725294955074787\n",
      "epoch= 393 loss= 0.00036274315789341927\n",
      "epoch= 394 loss= 0.00035321060568094254\n",
      "epoch= 395 loss= 0.00034390020300634205\n",
      "epoch= 396 loss= 0.0003348252212163061\n",
      "epoch= 397 loss= 0.0003259710792917758\n",
      "epoch= 398 loss= 0.00031733818468637764\n",
      "epoch= 399 loss= 0.00030891800997778773\n",
      "epoch= 400 loss= 0.00030071090441197157\n",
      "epoch= 401 loss= 0.0002927049354184419\n",
      "epoch= 402 loss= 0.00028489509713836014\n",
      "epoch= 403 loss= 0.00027728258282877505\n",
      "epoch= 404 loss= 0.0002698640455491841\n",
      "epoch= 405 loss= 0.0002626268833409995\n",
      "epoch= 406 loss= 0.0002555717946961522\n",
      "epoch= 407 loss= 0.00024869610206224024\n",
      "epoch= 408 loss= 0.00024199172912631184\n",
      "epoch= 409 loss= 0.00023546029115095735\n",
      "epoch= 410 loss= 0.00022908927348908037\n",
      "epoch= 411 loss= 0.00022288448235485703\n",
      "epoch= 412 loss= 0.00021683616796508431\n",
      "epoch= 413 loss= 0.00021093922259751707\n",
      "epoch= 414 loss= 0.00020519504323601723\n",
      "epoch= 415 loss= 0.000199601796339266\n",
      "epoch= 416 loss= 0.00019414805865380913\n",
      "epoch= 417 loss= 0.0001888343831524253\n",
      "epoch= 418 loss= 0.00018365297000855207\n",
      "epoch= 419 loss= 0.00017861115338746458\n",
      "epoch= 420 loss= 0.00017369836859870702\n",
      "epoch= 421 loss= 0.00016891294217202812\n",
      "epoch= 422 loss= 0.00016424786008428782\n",
      "epoch= 423 loss= 0.00015970553795341402\n",
      "epoch= 424 loss= 0.00015528705262113363\n",
      "epoch= 425 loss= 0.00015097357390914112\n",
      "epoch= 426 loss= 0.00014678107982035726\n",
      "epoch= 427 loss= 0.00014269218081608415\n",
      "epoch= 428 loss= 0.00013871416740585119\n",
      "epoch= 429 loss= 0.00013484257215168327\n",
      "epoch= 430 loss= 0.00013106827100273222\n",
      "epoch= 431 loss= 0.00012739536759909242\n",
      "epoch= 432 loss= 0.00012381923443172127\n",
      "epoch= 433 loss= 0.00012033868551952764\n",
      "epoch= 434 loss= 0.00011694721615640447\n",
      "epoch= 435 loss= 0.00011365074897184968\n",
      "epoch= 436 loss= 0.00011043735867133364\n",
      "epoch= 437 loss= 0.00010731242218753323\n",
      "epoch= 438 loss= 0.00010427005327073857\n",
      "epoch= 439 loss= 0.0001013096552924253\n",
      "epoch= 440 loss= 9.842917643254623e-05\n",
      "epoch= 441 loss= 9.562369086779654e-05\n",
      "epoch= 442 loss= 9.289296576753259e-05\n",
      "epoch= 443 loss= 9.024065366247669e-05\n",
      "epoch= 444 loss= 8.7653701484669e-05\n",
      "epoch= 445 loss= 8.514271030435339e-05\n",
      "epoch= 446 loss= 8.269705722341314e-05\n",
      "epoch= 447 loss= 8.031565084820613e-05\n",
      "epoch= 448 loss= 7.800036109983921e-05\n",
      "epoch= 449 loss= 7.57498200982809e-05\n",
      "epoch= 450 loss= 7.356014248216525e-05\n",
      "epoch= 451 loss= 7.143009861465544e-05\n",
      "epoch= 452 loss= 6.93560068611987e-05\n",
      "epoch= 453 loss= 6.734332419000566e-05\n",
      "epoch= 454 loss= 6.53847455396317e-05\n",
      "epoch= 455 loss= 6.347932503558695e-05\n",
      "epoch= 456 loss= 6.162518548080698e-05\n",
      "epoch= 457 loss= 5.9824204072356224e-05\n",
      "epoch= 458 loss= 5.8072502724826336e-05\n",
      "epoch= 459 loss= 5.636892092297785e-05\n",
      "epoch= 460 loss= 5.4709831601940095e-05\n",
      "epoch= 461 loss= 5.310077904141508e-05\n",
      "epoch= 462 loss= 5.153792517376132e-05\n",
      "epoch= 463 loss= 5.001566023565829e-05\n",
      "epoch= 464 loss= 4.853673090110533e-05\n",
      "epoch= 465 loss= 4.709918357548304e-05\n",
      "epoch= 466 loss= 4.570227974909358e-05\n",
      "epoch= 467 loss= 4.434447691892274e-05\n",
      "epoch= 468 loss= 4.302537126932293e-05\n",
      "epoch= 469 loss= 4.1743958718143404e-05\n",
      "epoch= 470 loss= 4.049772906000726e-05\n",
      "epoch= 471 loss= 3.928555815946311e-05\n",
      "epoch= 472 loss= 3.8109577872091904e-05\n",
      "epoch= 473 loss= 3.6966190236853436e-05\n",
      "epoch= 474 loss= 3.585558442864567e-05\n",
      "epoch= 475 loss= 3.477668360574171e-05\n",
      "epoch= 476 loss= 3.3730026189005e-05\n",
      "epoch= 477 loss= 3.271105742896907e-05\n",
      "epoch= 478 loss= 3.172181095578708e-05\n",
      "epoch= 479 loss= 3.076153734582476e-05\n",
      "epoch= 480 loss= 2.982799196615815e-05\n",
      "epoch= 481 loss= 2.892431257350836e-05\n",
      "epoch= 482 loss= 2.80433760053711e-05\n",
      "epoch= 483 loss= 2.7189447791897692e-05\n",
      "epoch= 484 loss= 2.6359974071965553e-05\n",
      "epoch= 485 loss= 2.5553270461387e-05\n",
      "epoch= 486 loss= 2.4772287360974588e-05\n",
      "epoch= 487 loss= 2.4012731955735944e-05\n",
      "epoch= 488 loss= 2.3275972125702538e-05\n",
      "epoch= 489 loss= 2.2560010620509274e-05\n",
      "epoch= 490 loss= 2.1864796508452855e-05\n",
      "epoch= 491 loss= 2.119084274454508e-05\n",
      "epoch= 492 loss= 2.0535377188934945e-05\n",
      "epoch= 493 loss= 1.990166310861241e-05\n",
      "epoch= 494 loss= 1.9283921574242413e-05\n",
      "epoch= 495 loss= 1.8685945178731345e-05\n",
      "epoch= 496 loss= 1.8104839909938164e-05\n",
      "epoch= 497 loss= 1.754147706378717e-05\n",
      "epoch= 498 loss= 1.69951072166441e-05\n",
      "epoch= 499 loss= 1.6464487998746336e-05\n",
      "epoch= 500 loss= 1.595037610968575e-05\n",
      "epoch= 501 loss= 1.5450079445145093e-05\n",
      "epoch= 502 loss= 1.4965662558097392e-05\n",
      "epoch= 503 loss= 1.4495631148747634e-05\n",
      "epoch= 504 loss= 1.4039590496395249e-05\n",
      "epoch= 505 loss= 1.3597535144072026e-05\n",
      "epoch= 506 loss= 1.3168838449928444e-05\n",
      "epoch= 507 loss= 1.275214981433237e-05\n",
      "epoch= 508 loss= 1.234831415786175e-05\n",
      "epoch= 509 loss= 1.1958204595430288e-05\n",
      "epoch= 510 loss= 1.1577540135476738e-05\n",
      "epoch= 511 loss= 1.1209878721274436e-05\n",
      "epoch= 512 loss= 1.0853103049157653e-05\n",
      "epoch= 513 loss= 1.0506020771572366e-05\n",
      "epoch= 514 loss= 1.0171771464229096e-05\n",
      "epoch= 515 loss= 9.846983630268369e-06\n",
      "epoch= 516 loss= 9.53055132413283e-06\n",
      "epoch= 517 loss= 9.224550012731925e-06\n",
      "epoch= 518 loss= 8.928719580580946e-06\n",
      "epoch= 519 loss= 8.641510248708073e-06\n",
      "epoch= 520 loss= 8.36334493214963e-06\n",
      "epoch= 521 loss= 8.092992175079416e-06\n",
      "epoch= 522 loss= 7.831698894733563e-06\n",
      "epoch= 523 loss= 7.5778480095323175e-06\n",
      "epoch= 524 loss= 7.332475433940999e-06\n",
      "epoch= 525 loss= 7.09431515133474e-06\n",
      "epoch= 526 loss= 6.863306680315873e-06\n",
      "epoch= 527 loss= 6.6409643295628484e-06\n",
      "epoch= 528 loss= 6.423817012546351e-06\n",
      "epoch= 529 loss= 6.21428034719429e-06\n",
      "epoch= 530 loss= 6.010419838275993e-06\n",
      "epoch= 531 loss= 5.814536507386947e-06\n",
      "epoch= 532 loss= 5.622789558401564e-06\n",
      "epoch= 533 loss= 5.439131200546399e-06\n",
      "epoch= 534 loss= 5.260143097984837e-06\n",
      "epoch= 535 loss= 5.086217697680695e-06\n",
      "epoch= 536 loss= 4.918876129522687e-06\n",
      "epoch= 537 loss= 4.756293037644355e-06\n",
      "epoch= 538 loss= 4.598762643581722e-06\n",
      "epoch= 539 loss= 4.447017090569716e-06\n",
      "epoch= 540 loss= 4.299281954445178e-06\n",
      "epoch= 541 loss= 4.156640443397919e-06\n",
      "epoch= 542 loss= 4.017783794552088e-06\n",
      "epoch= 543 loss= 3.884538728016196e-06\n",
      "epoch= 544 loss= 3.7543047710641986e-06\n",
      "epoch= 545 loss= 3.6291551168687874e-06\n",
      "epoch= 546 loss= 3.507535666358308e-06\n",
      "epoch= 547 loss= 3.3898288620548556e-06\n",
      "epoch= 548 loss= 3.2760228805273073e-06\n",
      "epoch= 549 loss= 3.1664606012782315e-06\n",
      "epoch= 550 loss= 3.0599649107898585e-06\n",
      "epoch= 551 loss= 2.9569457637990126e-06\n",
      "epoch= 552 loss= 2.8566366836457746e-06\n",
      "epoch= 553 loss= 2.760038796623121e-06\n",
      "epoch= 554 loss= 2.6668083137337817e-06\n",
      "epoch= 555 loss= 2.5759454729268327e-06\n",
      "epoch= 556 loss= 2.4891305656637996e-06\n",
      "epoch= 557 loss= 2.4037335606408305e-06\n",
      "epoch= 558 loss= 2.322089812878403e-06\n",
      "epoch= 559 loss= 2.24310588237131e-06\n",
      "epoch= 560 loss= 2.1665011900040554e-06\n",
      "epoch= 561 loss= 2.092222530336585e-06\n",
      "epoch= 562 loss= 2.020724650719785e-06\n",
      "epoch= 563 loss= 1.9516357951943064e-06\n",
      "epoch= 564 loss= 1.8843778661903343e-06\n",
      "epoch= 565 loss= 1.8195113398178364e-06\n",
      "epoch= 566 loss= 1.7568867178852088e-06\n",
      "epoch= 567 loss= 1.6964455653578625e-06\n",
      "epoch= 568 loss= 1.637567379475513e-06\n",
      "epoch= 569 loss= 1.5809390561116743e-06\n",
      "epoch= 570 loss= 1.5263379964380874e-06\n",
      "epoch= 571 loss= 1.473253064432356e-06\n",
      "epoch= 572 loss= 1.4221026276572957e-06\n",
      "epoch= 573 loss= 1.3729086276725866e-06\n",
      "epoch= 574 loss= 1.3249394896774902e-06\n",
      "epoch= 575 loss= 1.278600961995835e-06\n",
      "epoch= 576 loss= 1.2339936574790045e-06\n",
      "epoch= 577 loss= 1.1910190096386941e-06\n",
      "epoch= 578 loss= 1.1489631788208499e-06\n",
      "epoch= 579 loss= 1.1088505971201812e-06\n",
      "epoch= 580 loss= 1.0696217032091226e-06\n",
      "epoch= 581 loss= 1.0321608669983107e-06\n",
      "epoch= 582 loss= 9.961180467144004e-07\n",
      "epoch= 583 loss= 9.60940610639227e-07\n",
      "epoch= 584 loss= 9.27057669741771e-07\n",
      "epoch= 585 loss= 8.940776297094999e-07\n",
      "epoch= 586 loss= 8.623931080364855e-07\n",
      "epoch= 587 loss= 8.319659059452533e-07\n",
      "epoch= 588 loss= 8.022905149118742e-07\n",
      "epoch= 589 loss= 7.736300631222548e-07\n",
      "epoch= 590 loss= 7.461239874828607e-07\n",
      "epoch= 591 loss= 7.195749276434071e-07\n",
      "epoch= 592 loss= 6.938888077456795e-07\n",
      "epoch= 593 loss= 6.692691272291995e-07\n",
      "epoch= 594 loss= 6.448736371567065e-07\n",
      "epoch= 595 loss= 6.217549071152462e-07\n",
      "epoch= 596 loss= 5.997042649141804e-07\n",
      "epoch= 597 loss= 5.779402840744297e-07\n",
      "epoch= 598 loss= 5.571873202825373e-07\n",
      "epoch= 599 loss= 5.369956284084765e-07\n",
      "epoch= 600 loss= 5.179149411560502e-07\n",
      "epoch= 601 loss= 4.989854005543748e-07\n",
      "epoch= 602 loss= 4.809296001440089e-07\n",
      "epoch= 603 loss= 4.6356225880117563e-07\n",
      "epoch= 604 loss= 4.4647148911280965e-07\n",
      "epoch= 605 loss= 4.302489742258331e-07\n",
      "epoch= 606 loss= 4.147575509705348e-07\n",
      "epoch= 607 loss= 3.9960241338121705e-07\n",
      "epoch= 608 loss= 3.8500229493365623e-07\n",
      "epoch= 609 loss= 3.710034377490956e-07\n",
      "epoch= 610 loss= 3.574008644591231e-07\n",
      "epoch= 611 loss= 3.4418690120219253e-07\n",
      "epoch= 612 loss= 3.315226422273554e-07\n",
      "epoch= 613 loss= 3.19354882094558e-07\n",
      "epoch= 614 loss= 3.075772383454023e-07\n",
      "epoch= 615 loss= 2.961906204745901e-07\n",
      "epoch= 616 loss= 2.85219499573941e-07\n",
      "epoch= 617 loss= 2.7477258868202625e-07\n",
      "epoch= 618 loss= 2.6447810341778677e-07\n",
      "epoch= 619 loss= 2.5480122189946997e-07\n",
      "epoch= 620 loss= 2.4541830612179183e-07\n",
      "epoch= 621 loss= 2.3618025579708046e-07\n",
      "epoch= 622 loss= 2.2739908445146284e-07\n",
      "epoch= 623 loss= 2.189988350664862e-07\n",
      "epoch= 624 loss= 2.1072726497095573e-07\n",
      "epoch= 625 loss= 2.028791072916647e-07\n",
      "epoch= 626 loss= 1.954190338437911e-07\n",
      "epoch= 627 loss= 1.879356545941846e-07\n",
      "epoch= 628 loss= 1.8094543463575974e-07\n",
      "epoch= 629 loss= 1.7421780285076238e-07\n",
      "epoch= 630 loss= 1.6756494858327642e-07\n",
      "epoch= 631 loss= 1.6139513547841489e-07\n",
      "epoch= 632 loss= 1.551929358356574e-07\n",
      "epoch= 633 loss= 1.493531271989923e-07\n",
      "epoch= 634 loss= 1.437921781644036e-07\n",
      "epoch= 635 loss= 1.3833671630436584e-07\n",
      "epoch= 636 loss= 1.330703867097327e-07\n",
      "epoch= 637 loss= 1.2798828663562745e-07\n",
      "epoch= 638 loss= 1.231080091201875e-07\n",
      "epoch= 639 loss= 1.1832904789343957e-07\n",
      "epoch= 640 loss= 1.1389192877686583e-07\n",
      "epoch= 641 loss= 1.0954585150102503e-07\n",
      "epoch= 642 loss= 1.0535260486221887e-07\n",
      "epoch= 643 loss= 1.012472239381168e-07\n",
      "epoch= 644 loss= 9.745207307787496e-08\n",
      "epoch= 645 loss= 9.375480658491142e-08\n",
      "epoch= 646 loss= 9.010977919388097e-08\n",
      "epoch= 647 loss= 8.660452976982924e-08\n",
      "epoch= 648 loss= 8.331958412099993e-08\n",
      "epoch= 649 loss= 8.009815388732022e-08\n",
      "epoch= 650 loss= 7.69402390687901e-08\n",
      "epoch= 651 loss= 7.405024149420569e-08\n",
      "epoch= 652 loss= 7.115439615290597e-08\n",
      "epoch= 653 loss= 6.835961130491341e-08\n",
      "epoch= 654 loss= 6.569590738081388e-08\n",
      "epoch= 655 loss= 6.310599331982303e-08\n",
      "epoch= 656 loss= 6.067627822403665e-08\n",
      "epoch= 657 loss= 5.827898164056933e-08\n",
      "epoch= 658 loss= 5.606862529816681e-08\n",
      "epoch= 659 loss= 5.383306600492688e-08\n",
      "epoch= 660 loss= 5.1780641996401755e-08\n",
      "epoch= 661 loss= 4.973535894237102e-08\n",
      "epoch= 662 loss= 4.774930673079325e-08\n",
      "epoch= 663 loss= 4.5915687252318094e-08\n",
      "epoch= 664 loss= 4.403902309491059e-08\n",
      "epoch= 665 loss= 4.233917749729699e-08\n",
      "epoch= 666 loss= 4.064321501573431e-08\n",
      "epoch= 667 loss= 3.904341383531573e-08\n",
      "epoch= 668 loss= 3.7532668528683644e-08\n",
      "epoch= 669 loss= 3.598370312829502e-08\n",
      "epoch= 670 loss= 3.457650521454525e-08\n",
      "epoch= 671 loss= 3.323917141528909e-08\n",
      "epoch= 672 loss= 3.1887264384522496e-08\n",
      "epoch= 673 loss= 3.0643622750403665e-08\n",
      "epoch= 674 loss= 2.9438902870992933e-08\n",
      "epoch= 675 loss= 2.8244452110470775e-08\n",
      "epoch= 676 loss= 2.712302737961636e-08\n",
      "epoch= 677 loss= 2.601397319779153e-08\n",
      "epoch= 678 loss= 2.4974420753665072e-08\n",
      "epoch= 679 loss= 2.395898945906083e-08\n",
      "epoch= 680 loss= 2.3040987784384015e-08\n",
      "epoch= 681 loss= 2.209733018787574e-08\n",
      "epoch= 682 loss= 2.1176163045311114e-08\n",
      "epoch= 683 loss= 2.034632551328741e-08\n",
      "epoch= 684 loss= 1.953316086655832e-08\n",
      "epoch= 685 loss= 1.869898369477596e-08\n",
      "epoch= 686 loss= 1.798974835764966e-08\n",
      "epoch= 687 loss= 1.7217189451912418e-08\n",
      "epoch= 688 loss= 1.653931214207205e-08\n",
      "epoch= 689 loss= 1.5875079029115113e-08\n",
      "epoch= 690 loss= 1.5242543227600436e-08\n",
      "epoch= 691 loss= 1.4605139320167382e-08\n",
      "epoch= 692 loss= 1.3973855850224481e-08\n",
      "epoch= 693 loss= 1.3414687138890713e-08\n",
      "epoch= 694 loss= 1.2869141308158305e-08\n",
      "epoch= 695 loss= 1.236747948496486e-08\n",
      "epoch= 696 loss= 1.1866802651638864e-08\n",
      "epoch= 697 loss= 1.1385300702215773e-08\n",
      "epoch= 698 loss= 1.0883108636505767e-08\n",
      "epoch= 699 loss= 1.0415685203213343e-08\n",
      "epoch= 700 loss= 1.0040063891381124e-08\n",
      "epoch= 701 loss= 9.591322402968672e-09\n",
      "epoch= 702 loss= 9.201055028995597e-09\n",
      "epoch= 703 loss= 8.82065886997907e-09\n",
      "epoch= 704 loss= 8.46938519316609e-09\n",
      "epoch= 705 loss= 8.104602322589471e-09\n",
      "epoch= 706 loss= 7.793914846843109e-09\n",
      "epoch= 707 loss= 7.444138194756533e-09\n",
      "epoch= 708 loss= 7.121741418814054e-09\n",
      "epoch= 709 loss= 6.849651068563389e-09\n",
      "epoch= 710 loss= 6.540555208545129e-09\n",
      "epoch= 711 loss= 6.28500629318296e-09\n",
      "epoch= 712 loss= 6.006776853695328e-09\n",
      "epoch= 713 loss= 5.757120558058659e-09\n",
      "epoch= 714 loss= 5.535942815271255e-09\n",
      "epoch= 715 loss= 5.296366456519763e-09\n",
      "epoch= 716 loss= 5.078410136860612e-09\n",
      "epoch= 717 loss= 4.8446509026689455e-09\n",
      "epoch= 718 loss= 4.656252716728204e-09\n",
      "epoch= 719 loss= 4.452052504433368e-09\n",
      "epoch= 720 loss= 4.27161239713314e-09\n",
      "epoch= 721 loss= 4.09600398043608e-09\n",
      "epoch= 722 loss= 3.90461218913174e-09\n",
      "epoch= 723 loss= 3.7318081957948834e-09\n",
      "epoch= 724 loss= 3.585379770854047e-09\n",
      "epoch= 725 loss= 3.4332856557739433e-09\n",
      "epoch= 726 loss= 3.27617044604267e-09\n",
      "epoch= 727 loss= 3.1343649897763726e-09\n",
      "epoch= 728 loss= 3.008305382579124e-09\n",
      "epoch= 729 loss= 2.8848603506048676e-09\n",
      "epoch= 730 loss= 2.7683502157316298e-09\n",
      "epoch= 731 loss= 2.634900964082476e-09\n",
      "epoch= 732 loss= 2.519451980376175e-09\n",
      "epoch= 733 loss= 2.410634580840565e-09\n",
      "epoch= 734 loss= 2.3112722846718725e-09\n",
      "epoch= 735 loss= 2.2032509150449187e-09\n",
      "epoch= 736 loss= 2.125640774508497e-09\n",
      "epoch= 737 loss= 2.01915395514618e-09\n",
      "epoch= 738 loss= 1.9448787025311276e-09\n",
      "epoch= 739 loss= 1.8565250448077109e-09\n",
      "epoch= 740 loss= 1.781794822797167e-09\n",
      "epoch= 741 loss= 1.696529694505955e-09\n",
      "epoch= 742 loss= 1.6258733248619706e-09\n",
      "epoch= 743 loss= 1.5444735490532935e-09\n",
      "epoch= 744 loss= 1.477114097703236e-09\n",
      "epoch= 745 loss= 1.4191906538840726e-09\n",
      "epoch= 746 loss= 1.3546355148719158e-09\n",
      "epoch= 747 loss= 1.299213181482628e-09\n",
      "epoch= 748 loss= 1.2374622437860694e-09\n",
      "epoch= 749 loss= 1.1772650632124737e-09\n",
      "epoch= 750 loss= 1.1333062266416505e-09\n",
      "epoch= 751 loss= 1.0853492549145471e-09\n",
      "epoch= 752 loss= 1.0432094077472698e-09\n",
      "epoch= 753 loss= 9.972609404940158e-10\n",
      "epoch= 754 loss= 9.502704179098487e-10\n",
      "epoch= 755 loss= 9.019913704833016e-10\n",
      "epoch= 756 loss= 8.659905570418402e-10\n",
      "epoch= 757 loss= 8.307476373481393e-10\n",
      "epoch= 758 loss= 7.856518213777974e-10\n",
      "epoch= 759 loss= 7.601859697281554e-10\n",
      "epoch= 760 loss= 7.25416782199062e-10\n",
      "epoch= 761 loss= 6.910075289745521e-10\n",
      "epoch= 762 loss= 6.579436440112829e-10\n",
      "epoch= 763 loss= 6.345999281620607e-10\n",
      "epoch= 764 loss= 6.029381438565906e-10\n",
      "epoch= 765 loss= 5.791207513539121e-10\n",
      "epoch= 766 loss= 5.483495324476451e-10\n",
      "epoch= 767 loss= 5.256310942058917e-10\n",
      "epoch= 768 loss= 5.015105553063393e-10\n",
      "epoch= 769 loss= 4.811984699593097e-10\n",
      "epoch= 770 loss= 4.5362943956739343e-10\n",
      "epoch= 771 loss= 4.3778905500779786e-10\n",
      "epoch= 772 loss= 4.2177816794719547e-10\n",
      "epoch= 773 loss= 3.9602809920324944e-10\n",
      "epoch= 774 loss= 3.824425220955163e-10\n",
      "epoch= 775 loss= 3.6192204788676463e-10\n",
      "epoch= 776 loss= 3.490185918053612e-10\n",
      "epoch= 777 loss= 3.2948341277538873e-10\n",
      "epoch= 778 loss= 3.1591676497022547e-10\n",
      "epoch= 779 loss= 3.03922803590595e-10\n",
      "epoch= 780 loss= 2.908867313689001e-10\n",
      "epoch= 781 loss= 2.781538055440791e-10\n",
      "epoch= 782 loss= 2.65724026116132e-10\n",
      "epoch= 783 loss= 2.5359744859621003e-10\n",
      "epoch= 784 loss= 2.4177401747316196e-10\n",
      "epoch= 785 loss= 2.302537466247756e-10\n",
      "epoch= 786 loss= 2.1903663605105095e-10\n",
      "epoch= 787 loss= 2.068342580541227e-10\n",
      "epoch= 788 loss= 1.970003465912029e-10\n",
      "epoch= 789 loss= 1.866169441200327e-10\n",
      "epoch= 790 loss= 1.792651999066308e-10\n",
      "epoch= 791 loss= 1.7320189726888202e-10\n",
      "epoch= 792 loss= 1.6342482922482304e-10\n",
      "epoch= 793 loss= 1.5681204945661165e-10\n",
      "epoch= 794 loss= 1.5112770757053084e-10\n",
      "epoch= 795 loss= 1.3862215542115308e-10\n",
      "epoch= 796 loss= 1.3591261449619196e-10\n",
      "epoch= 797 loss= 1.2734820142856762e-10\n",
      "epoch= 798 loss= 1.2475236121911593e-10\n",
      "epoch= 799 loss= 1.1558162066327426e-10\n",
      "epoch= 800 loss= 1.1376263125972841e-10\n",
      "epoch= 801 loss= 1.0504663805477321e-10\n",
      "epoch= 802 loss= 1.0353081586478297e-10\n",
      "epoch= 803 loss= 9.526957001071423e-11\n",
      "epoch= 804 loss= 9.309056997475196e-11\n",
      "epoch= 805 loss= 8.884626367944293e-11\n",
      "epoch= 806 loss= 8.678095048120227e-11\n",
      "epoch= 807 loss= 8.179767974070273e-11\n",
      "epoch= 808 loss= 7.980816008057445e-11\n",
      "epoch= 809 loss= 7.26079960045034e-11\n",
      "epoch= 810 loss= 7.073216318209674e-11\n",
      "epoch= 811 loss= 6.861000656499527e-11\n",
      "epoch= 812 loss= 6.677206704219785e-11\n",
      "epoch= 813 loss= 6.247091732802801e-11\n",
      "epoch= 814 loss= 6.070877134334296e-11\n",
      "epoch= 815 loss= 5.66349918351694e-11\n",
      "epoch= 816 loss= 5.494863938859673e-11\n",
      "epoch= 817 loss= 5.070432962384075e-11\n",
      "epoch= 818 loss= 4.905587047687732e-11\n",
      "epoch= 819 loss= 4.555052515731184e-11\n",
      "epoch= 820 loss= 4.6232646183641535e-11\n",
      "epoch= 821 loss= 4.291678123991005e-11\n",
      "epoch= 822 loss= 4.1382008930668235e-11\n",
      "epoch= 823 loss= 3.8293517662379983e-11\n",
      "epoch= 824 loss= 3.61524143954739e-11\n",
      "epoch= 825 loss= 3.632294465205632e-11\n",
      "epoch= 826 loss= 3.3063923127185646e-11\n",
      "epoch= 827 loss= 3.175652449338706e-11\n",
      "epoch= 828 loss= 3.0487019159197715e-11\n",
      "epoch= 829 loss= 2.887645678129047e-11\n",
      "epoch= 830 loss= 2.7682744985213503e-11\n",
      "epoch= 831 loss= 2.6526928223469248e-11\n",
      "epoch= 832 loss= 2.5409008230781183e-11\n",
      "epoch= 833 loss= 2.432898327242583e-11\n",
      "epoch= 834 loss= 2.432898327242583e-11\n",
      "epoch= 835 loss= 2.305947967295996e-11\n",
      "epoch= 836 loss= 2.0463630789890885e-11\n",
      "epoch= 837 loss= 2.0463630789890885e-11\n",
      "epoch= 838 loss= 1.949729266925715e-11\n",
      "epoch= 839 loss= 1.8284632488652086e-11\n",
      "epoch= 840 loss= 1.8284632488652086e-11\n",
      "epoch= 841 loss= 1.6996182239381596e-11\n",
      "epoch= 842 loss= 1.6067739153080574e-11\n",
      "epoch= 843 loss= 1.4930870775864413e-11\n",
      "epoch= 844 loss= 1.404032445861958e-11\n",
      "epoch= 845 loss= 1.404032445861958e-11\n",
      "epoch= 846 loss= 1.404032445861958e-11\n",
      "epoch= 847 loss= 1.2202387537907367e-11\n",
      "epoch= 848 loss= 1.318767317570746e-11\n",
      "epoch= 849 loss= 1.138763128932796e-11\n",
      "epoch= 850 loss= 1.0932883938441496e-11\n",
      "epoch= 851 loss= 1.0932883938441496e-11\n",
      "epoch= 852 loss= 9.473903432588582e-12\n",
      "epoch= 853 loss= 1.0156024458918278e-11\n",
      "epoch= 854 loss= 8.734938987398078e-12\n",
      "epoch= 855 loss= 8.337035055372422e-12\n",
      "epoch= 856 loss= 7.673861546209082e-12\n",
      "epoch= 857 loss= 7.654914029042725e-12\n",
      "epoch= 858 loss= 7.654914029042725e-12\n",
      "epoch= 859 loss= 7.0675318895874195e-12\n",
      "epoch= 860 loss= 7.0675318895874195e-12\n",
      "epoch= 861 loss= 6.233828123841656e-12\n",
      "epoch= 862 loss= 6.233828123841656e-12\n",
      "epoch= 863 loss= 5.002220859751105e-12\n",
      "epoch= 864 loss= 4.6990558145998396e-12\n",
      "epoch= 865 loss= 5.002220859751105e-12\n",
      "epoch= 866 loss= 4.490630090003833e-12\n",
      "epoch= 867 loss= 4.016934788270143e-12\n",
      "epoch= 868 loss= 4.623264878572675e-12\n",
      "epoch= 869 loss= 4.1874650448525674e-12\n",
      "epoch= 870 loss= 3.581135388230905e-12\n",
      "epoch= 871 loss= 3.581135388230905e-12\n",
      "epoch= 872 loss= 3.581135388230905e-12\n",
      "epoch= 873 loss= 3.0505968844768416e-12\n",
      "epoch= 874 loss= 3.3348139787808817e-12\n",
      "epoch= 875 loss= 3.0505968844768416e-12\n",
      "epoch= 876 loss= 2.6526929524511855e-12\n",
      "epoch= 877 loss= 2.6526929524511855e-12\n",
      "epoch= 878 loss= 2.6526929524511855e-12\n",
      "epoch= 879 loss= 2.2926844884391118e-12\n",
      "epoch= 880 loss= 2.747431839325576e-12\n",
      "epoch= 881 loss= 2.4253192770079535e-12\n",
      "epoch= 882 loss= 2.4253192770079535e-12\n",
      "epoch= 883 loss= 1.8947805564134557e-12\n",
      "epoch= 884 loss= 1.5916157281026244e-12\n",
      "epoch= 885 loss= 1.8947805564134557e-12\n",
      "epoch= 886 loss= 1.6105635705296328e-12\n",
      "epoch= 887 loss= 1.6105635705296328e-12\n",
      "epoch= 888 loss= 1.6105635705296328e-12\n",
      "epoch= 889 loss= 1.5916157281026244e-12\n",
      "epoch= 890 loss= 1.3073986337985843e-12\n",
      "epoch= 891 loss= 1.3073986337985843e-12\n",
      "epoch= 892 loss= 1.6105635705296328e-12\n",
      "epoch= 893 loss= 1.6105635705296328e-12\n",
      "epoch= 894 loss= 1.3642420526593924e-12\n",
      "epoch= 895 loss= 1.3642420526593924e-12\n",
      "epoch= 896 loss= 1.3642420526593924e-12\n",
      "epoch= 897 loss= 9.852859630607447e-13\n",
      "epoch= 898 loss= 1.3073986337985843e-12\n",
      "epoch= 899 loss= 1.0610771159283439e-12\n",
      "epoch= 900 loss= 1.0610771159283439e-12\n",
      "epoch= 901 loss= 1.3642420526593924e-12\n",
      "epoch= 902 loss= 1.3642420526593924e-12\n",
      "epoch= 903 loss= 1.3642420526593924e-12\n",
      "epoch= 904 loss= 1.1558162196431687e-12\n",
      "epoch= 905 loss= 1.0610771159283439e-12\n",
      "epoch= 906 loss= 1.0610771159283439e-12\n",
      "epoch= 907 loss= 1.0610771159283439e-12\n",
      "epoch= 908 loss= 7.768600758344124e-13\n",
      "epoch= 909 loss= 7.768600758344124e-13\n",
      "epoch= 910 loss= 7.768600758344124e-13\n",
      "epoch= 911 loss= 7.768600758344124e-13\n",
      "epoch= 912 loss= 7.768600758344124e-13\n",
      "epoch= 913 loss= 7.768600758344124e-13\n",
      "epoch= 914 loss= 7.768600758344124e-13\n",
      "epoch= 915 loss= 9.852859630607447e-13\n",
      "epoch= 916 loss= 9.852859630607447e-13\n",
      "epoch= 917 loss= 9.852859630607447e-13\n",
      "epoch= 918 loss= 7.768600758344124e-13\n",
      "epoch= 919 loss= 6.252776074688882e-13\n",
      "epoch= 920 loss= 6.252776074688882e-13\n",
      "epoch= 921 loss= 6.252776074688882e-13\n",
      "epoch= 922 loss= 6.252776074688882e-13\n",
      "epoch= 923 loss= 6.252776074688882e-13\n",
      "epoch= 924 loss= 6.252776074688882e-13\n",
      "epoch= 925 loss= 3.78956116703702e-13\n",
      "epoch= 926 loss= 3.78956116703702e-13\n",
      "epoch= 927 loss= 3.78956116703702e-13\n",
      "epoch= 928 loss= 3.78956116703702e-13\n",
      "epoch= 929 loss= 3.78956116703702e-13\n",
      "epoch= 930 loss= 4.736951391033639e-13\n",
      "epoch= 931 loss= 4.736951391033639e-13\n",
      "epoch= 932 loss= 4.736951391033639e-13\n",
      "epoch= 933 loss= 4.736951391033639e-13\n",
      "epoch= 934 loss= 4.736951391033639e-13\n",
      "epoch= 935 loss= 4.926429815303723e-13\n",
      "epoch= 936 loss= 4.926429815303723e-13\n",
      "epoch= 937 loss= 4.926429815303723e-13\n",
      "epoch= 938 loss= 4.926429815303723e-13\n",
      "epoch= 939 loss= 4.926429815303723e-13\n",
      "epoch= 940 loss= 4.926429815303723e-13\n",
      "epoch= 941 loss= 4.926429815303723e-13\n",
      "epoch= 942 loss= 2.4632149076518617e-13\n",
      "epoch= 943 loss= 2.4632149076518617e-13\n",
      "epoch= 944 loss= 2.4632149076518617e-13\n",
      "epoch= 945 loss= 2.4632149076518617e-13\n",
      "epoch= 946 loss= 2.4632149076518617e-13\n",
      "epoch= 947 loss= 2.4632149076518617e-13\n",
      "epoch= 948 loss= 2.4632149076518617e-13\n",
      "epoch= 949 loss= 2.4632149076518617e-13\n",
      "epoch= 950 loss= 2.4632149076518617e-13\n",
      "epoch= 951 loss= 2.4632149076518617e-13\n",
      "epoch= 952 loss= 2.4632149076518617e-13\n",
      "epoch= 953 loss= 2.4632149076518617e-13\n",
      "epoch= 954 loss= 2.4632149076518617e-13\n",
      "epoch= 955 loss= 2.4632149076518617e-13\n",
      "epoch= 956 loss= 2.4632149076518617e-13\n",
      "epoch= 957 loss= 2.4632149076518617e-13\n",
      "epoch= 958 loss= 2.4632149076518617e-13\n",
      "epoch= 959 loss= 2.4632149076518617e-13\n",
      "epoch= 960 loss= 2.4632149076518617e-13\n",
      "epoch= 961 loss= 2.4632149076518617e-13\n",
      "epoch= 962 loss= 2.4632149076518617e-13\n",
      "epoch= 963 loss= 2.4632149076518617e-13\n",
      "epoch= 964 loss= 2.4632149076518617e-13\n",
      "epoch= 965 loss= 2.4632149076518617e-13\n",
      "epoch= 966 loss= 2.4632149076518617e-13\n",
      "epoch= 967 loss= 2.4632149076518617e-13\n",
      "epoch= 968 loss= 1.7053025658242404e-13\n",
      "epoch= 969 loss= 1.7053025658242404e-13\n",
      "epoch= 970 loss= 1.7053025658242404e-13\n",
      "epoch= 971 loss= 1.7053025658242404e-13\n",
      "epoch= 972 loss= 1.7053025658242404e-13\n",
      "epoch= 973 loss= 1.7053025658242404e-13\n",
      "epoch= 974 loss= 1.7053025658242404e-13\n",
      "epoch= 975 loss= 1.7053025658242404e-13\n",
      "epoch= 976 loss= 1.7053025658242404e-13\n",
      "epoch= 977 loss= 1.7053025658242404e-13\n",
      "epoch= 978 loss= 1.7053025658242404e-13\n",
      "epoch= 979 loss= 1.7053025658242404e-13\n",
      "epoch= 980 loss= 1.7053025658242404e-13\n",
      "epoch= 981 loss= 2.4632149076518617e-13\n",
      "epoch= 982 loss= 2.4632149076518617e-13\n",
      "epoch= 983 loss= 2.4632149076518617e-13\n",
      "epoch= 984 loss= 2.4632149076518617e-13\n",
      "epoch= 985 loss= 2.4632149076518617e-13\n",
      "epoch= 986 loss= 2.4632149076518617e-13\n",
      "epoch= 987 loss= 2.4632149076518617e-13\n",
      "epoch= 988 loss= 2.4632149076518617e-13\n",
      "epoch= 989 loss= 2.4632149076518617e-13\n",
      "epoch= 990 loss= 1.7053025658242404e-13\n",
      "epoch= 991 loss= 1.7053025658242404e-13\n",
      "epoch= 992 loss= 1.7053025658242404e-13\n",
      "epoch= 993 loss= 1.7053025658242404e-13\n",
      "epoch= 994 loss= 1.7053025658242404e-13\n",
      "epoch= 995 loss= 1.7053025658242404e-13\n",
      "epoch= 996 loss= 1.7053025658242404e-13\n",
      "epoch= 997 loss= 1.7053025658242404e-13\n",
      "epoch= 998 loss= 2.4632149076518617e-13\n",
      "epoch= 999 loss= 2.4632149076518617e-13\n",
      "w= 1.9999992847442627\n",
      "b= 1.3247740753286052e-06\n",
      "prediction= 7.999998569488525\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare dataset \n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_data = torch.Tensor([[1.0], [2.0], [3.0]])\n",
    "y_data = torch.Tensor([[2.0], [4.0], [6.0]])\n",
    "\n",
    "# define model using class\n",
    "class LinearModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "\n",
    "model = LinearModel()\n",
    "# define loss function and optimizer\n",
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "# training cycle\n",
    "cost_list = []\n",
    "for epoch in range(1000):\n",
    "    y_pred = model(x_data)\n",
    "    cost = loss(y_pred, y_data)\n",
    "    cost_list.append(cost.item())\n",
    "    print('epoch=', epoch, 'loss=', cost.item())\n",
    "    optimizer.zero_grad()  # 梯度初始化\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "print('w=', model.linear.weight.item())\n",
    "print('b=', model.linear.bias.item())\n",
    "\n",
    "x_test = torch.Tensor([[4.0]])\n",
    "y_test = model(x_test)\n",
    "print('prediction=', y_test.item())\n",
    "\n",
    "plt.plot(cost_list)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture_06_Logistic_Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 0 loss= 2.9917542934417725\n",
      "epoch= 1 loss= 2.2760088443756104\n",
      "epoch= 2 loss= 2.043332815170288\n",
      "epoch= 3 loss= 1.9191837310791016\n",
      "epoch= 4 loss= 1.8111979961395264\n",
      "epoch= 5 loss= 1.7167229652404785\n",
      "epoch= 6 loss= 1.6389877796173096\n",
      "epoch= 7 loss= 1.5586357116699219\n",
      "epoch= 8 loss= 1.495798110961914\n",
      "epoch= 9 loss= 1.4268018007278442\n",
      "epoch= 10 loss= 1.37360680103302\n",
      "epoch= 11 loss= 1.3154716491699219\n",
      "epoch= 12 loss= 1.269834041595459\n",
      "epoch= 13 loss= 1.2220102548599243\n",
      "epoch= 14 loss= 1.1830617189407349\n",
      "epoch= 15 loss= 1.1443384885787964\n",
      "epoch= 16 loss= 1.111445665359497\n",
      "epoch= 17 loss= 1.0800671577453613\n",
      "epoch= 18 loss= 1.052361249923706\n",
      "epoch= 19 loss= 1.026440143585205\n",
      "epoch= 20 loss= 1.0028281211853027\n",
      "epoch= 21 loss= 0.9807497262954712\n",
      "epoch= 22 loss= 0.9601854085922241\n",
      "epoch= 23 loss= 0.9408073425292969\n",
      "epoch= 24 loss= 0.9225031137466431\n",
      "epoch= 25 loss= 0.9051195383071899\n",
      "epoch= 26 loss= 0.8885674476623535\n",
      "epoch= 27 loss= 0.8727642893791199\n",
      "epoch= 28 loss= 0.8576487302780151\n",
      "epoch= 29 loss= 0.8431676626205444\n",
      "epoch= 30 loss= 0.8292766809463501\n",
      "epoch= 31 loss= 0.8159358501434326\n",
      "epoch= 32 loss= 0.8031101226806641\n",
      "epoch= 33 loss= 0.7907673120498657\n",
      "epoch= 34 loss= 0.7788779735565186\n",
      "epoch= 35 loss= 0.7674156427383423\n",
      "epoch= 36 loss= 0.7563550472259521\n",
      "epoch= 37 loss= 0.7456738352775574\n",
      "epoch= 38 loss= 0.7353508472442627\n",
      "epoch= 39 loss= 0.725366473197937\n",
      "epoch= 40 loss= 0.7157025933265686\n",
      "epoch= 41 loss= 0.7063426971435547\n",
      "epoch= 42 loss= 0.6972708702087402\n",
      "epoch= 43 loss= 0.6884727478027344\n",
      "epoch= 44 loss= 0.6799347400665283\n",
      "epoch= 45 loss= 0.6716443300247192\n",
      "epoch= 46 loss= 0.6635897159576416\n",
      "epoch= 47 loss= 0.655759871006012\n",
      "epoch= 48 loss= 0.6481444835662842\n",
      "epoch= 49 loss= 0.6407337784767151\n",
      "epoch= 50 loss= 0.6335188746452332\n",
      "epoch= 51 loss= 0.6264910697937012\n",
      "epoch= 52 loss= 0.6196424961090088\n",
      "epoch= 53 loss= 0.6129655838012695\n",
      "epoch= 54 loss= 0.6064531803131104\n",
      "epoch= 55 loss= 0.6000986695289612\n",
      "epoch= 56 loss= 0.5938954949378967\n",
      "epoch= 57 loss= 0.5878381133079529\n",
      "epoch= 58 loss= 0.5819205045700073\n",
      "epoch= 59 loss= 0.5761375427246094\n",
      "epoch= 60 loss= 0.5704842209815979\n",
      "epoch= 61 loss= 0.5649554133415222\n",
      "epoch= 62 loss= 0.559546947479248\n",
      "epoch= 63 loss= 0.554254412651062\n",
      "epoch= 64 loss= 0.549073338508606\n",
      "epoch= 65 loss= 0.5440003275871277\n",
      "epoch= 66 loss= 0.5390316247940063\n",
      "epoch= 67 loss= 0.5341634154319763\n",
      "epoch= 68 loss= 0.5293926000595093\n",
      "epoch= 69 loss= 0.524715781211853\n",
      "epoch= 70 loss= 0.5201300382614136\n",
      "epoch= 71 loss= 0.5156323909759521\n",
      "epoch= 72 loss= 0.5112202167510986\n",
      "epoch= 73 loss= 0.5068906545639038\n",
      "epoch= 74 loss= 0.5026410222053528\n",
      "epoch= 75 loss= 0.49846920371055603\n",
      "epoch= 76 loss= 0.4943728446960449\n",
      "epoch= 77 loss= 0.4903494715690613\n",
      "epoch= 78 loss= 0.4863971471786499\n",
      "epoch= 79 loss= 0.48251375555992126\n",
      "epoch= 80 loss= 0.4786972999572754\n",
      "epoch= 81 loss= 0.47494590282440186\n",
      "epoch= 82 loss= 0.47125789523124695\n",
      "epoch= 83 loss= 0.46763139963150024\n",
      "epoch= 84 loss= 0.4640646278858185\n",
      "epoch= 85 loss= 0.46055617928504944\n",
      "epoch= 86 loss= 0.45710447430610657\n",
      "epoch= 87 loss= 0.453707754611969\n",
      "epoch= 88 loss= 0.4503650367259979\n",
      "epoch= 89 loss= 0.4470747113227844\n",
      "epoch= 90 loss= 0.4438353478908539\n",
      "epoch= 91 loss= 0.44064581394195557\n",
      "epoch= 92 loss= 0.43750470876693726\n",
      "epoch= 93 loss= 0.43441104888916016\n",
      "epoch= 94 loss= 0.43136346340179443\n",
      "epoch= 95 loss= 0.42836105823516846\n",
      "epoch= 96 loss= 0.4254026412963867\n",
      "epoch= 97 loss= 0.4224870204925537\n",
      "epoch= 98 loss= 0.41961348056793213\n",
      "epoch= 99 loss= 0.41678082942962646\n",
      "epoch= 100 loss= 0.4139884114265442\n",
      "epoch= 101 loss= 0.41123485565185547\n",
      "epoch= 102 loss= 0.4085195064544678\n",
      "epoch= 103 loss= 0.4058418869972229\n",
      "epoch= 104 loss= 0.403200626373291\n",
      "epoch= 105 loss= 0.40059518814086914\n",
      "epoch= 106 loss= 0.39802467823028564\n",
      "epoch= 107 loss= 0.39548835158348083\n",
      "epoch= 108 loss= 0.39298558235168457\n",
      "epoch= 109 loss= 0.3905155658721924\n",
      "epoch= 110 loss= 0.38807785511016846\n",
      "epoch= 111 loss= 0.3856714367866516\n",
      "epoch= 112 loss= 0.38329577445983887\n",
      "epoch= 113 loss= 0.3809504508972168\n",
      "epoch= 114 loss= 0.37863457202911377\n",
      "epoch= 115 loss= 0.3763476312160492\n",
      "epoch= 116 loss= 0.3740893304347992\n",
      "epoch= 117 loss= 0.3718585669994354\n",
      "epoch= 118 loss= 0.3696553111076355\n",
      "epoch= 119 loss= 0.36747872829437256\n",
      "epoch= 120 loss= 0.365328311920166\n",
      "epoch= 121 loss= 0.36320385336875916\n",
      "epoch= 122 loss= 0.36110442876815796\n",
      "epoch= 123 loss= 0.3590298891067505\n",
      "epoch= 124 loss= 0.35697969794273376\n",
      "epoch= 125 loss= 0.3549535274505615\n",
      "epoch= 126 loss= 0.3529505431652069\n",
      "epoch= 127 loss= 0.35097071528434753\n",
      "epoch= 128 loss= 0.34901344776153564\n",
      "epoch= 129 loss= 0.3470783531665802\n",
      "epoch= 130 loss= 0.34516510367393494\n",
      "epoch= 131 loss= 0.3432731628417969\n",
      "epoch= 132 loss= 0.3414023518562317\n",
      "epoch= 133 loss= 0.3395521640777588\n",
      "epoch= 134 loss= 0.33772218227386475\n",
      "epoch= 135 loss= 0.3359123468399048\n",
      "epoch= 136 loss= 0.33412209153175354\n",
      "epoch= 137 loss= 0.3323509097099304\n",
      "epoch= 138 loss= 0.330598920583725\n",
      "epoch= 139 loss= 0.3288656771183014\n",
      "epoch= 140 loss= 0.32715049386024475\n",
      "epoch= 141 loss= 0.3254534900188446\n",
      "epoch= 142 loss= 0.3237742781639099\n",
      "epoch= 143 loss= 0.3221122622489929\n",
      "epoch= 144 loss= 0.3204677104949951\n",
      "epoch= 145 loss= 0.3188399076461792\n",
      "epoch= 146 loss= 0.3172287940979004\n",
      "epoch= 147 loss= 0.3156338930130005\n",
      "epoch= 148 loss= 0.3140552341938019\n",
      "epoch= 149 loss= 0.312492311000824\n",
      "epoch= 150 loss= 0.31094518303871155\n",
      "epoch= 151 loss= 0.30941325426101685\n",
      "epoch= 152 loss= 0.30789637565612793\n",
      "epoch= 153 loss= 0.30639463663101196\n",
      "epoch= 154 loss= 0.3049074113368988\n",
      "epoch= 155 loss= 0.3034345805644989\n",
      "epoch= 156 loss= 0.3019760251045227\n",
      "epoch= 157 loss= 0.30053165555000305\n",
      "epoch= 158 loss= 0.2991008758544922\n",
      "epoch= 159 loss= 0.29768380522727966\n",
      "epoch= 160 loss= 0.29628005623817444\n",
      "epoch= 161 loss= 0.2948895990848541\n",
      "epoch= 162 loss= 0.293512225151062\n",
      "epoch= 163 loss= 0.2921474575996399\n",
      "epoch= 164 loss= 0.29079535603523254\n",
      "epoch= 165 loss= 0.2894558310508728\n",
      "epoch= 166 loss= 0.2881286144256592\n",
      "epoch= 167 loss= 0.28681349754333496\n",
      "epoch= 168 loss= 0.2855103015899658\n",
      "epoch= 169 loss= 0.28421899676322937\n",
      "epoch= 170 loss= 0.28293904662132263\n",
      "epoch= 171 loss= 0.28167083859443665\n",
      "epoch= 172 loss= 0.28041380643844604\n",
      "epoch= 173 loss= 0.2791677713394165\n",
      "epoch= 174 loss= 0.2779329717159271\n",
      "epoch= 175 loss= 0.2767088711261749\n",
      "epoch= 176 loss= 0.2754954993724823\n",
      "epoch= 177 loss= 0.27429255843162537\n",
      "epoch= 178 loss= 0.2731003761291504\n",
      "epoch= 179 loss= 0.2719183564186096\n",
      "epoch= 180 loss= 0.27074623107910156\n",
      "epoch= 181 loss= 0.26958438754081726\n",
      "epoch= 182 loss= 0.2684321105480194\n",
      "epoch= 183 loss= 0.26728999614715576\n",
      "epoch= 184 loss= 0.2661571502685547\n",
      "epoch= 185 loss= 0.2650339901447296\n",
      "epoch= 186 loss= 0.2639201581478119\n",
      "epoch= 187 loss= 0.2628156244754791\n",
      "epoch= 188 loss= 0.26172012090682983\n",
      "epoch= 189 loss= 0.26063376665115356\n",
      "epoch= 190 loss= 0.2595563530921936\n",
      "epoch= 191 loss= 0.25848764181137085\n",
      "epoch= 192 loss= 0.2574275732040405\n",
      "epoch= 193 loss= 0.25637614727020264\n",
      "epoch= 194 loss= 0.2553332448005676\n",
      "epoch= 195 loss= 0.25429877638816833\n",
      "epoch= 196 loss= 0.2532724440097809\n",
      "epoch= 197 loss= 0.2522543668746948\n",
      "epoch= 198 loss= 0.25124430656433105\n",
      "epoch= 199 loss= 0.2502421736717224\n",
      "epoch= 200 loss= 0.24924808740615845\n",
      "epoch= 201 loss= 0.24826160073280334\n",
      "epoch= 202 loss= 0.24728307127952576\n",
      "epoch= 203 loss= 0.24631190299987793\n",
      "epoch= 204 loss= 0.24534842371940613\n",
      "epoch= 205 loss= 0.24439239501953125\n",
      "epoch= 206 loss= 0.24344350397586823\n",
      "epoch= 207 loss= 0.2425018697977066\n",
      "epoch= 208 loss= 0.24156755208969116\n",
      "epoch= 209 loss= 0.24064025282859802\n",
      "epoch= 210 loss= 0.23971989750862122\n",
      "epoch= 211 loss= 0.23880666494369507\n",
      "epoch= 212 loss= 0.23790007829666138\n",
      "epoch= 213 loss= 0.2370002269744873\n",
      "epoch= 214 loss= 0.23610718548297882\n",
      "epoch= 215 loss= 0.23522073030471802\n",
      "epoch= 216 loss= 0.23434090614318848\n",
      "epoch= 217 loss= 0.23346751928329468\n",
      "epoch= 218 loss= 0.23260051012039185\n",
      "epoch= 219 loss= 0.2317398488521576\n",
      "epoch= 220 loss= 0.23088553547859192\n",
      "epoch= 221 loss= 0.23003728687763214\n",
      "epoch= 222 loss= 0.22919511795043945\n",
      "epoch= 223 loss= 0.22835910320281982\n",
      "epoch= 224 loss= 0.22752895951271057\n",
      "epoch= 225 loss= 0.2267048954963684\n",
      "epoch= 226 loss= 0.22588667273521423\n",
      "epoch= 227 loss= 0.2250741422176361\n",
      "epoch= 228 loss= 0.22426725924015045\n",
      "epoch= 229 loss= 0.2234661877155304\n",
      "epoch= 230 loss= 0.2226708084344864\n",
      "epoch= 231 loss= 0.2218809872865677\n",
      "epoch= 232 loss= 0.2210964858531952\n",
      "epoch= 233 loss= 0.22031760215759277\n",
      "epoch= 234 loss= 0.21954402327537537\n",
      "epoch= 235 loss= 0.21877580881118774\n",
      "epoch= 236 loss= 0.21801283955574036\n",
      "epoch= 237 loss= 0.2172551453113556\n",
      "epoch= 238 loss= 0.21650245785713196\n",
      "epoch= 239 loss= 0.21575495600700378\n",
      "epoch= 240 loss= 0.21501260995864868\n",
      "epoch= 241 loss= 0.21427524089813232\n",
      "epoch= 242 loss= 0.21354275941848755\n",
      "epoch= 243 loss= 0.21281521022319794\n",
      "epoch= 244 loss= 0.2120925486087799\n",
      "epoch= 245 loss= 0.21137464046478271\n",
      "epoch= 246 loss= 0.21066159009933472\n",
      "epoch= 247 loss= 0.20995330810546875\n",
      "epoch= 248 loss= 0.209249347448349\n",
      "epoch= 249 loss= 0.208550363779068\n",
      "epoch= 250 loss= 0.20785579085350037\n",
      "epoch= 251 loss= 0.20716586709022522\n",
      "epoch= 252 loss= 0.20648032426834106\n",
      "epoch= 253 loss= 0.20579923689365387\n",
      "epoch= 254 loss= 0.20512251555919647\n",
      "epoch= 255 loss= 0.2044503092765808\n",
      "epoch= 256 loss= 0.203782320022583\n",
      "epoch= 257 loss= 0.2031184732913971\n",
      "epoch= 258 loss= 0.2024589478969574\n",
      "epoch= 259 loss= 0.2018037885427475\n",
      "epoch= 260 loss= 0.20115253329277039\n",
      "epoch= 261 loss= 0.2005053609609604\n",
      "epoch= 262 loss= 0.199862539768219\n",
      "epoch= 263 loss= 0.19922363758087158\n",
      "epoch= 264 loss= 0.19858857989311218\n",
      "epoch= 265 loss= 0.1979576051235199\n",
      "epoch= 266 loss= 0.1973305344581604\n",
      "epoch= 267 loss= 0.19670741260051727\n",
      "epoch= 268 loss= 0.19608822464942932\n",
      "epoch= 269 loss= 0.1954725682735443\n",
      "epoch= 270 loss= 0.19486090540885925\n",
      "epoch= 271 loss= 0.19425302743911743\n",
      "epoch= 272 loss= 0.19364866614341736\n",
      "epoch= 273 loss= 0.19304817914962769\n",
      "epoch= 274 loss= 0.19245105981826782\n",
      "epoch= 275 loss= 0.19185785949230194\n",
      "epoch= 276 loss= 0.19126802682876587\n",
      "epoch= 277 loss= 0.1906818449497223\n",
      "epoch= 278 loss= 0.19009923934936523\n",
      "epoch= 279 loss= 0.18951988220214844\n",
      "epoch= 280 loss= 0.18894414603710175\n",
      "epoch= 281 loss= 0.18837185204029083\n",
      "epoch= 282 loss= 0.1878029704093933\n",
      "epoch= 283 loss= 0.18723727762699127\n",
      "epoch= 284 loss= 0.18667501211166382\n",
      "epoch= 285 loss= 0.1861160844564438\n",
      "epoch= 286 loss= 0.18556039035320282\n",
      "epoch= 287 loss= 0.1850079745054245\n",
      "epoch= 288 loss= 0.18445879220962524\n",
      "epoch= 289 loss= 0.18391269445419312\n",
      "epoch= 290 loss= 0.1833697259426117\n",
      "epoch= 291 loss= 0.18282999098300934\n",
      "epoch= 292 loss= 0.18229332566261292\n",
      "epoch= 293 loss= 0.1817598044872284\n",
      "epoch= 294 loss= 0.18122923374176025\n",
      "epoch= 295 loss= 0.18070179224014282\n",
      "epoch= 296 loss= 0.1801772266626358\n",
      "epoch= 297 loss= 0.17965567111968994\n",
      "epoch= 298 loss= 0.17913717031478882\n",
      "epoch= 299 loss= 0.17862147092819214\n",
      "epoch= 300 loss= 0.17810872197151184\n",
      "epoch= 301 loss= 0.1775989532470703\n",
      "epoch= 302 loss= 0.17709192633628845\n",
      "epoch= 303 loss= 0.17658761143684387\n",
      "epoch= 304 loss= 0.17608627676963806\n",
      "epoch= 305 loss= 0.17558768391609192\n",
      "epoch= 306 loss= 0.175091952085495\n",
      "epoch= 307 loss= 0.1745988130569458\n",
      "epoch= 308 loss= 0.17410844564437866\n",
      "epoch= 309 loss= 0.17362074553966522\n",
      "epoch= 310 loss= 0.17313562333583832\n",
      "epoch= 311 loss= 0.17265328764915466\n",
      "epoch= 312 loss= 0.17217358946800232\n",
      "epoch= 313 loss= 0.17169642448425293\n",
      "epoch= 314 loss= 0.17122188210487366\n",
      "epoch= 315 loss= 0.17074984312057495\n",
      "epoch= 316 loss= 0.1702803373336792\n",
      "epoch= 317 loss= 0.16981348395347595\n",
      "epoch= 318 loss= 0.1693490445613861\n",
      "epoch= 319 loss= 0.16888706386089325\n",
      "epoch= 320 loss= 0.16842758655548096\n",
      "epoch= 321 loss= 0.1679704785346985\n",
      "epoch= 322 loss= 0.16751578450202942\n",
      "epoch= 323 loss= 0.16706368327140808\n",
      "epoch= 324 loss= 0.16661381721496582\n",
      "epoch= 325 loss= 0.1661663055419922\n",
      "epoch= 326 loss= 0.16572117805480957\n",
      "epoch= 327 loss= 0.1652783453464508\n",
      "epoch= 328 loss= 0.16483792662620544\n",
      "epoch= 329 loss= 0.16439974308013916\n",
      "epoch= 330 loss= 0.16396379470825195\n",
      "epoch= 331 loss= 0.1635301560163498\n",
      "epoch= 332 loss= 0.1630987823009491\n",
      "epoch= 333 loss= 0.1626695990562439\n",
      "epoch= 334 loss= 0.16224254667758942\n",
      "epoch= 335 loss= 0.16181766986846924\n",
      "epoch= 336 loss= 0.16139507293701172\n",
      "epoch= 337 loss= 0.1609746366739273\n",
      "epoch= 338 loss= 0.16055628657341003\n",
      "epoch= 339 loss= 0.16014015674591064\n",
      "epoch= 340 loss= 0.15972599387168884\n",
      "epoch= 341 loss= 0.15931396186351776\n",
      "epoch= 342 loss= 0.158904030919075\n",
      "epoch= 343 loss= 0.15849623084068298\n",
      "epoch= 344 loss= 0.15809029340744019\n",
      "epoch= 345 loss= 0.15768659114837646\n",
      "epoch= 346 loss= 0.15728473663330078\n",
      "epoch= 347 loss= 0.15688493847846985\n",
      "epoch= 348 loss= 0.1564871072769165\n",
      "epoch= 349 loss= 0.15609130263328552\n",
      "epoch= 350 loss= 0.15569740533828735\n",
      "epoch= 351 loss= 0.15530535578727722\n",
      "epoch= 352 loss= 0.15491557121276855\n",
      "epoch= 353 loss= 0.1545274555683136\n",
      "epoch= 354 loss= 0.15414123237133026\n",
      "epoch= 355 loss= 0.15375682711601257\n",
      "epoch= 356 loss= 0.15337446331977844\n",
      "epoch= 357 loss= 0.15299388766288757\n",
      "epoch= 358 loss= 0.15261514484882355\n",
      "epoch= 359 loss= 0.15223824977874756\n",
      "epoch= 360 loss= 0.1518632024526596\n",
      "epoch= 361 loss= 0.15148983895778656\n",
      "epoch= 362 loss= 0.15111833810806274\n",
      "epoch= 363 loss= 0.15074871480464935\n",
      "epoch= 364 loss= 0.15038076043128967\n",
      "epoch= 365 loss= 0.15001454949378967\n",
      "epoch= 366 loss= 0.1496502161026001\n",
      "epoch= 367 loss= 0.14928734302520752\n",
      "epoch= 368 loss= 0.14892640709877014\n",
      "epoch= 369 loss= 0.1485670804977417\n",
      "epoch= 370 loss= 0.1482096165418625\n",
      "epoch= 371 loss= 0.14785368740558624\n",
      "epoch= 372 loss= 0.14749935269355774\n",
      "epoch= 373 loss= 0.1471467763185501\n",
      "epoch= 374 loss= 0.146795853972435\n",
      "epoch= 375 loss= 0.14644652605056763\n",
      "epoch= 376 loss= 0.14609886705875397\n",
      "epoch= 377 loss= 0.14575275778770447\n",
      "epoch= 378 loss= 0.1454082429409027\n",
      "epoch= 379 loss= 0.14506542682647705\n",
      "epoch= 380 loss= 0.144724041223526\n",
      "epoch= 381 loss= 0.14438430964946747\n",
      "epoch= 382 loss= 0.14404624700546265\n",
      "epoch= 383 loss= 0.14370958507061005\n",
      "epoch= 384 loss= 0.14337457716464996\n",
      "epoch= 385 loss= 0.1430409550666809\n",
      "epoch= 386 loss= 0.14270883798599243\n",
      "epoch= 387 loss= 0.14237834513187408\n",
      "epoch= 388 loss= 0.14204932749271393\n",
      "epoch= 389 loss= 0.1417216956615448\n",
      "epoch= 390 loss= 0.1413956582546234\n",
      "epoch= 391 loss= 0.14107109606266022\n",
      "epoch= 392 loss= 0.14074786007404327\n",
      "epoch= 393 loss= 0.14042620360851288\n",
      "epoch= 394 loss= 0.14010602235794067\n",
      "epoch= 395 loss= 0.139786958694458\n",
      "epoch= 396 loss= 0.1394696831703186\n",
      "epoch= 397 loss= 0.1391536146402359\n",
      "epoch= 398 loss= 0.1388390064239502\n",
      "epoch= 399 loss= 0.13852570950984955\n",
      "epoch= 400 loss= 0.1382138729095459\n",
      "epoch= 401 loss= 0.1379033625125885\n",
      "epoch= 402 loss= 0.1375943124294281\n",
      "epoch= 403 loss= 0.13728652894496918\n",
      "epoch= 404 loss= 0.13698013126850128\n",
      "epoch= 405 loss= 0.13667500019073486\n",
      "epoch= 406 loss= 0.13637124001979828\n",
      "epoch= 407 loss= 0.13606882095336914\n",
      "epoch= 408 loss= 0.1357676386833191\n",
      "epoch= 409 loss= 0.1354677826166153\n",
      "epoch= 410 loss= 0.13516926765441895\n",
      "epoch= 411 loss= 0.13487204909324646\n",
      "epoch= 412 loss= 0.1345759779214859\n",
      "epoch= 413 loss= 0.13428135216236115\n",
      "epoch= 414 loss= 0.13398797810077667\n",
      "epoch= 415 loss= 0.13369572162628174\n",
      "epoch= 416 loss= 0.13340479135513306\n",
      "epoch= 417 loss= 0.1331152468919754\n",
      "epoch= 418 loss= 0.1328267753124237\n",
      "epoch= 419 loss= 0.13253946602344513\n",
      "epoch= 420 loss= 0.13225343823432922\n",
      "epoch= 421 loss= 0.1319686472415924\n",
      "epoch= 422 loss= 0.1316850483417511\n",
      "epoch= 423 loss= 0.13140249252319336\n",
      "epoch= 424 loss= 0.13112132251262665\n",
      "epoch= 425 loss= 0.1308412104845047\n",
      "epoch= 426 loss= 0.13056223094463348\n",
      "epoch= 427 loss= 0.13028448820114136\n",
      "epoch= 428 loss= 0.13000795245170593\n",
      "epoch= 429 loss= 0.12973251938819885\n",
      "epoch= 430 loss= 0.1294582188129425\n",
      "epoch= 431 loss= 0.1291850209236145\n",
      "epoch= 432 loss= 0.128913015127182\n",
      "epoch= 433 loss= 0.12864211201667786\n",
      "epoch= 434 loss= 0.1283724009990692\n",
      "epoch= 435 loss= 0.12810362875461578\n",
      "epoch= 436 loss= 0.12783589959144592\n",
      "epoch= 437 loss= 0.12756948173046112\n",
      "epoch= 438 loss= 0.12730392813682556\n",
      "epoch= 439 loss= 0.12703974545001984\n",
      "epoch= 440 loss= 0.12677648663520813\n",
      "epoch= 441 loss= 0.12651421129703522\n",
      "epoch= 442 loss= 0.12625305354595184\n",
      "epoch= 443 loss= 0.125993013381958\n",
      "epoch= 444 loss= 0.12573394179344177\n",
      "epoch= 445 loss= 0.1254759430885315\n",
      "epoch= 446 loss= 0.12521904706954956\n",
      "epoch= 447 loss= 0.12496314942836761\n",
      "epoch= 448 loss= 0.12470828741788864\n",
      "epoch= 449 loss= 0.12445428967475891\n",
      "epoch= 450 loss= 0.12420140206813812\n",
      "epoch= 451 loss= 0.1239495575428009\n",
      "epoch= 452 loss= 0.1236986443400383\n",
      "epoch= 453 loss= 0.12344877421855927\n",
      "epoch= 454 loss= 0.1231999397277832\n",
      "epoch= 455 loss= 0.1229519248008728\n",
      "epoch= 456 loss= 0.12270505726337433\n",
      "epoch= 457 loss= 0.1224590539932251\n",
      "epoch= 458 loss= 0.12221407890319824\n",
      "epoch= 459 loss= 0.12196992337703705\n",
      "epoch= 460 loss= 0.121726855635643\n",
      "epoch= 461 loss= 0.12148471176624298\n",
      "epoch= 462 loss= 0.12124355137348175\n",
      "epoch= 463 loss= 0.12100329995155334\n",
      "epoch= 464 loss= 0.12076403945684433\n",
      "epoch= 465 loss= 0.12052550166845322\n",
      "epoch= 466 loss= 0.12028812617063522\n",
      "epoch= 467 loss= 0.12005160748958588\n",
      "epoch= 468 loss= 0.1198158785700798\n",
      "epoch= 469 loss= 0.11958106607198715\n",
      "epoch= 470 loss= 0.11934716254472733\n",
      "epoch= 471 loss= 0.11911417543888092\n",
      "epoch= 472 loss= 0.11888222396373749\n",
      "epoch= 473 loss= 0.11865100264549255\n",
      "epoch= 474 loss= 0.11842069029808044\n",
      "epoch= 475 loss= 0.11819122731685638\n",
      "epoch= 476 loss= 0.11796262860298157\n",
      "epoch= 477 loss= 0.11773492395877838\n",
      "epoch= 478 loss= 0.11750806868076324\n",
      "epoch= 479 loss= 0.11728207767009735\n",
      "epoch= 480 loss= 0.11705692112445831\n",
      "epoch= 481 loss= 0.1168326735496521\n",
      "epoch= 482 loss= 0.11660922318696976\n",
      "epoch= 483 loss= 0.11638655513525009\n",
      "epoch= 484 loss= 0.11616484820842743\n",
      "epoch= 485 loss= 0.11594393849372864\n",
      "epoch= 486 loss= 0.11572380363941193\n",
      "epoch= 487 loss= 0.11550445109605789\n",
      "epoch= 488 loss= 0.11528600752353668\n",
      "epoch= 489 loss= 0.11506841331720352\n",
      "epoch= 490 loss= 0.11485141515731812\n",
      "epoch= 491 loss= 0.11463531851768494\n",
      "epoch= 492 loss= 0.11441994458436966\n",
      "epoch= 493 loss= 0.11420554667711258\n",
      "epoch= 494 loss= 0.11399185657501221\n",
      "epoch= 495 loss= 0.11377875506877899\n",
      "epoch= 496 loss= 0.11356675624847412\n",
      "epoch= 497 loss= 0.113355353474617\n",
      "epoch= 498 loss= 0.11314472556114197\n",
      "epoch= 499 loss= 0.11293487250804901\n",
      "epoch= 500 loss= 0.11272574961185455\n",
      "epoch= 501 loss= 0.11251746118068695\n",
      "epoch= 502 loss= 0.11230988800525665\n",
      "epoch= 503 loss= 0.11210297048091888\n",
      "epoch= 504 loss= 0.11189708113670349\n",
      "epoch= 505 loss= 0.11169172823429108\n",
      "epoch= 506 loss= 0.11148707568645477\n",
      "epoch= 507 loss= 0.11128321290016174\n",
      "epoch= 508 loss= 0.11108018457889557\n",
      "epoch= 509 loss= 0.11087781190872192\n",
      "epoch= 510 loss= 0.11067608743906021\n",
      "epoch= 511 loss= 0.1104750782251358\n",
      "epoch= 512 loss= 0.11027485132217407\n",
      "epoch= 513 loss= 0.11007539182901382\n",
      "epoch= 514 loss= 0.10987652838230133\n",
      "epoch= 515 loss= 0.10967831313610077\n",
      "epoch= 516 loss= 0.10948087275028229\n",
      "epoch= 517 loss= 0.10928413271903992\n",
      "epoch= 518 loss= 0.10908812284469604\n",
      "epoch= 519 loss= 0.10889282077550888\n",
      "epoch= 520 loss= 0.1086980402469635\n",
      "epoch= 521 loss= 0.10850416123867035\n",
      "epoch= 522 loss= 0.10831086337566376\n",
      "epoch= 523 loss= 0.1081182211637497\n",
      "epoch= 524 loss= 0.10792616009712219\n",
      "epoch= 525 loss= 0.10773488134145737\n",
      "epoch= 526 loss= 0.10754430294036865\n",
      "epoch= 527 loss= 0.10735425353050232\n",
      "epoch= 528 loss= 0.10716503858566284\n",
      "epoch= 529 loss= 0.10697628557682037\n",
      "epoch= 530 loss= 0.10678848624229431\n",
      "epoch= 531 loss= 0.10660097002983093\n",
      "epoch= 532 loss= 0.10641428083181381\n",
      "epoch= 533 loss= 0.10622817277908325\n",
      "epoch= 534 loss= 0.10604272037744522\n",
      "epoch= 535 loss= 0.10585790872573853\n",
      "epoch= 536 loss= 0.10567374527454376\n",
      "epoch= 537 loss= 0.10549010336399078\n",
      "epoch= 538 loss= 0.10530722141265869\n",
      "epoch= 539 loss= 0.10512499511241913\n",
      "epoch= 540 loss= 0.10494323074817657\n",
      "epoch= 541 loss= 0.10476216673851013\n",
      "epoch= 542 loss= 0.104581817984581\n",
      "epoch= 543 loss= 0.10440192371606827\n",
      "epoch= 544 loss= 0.10422273725271225\n",
      "epoch= 545 loss= 0.10404406487941742\n",
      "epoch= 546 loss= 0.10386598110198975\n",
      "epoch= 547 loss= 0.10368865728378296\n",
      "epoch= 548 loss= 0.10351180285215378\n",
      "epoch= 549 loss= 0.10333552211523056\n",
      "epoch= 550 loss= 0.10315988957881927\n",
      "epoch= 551 loss= 0.1029847115278244\n",
      "epoch= 552 loss= 0.10281017422676086\n",
      "epoch= 553 loss= 0.10263627767562866\n",
      "epoch= 554 loss= 0.10246296226978302\n",
      "epoch= 555 loss= 0.10229016840457916\n",
      "epoch= 556 loss= 0.10211808234453201\n",
      "epoch= 557 loss= 0.10194644331932068\n",
      "epoch= 558 loss= 0.1017753928899765\n",
      "epoch= 559 loss= 0.10160484910011292\n",
      "epoch= 560 loss= 0.10143496096134186\n",
      "epoch= 561 loss= 0.10126551985740662\n",
      "epoch= 562 loss= 0.10109665989875793\n",
      "epoch= 563 loss= 0.10092831403017044\n",
      "epoch= 564 loss= 0.10076060891151428\n",
      "epoch= 565 loss= 0.10059348493814468\n",
      "epoch= 566 loss= 0.10042674839496613\n",
      "epoch= 567 loss= 0.10026071965694427\n",
      "epoch= 568 loss= 0.10009521245956421\n",
      "epoch= 569 loss= 0.09993009269237518\n",
      "epoch= 570 loss= 0.0997656062245369\n",
      "epoch= 571 loss= 0.09960158169269562\n",
      "epoch= 572 loss= 0.09943825006484985\n",
      "epoch= 573 loss= 0.09927531331777573\n",
      "epoch= 574 loss= 0.09911295771598816\n",
      "epoch= 575 loss= 0.09895099699497223\n",
      "epoch= 576 loss= 0.09878972172737122\n",
      "epoch= 577 loss= 0.09862884879112244\n",
      "epoch= 578 loss= 0.09846848994493484\n",
      "epoch= 579 loss= 0.09830876439809799\n",
      "epoch= 580 loss= 0.09814943373203278\n",
      "epoch= 581 loss= 0.0979907363653183\n",
      "epoch= 582 loss= 0.09783224761486053\n",
      "epoch= 583 loss= 0.09767451882362366\n",
      "epoch= 584 loss= 0.0975172370672226\n",
      "epoch= 585 loss= 0.09736041724681854\n",
      "epoch= 586 loss= 0.09720422327518463\n",
      "epoch= 587 loss= 0.09704843163490295\n",
      "epoch= 588 loss= 0.09689314663410187\n",
      "epoch= 589 loss= 0.0967383086681366\n",
      "epoch= 590 loss= 0.09658387303352356\n",
      "epoch= 591 loss= 0.09643012285232544\n",
      "epoch= 592 loss= 0.09627670049667358\n",
      "epoch= 593 loss= 0.09612378478050232\n",
      "epoch= 594 loss= 0.09597133100032806\n",
      "epoch= 595 loss= 0.09581932425498962\n",
      "epoch= 596 loss= 0.09566795825958252\n",
      "epoch= 597 loss= 0.09551690518856049\n",
      "epoch= 598 loss= 0.09536637365818024\n",
      "epoch= 599 loss= 0.0952162891626358\n",
      "epoch= 600 loss= 0.09506678581237793\n",
      "epoch= 601 loss= 0.09491753578186035\n",
      "epoch= 602 loss= 0.09476886689662933\n",
      "epoch= 603 loss= 0.09462064504623413\n",
      "epoch= 604 loss= 0.09447280317544937\n",
      "epoch= 605 loss= 0.09432553499937057\n",
      "epoch= 606 loss= 0.09417860209941864\n",
      "epoch= 607 loss= 0.09403222799301147\n",
      "epoch= 608 loss= 0.09388625621795654\n",
      "epoch= 609 loss= 0.09374072402715683\n",
      "epoch= 610 loss= 0.09359557926654816\n",
      "epoch= 611 loss= 0.09345100820064545\n",
      "epoch= 612 loss= 0.0933067575097084\n",
      "epoch= 613 loss= 0.09316296130418777\n",
      "epoch= 614 loss= 0.09301966428756714\n",
      "epoch= 615 loss= 0.09287676215171814\n",
      "epoch= 616 loss= 0.09273430705070496\n",
      "epoch= 617 loss= 0.09259217232465744\n",
      "epoch= 618 loss= 0.09245055168867111\n",
      "epoch= 619 loss= 0.09230943769216537\n",
      "epoch= 620 loss= 0.09216852486133575\n",
      "epoch= 621 loss= 0.09202830493450165\n",
      "epoch= 622 loss= 0.09188834577798843\n",
      "epoch= 623 loss= 0.09174877405166626\n",
      "epoch= 624 loss= 0.09160958230495453\n",
      "epoch= 625 loss= 0.09147097170352936\n",
      "epoch= 626 loss= 0.09133267402648926\n",
      "epoch= 627 loss= 0.09119482338428497\n",
      "epoch= 628 loss= 0.09105736017227173\n",
      "epoch= 629 loss= 0.09092028439044952\n",
      "epoch= 630 loss= 0.09078365564346313\n",
      "epoch= 631 loss= 0.09064739942550659\n",
      "epoch= 632 loss= 0.09051166474819183\n",
      "epoch= 633 loss= 0.0903761237859726\n",
      "epoch= 634 loss= 0.09024114906787872\n",
      "epoch= 635 loss= 0.09010636806488037\n",
      "epoch= 636 loss= 0.08997216820716858\n",
      "epoch= 637 loss= 0.08983834832906723\n",
      "epoch= 638 loss= 0.0897047221660614\n",
      "epoch= 639 loss= 0.08957172930240631\n",
      "epoch= 640 loss= 0.08943912386894226\n",
      "epoch= 641 loss= 0.08930683881044388\n",
      "epoch= 642 loss= 0.08917486667633057\n",
      "epoch= 643 loss= 0.08904340863227844\n",
      "epoch= 644 loss= 0.08891215175390244\n",
      "epoch= 645 loss= 0.08878139406442642\n",
      "epoch= 646 loss= 0.08865096420049667\n",
      "epoch= 647 loss= 0.08852097392082214\n",
      "epoch= 648 loss= 0.08839130401611328\n",
      "epoch= 649 loss= 0.08826208114624023\n",
      "epoch= 650 loss= 0.08813317120075226\n",
      "epoch= 651 loss= 0.08800452947616577\n",
      "epoch= 652 loss= 0.08787645399570465\n",
      "epoch= 653 loss= 0.08774857223033905\n",
      "epoch= 654 loss= 0.08762113749980927\n",
      "epoch= 655 loss= 0.08749409019947052\n",
      "epoch= 656 loss= 0.08736729621887207\n",
      "epoch= 657 loss= 0.08724106103181839\n",
      "epoch= 658 loss= 0.08711497485637665\n",
      "epoch= 659 loss= 0.08698932081460953\n",
      "epoch= 660 loss= 0.08686399459838867\n",
      "epoch= 661 loss= 0.08673916757106781\n",
      "epoch= 662 loss= 0.08661460131406784\n",
      "epoch= 663 loss= 0.08649035543203354\n",
      "epoch= 664 loss= 0.08636637032032013\n",
      "epoch= 665 loss= 0.08624294400215149\n",
      "epoch= 666 loss= 0.08611972630023956\n",
      "epoch= 667 loss= 0.08599687367677689\n",
      "epoch= 668 loss= 0.08587440848350525\n",
      "epoch= 669 loss= 0.0857522040605545\n",
      "epoch= 670 loss= 0.08563044667243958\n",
      "epoch= 671 loss= 0.08550906181335449\n",
      "epoch= 672 loss= 0.0853879302740097\n",
      "epoch= 673 loss= 0.08526712656021118\n",
      "epoch= 674 loss= 0.08514657616615295\n",
      "epoch= 675 loss= 0.08502653241157532\n",
      "epoch= 676 loss= 0.08490674942731857\n",
      "epoch= 677 loss= 0.08478721231222153\n",
      "epoch= 678 loss= 0.08466807007789612\n",
      "epoch= 679 loss= 0.08454917371273041\n",
      "epoch= 680 loss= 0.08443084359169006\n",
      "epoch= 681 loss= 0.08431264758110046\n",
      "epoch= 682 loss= 0.08419501781463623\n",
      "epoch= 683 loss= 0.0840773954987526\n",
      "epoch= 684 loss= 0.08396027982234955\n",
      "epoch= 685 loss= 0.08384335786104202\n",
      "epoch= 686 loss= 0.08372680842876434\n",
      "epoch= 687 loss= 0.0836106538772583\n",
      "epoch= 688 loss= 0.08349461853504181\n",
      "epoch= 689 loss= 0.08337921649217606\n",
      "epoch= 690 loss= 0.0832638218998909\n",
      "epoch= 691 loss= 0.08314892649650574\n",
      "epoch= 692 loss= 0.08303429186344147\n",
      "epoch= 693 loss= 0.08291991055011749\n",
      "epoch= 694 loss= 0.08280591666698456\n",
      "epoch= 695 loss= 0.08269216865301132\n",
      "epoch= 696 loss= 0.08257868140935898\n",
      "epoch= 697 loss= 0.08246569335460663\n",
      "epoch= 698 loss= 0.08235277235507965\n",
      "epoch= 699 loss= 0.08224041759967804\n",
      "epoch= 700 loss= 0.08212820440530777\n",
      "epoch= 701 loss= 0.0820162370800972\n",
      "epoch= 702 loss= 0.08190470933914185\n",
      "epoch= 703 loss= 0.08179332315921783\n",
      "epoch= 704 loss= 0.08168242871761322\n",
      "epoch= 705 loss= 0.08157160878181458\n",
      "epoch= 706 loss= 0.08146123588085175\n",
      "epoch= 707 loss= 0.08135116845369339\n",
      "epoch= 708 loss= 0.08124129474163055\n",
      "epoch= 709 loss= 0.0811319351196289\n",
      "epoch= 710 loss= 0.08102256804704666\n",
      "epoch= 711 loss= 0.08091370761394501\n",
      "epoch= 712 loss= 0.08080492168664932\n",
      "epoch= 713 loss= 0.08069656789302826\n",
      "epoch= 714 loss= 0.08058854192495346\n",
      "epoch= 715 loss= 0.08048076182603836\n",
      "epoch= 716 loss= 0.080373115837574\n",
      "epoch= 717 loss= 0.08026602864265442\n",
      "epoch= 718 loss= 0.08015895634889603\n",
      "epoch= 719 loss= 0.08005225658416748\n",
      "epoch= 720 loss= 0.0799458771944046\n",
      "epoch= 721 loss= 0.07983987033367157\n",
      "epoch= 722 loss= 0.0797339379787445\n",
      "epoch= 723 loss= 0.07962831854820251\n",
      "epoch= 724 loss= 0.07952307164669037\n",
      "epoch= 725 loss= 0.07941808551549911\n",
      "epoch= 726 loss= 0.07931335270404816\n",
      "epoch= 727 loss= 0.07920880615711212\n",
      "epoch= 728 loss= 0.07910464704036713\n",
      "epoch= 729 loss= 0.07900067418813705\n",
      "epoch= 730 loss= 0.07889695465564728\n",
      "epoch= 731 loss= 0.07879355549812317\n",
      "epoch= 732 loss= 0.07869058847427368\n",
      "epoch= 733 loss= 0.07858763635158539\n",
      "epoch= 734 loss= 0.07848511636257172\n",
      "epoch= 735 loss= 0.07838266342878342\n",
      "epoch= 736 loss= 0.07828059047460556\n",
      "epoch= 737 loss= 0.0781787782907486\n",
      "epoch= 738 loss= 0.0780772715806961\n",
      "epoch= 739 loss= 0.07797589898109436\n",
      "epoch= 740 loss= 0.07787489891052246\n",
      "epoch= 741 loss= 0.07777415961027145\n",
      "epoch= 742 loss= 0.07767359912395477\n",
      "epoch= 743 loss= 0.0775732472538948\n",
      "epoch= 744 loss= 0.07747326791286469\n",
      "epoch= 745 loss= 0.07737352699041367\n",
      "epoch= 746 loss= 0.07727405428886414\n",
      "epoch= 747 loss= 0.0771748274564743\n",
      "epoch= 748 loss= 0.07707573473453522\n",
      "epoch= 749 loss= 0.07697689533233643\n",
      "epoch= 750 loss= 0.07687848806381226\n",
      "epoch= 751 loss= 0.07678021490573883\n",
      "epoch= 752 loss= 0.07668231427669525\n",
      "epoch= 753 loss= 0.0765843614935875\n",
      "epoch= 754 loss= 0.07648690789937973\n",
      "epoch= 755 loss= 0.07638964056968689\n",
      "epoch= 756 loss= 0.07629269361495972\n",
      "epoch= 757 loss= 0.07619581371545792\n",
      "epoch= 758 loss= 0.07609930634498596\n",
      "epoch= 759 loss= 0.07600300014019012\n",
      "epoch= 760 loss= 0.07590687274932861\n",
      "epoch= 761 loss= 0.075811006128788\n",
      "epoch= 762 loss= 0.07571545243263245\n",
      "epoch= 763 loss= 0.07562008500099182\n",
      "epoch= 764 loss= 0.07552503049373627\n",
      "epoch= 765 loss= 0.07543005049228668\n",
      "epoch= 766 loss= 0.07533550262451172\n",
      "epoch= 767 loss= 0.0752410888671875\n",
      "epoch= 768 loss= 0.07514685392379761\n",
      "epoch= 769 loss= 0.07505294680595398\n",
      "epoch= 770 loss= 0.0749591588973999\n",
      "epoch= 771 loss= 0.0748656839132309\n",
      "epoch= 772 loss= 0.07477252930402756\n",
      "epoch= 773 loss= 0.07467931509017944\n",
      "epoch= 774 loss= 0.0745866596698761\n",
      "epoch= 775 loss= 0.07449407875537872\n",
      "epoch= 776 loss= 0.07440168410539627\n",
      "epoch= 777 loss= 0.07430954277515411\n",
      "epoch= 778 loss= 0.07421764731407166\n",
      "epoch= 779 loss= 0.07412601262331009\n",
      "epoch= 780 loss= 0.07403449714183807\n",
      "epoch= 781 loss= 0.07394329458475113\n",
      "epoch= 782 loss= 0.07385235279798508\n",
      "epoch= 783 loss= 0.07376159727573395\n",
      "epoch= 784 loss= 0.07367096841335297\n",
      "epoch= 785 loss= 0.07358071208000183\n",
      "epoch= 786 loss= 0.07349053025245667\n",
      "epoch= 787 loss= 0.0734005942940712\n",
      "epoch= 788 loss= 0.07331091165542603\n",
      "epoch= 789 loss= 0.073221355676651\n",
      "epoch= 790 loss= 0.07313211262226105\n",
      "epoch= 791 loss= 0.07304306328296661\n",
      "epoch= 792 loss= 0.07295425981283188\n",
      "epoch= 793 loss= 0.07286553084850311\n",
      "epoch= 794 loss= 0.0727771669626236\n",
      "epoch= 795 loss= 0.07268887758255005\n",
      "epoch= 796 loss= 0.07260089367628098\n",
      "epoch= 797 loss= 0.0725131630897522\n",
      "epoch= 798 loss= 0.07242562621831894\n",
      "epoch= 799 loss= 0.07233815640211105\n",
      "epoch= 800 loss= 0.07225105911493301\n",
      "epoch= 801 loss= 0.07216396182775497\n",
      "epoch= 802 loss= 0.0720774307847023\n",
      "epoch= 803 loss= 0.07199077308177948\n",
      "epoch= 804 loss= 0.07190443575382233\n",
      "epoch= 805 loss= 0.07181835174560547\n",
      "epoch= 806 loss= 0.07173238694667816\n",
      "epoch= 807 loss= 0.07164660841226578\n",
      "epoch= 808 loss= 0.07156115025281906\n",
      "epoch= 809 loss= 0.07147581875324249\n",
      "epoch= 810 loss= 0.07139061391353607\n",
      "epoch= 811 loss= 0.0713057890534401\n",
      "epoch= 812 loss= 0.07122095674276352\n",
      "epoch= 813 loss= 0.07113644480705261\n",
      "epoch= 814 loss= 0.0710521787405014\n",
      "epoch= 815 loss= 0.07096798717975616\n",
      "epoch= 816 loss= 0.07088404148817062\n",
      "epoch= 817 loss= 0.07080034166574478\n",
      "epoch= 818 loss= 0.07071677595376968\n",
      "epoch= 819 loss= 0.07063333690166473\n",
      "epoch= 820 loss= 0.07055027037858963\n",
      "epoch= 821 loss= 0.0704672634601593\n",
      "epoch= 822 loss= 0.07038445770740509\n",
      "epoch= 823 loss= 0.07030189037322998\n",
      "epoch= 824 loss= 0.07021951675415039\n",
      "epoch= 825 loss= 0.07013721764087677\n",
      "epoch= 826 loss= 0.07005521655082703\n",
      "epoch= 827 loss= 0.0699734091758728\n",
      "epoch= 828 loss= 0.06989172846078873\n",
      "epoch= 829 loss= 0.06981036067008972\n",
      "epoch= 830 loss= 0.06972911953926086\n",
      "epoch= 831 loss= 0.06964807212352753\n",
      "epoch= 832 loss= 0.06956714391708374\n",
      "epoch= 833 loss= 0.06948640942573547\n",
      "epoch= 834 loss= 0.06940586119890213\n",
      "epoch= 835 loss= 0.0693255066871643\n",
      "epoch= 836 loss= 0.06924539804458618\n",
      "epoch= 837 loss= 0.06916534900665283\n",
      "epoch= 838 loss= 0.06908556073904037\n",
      "epoch= 839 loss= 0.06900595128536224\n",
      "epoch= 840 loss= 0.06892647594213486\n",
      "epoch= 841 loss= 0.06884737312793732\n",
      "epoch= 842 loss= 0.068768210709095\n",
      "epoch= 843 loss= 0.06868930160999298\n",
      "epoch= 844 loss= 0.06861057877540588\n",
      "epoch= 845 loss= 0.06853209435939789\n",
      "epoch= 846 loss= 0.06845362484455109\n",
      "epoch= 847 loss= 0.06837552785873413\n",
      "epoch= 848 loss= 0.06829756498336792\n",
      "epoch= 849 loss= 0.06821965426206589\n",
      "epoch= 850 loss= 0.06814199686050415\n",
      "epoch= 851 loss= 0.06806440651416779\n",
      "epoch= 852 loss= 0.06798724830150604\n",
      "epoch= 853 loss= 0.06791003793478012\n",
      "epoch= 854 loss= 0.0678330734372139\n",
      "epoch= 855 loss= 0.0677562952041626\n",
      "epoch= 856 loss= 0.06767971068620682\n",
      "epoch= 857 loss= 0.06760337203741074\n",
      "epoch= 858 loss= 0.0675269141793251\n",
      "epoch= 859 loss= 0.06745082139968872\n",
      "epoch= 860 loss= 0.06737492978572845\n",
      "epoch= 861 loss= 0.06729921698570251\n",
      "epoch= 862 loss= 0.0672234445810318\n",
      "epoch= 863 loss= 0.0671481192111969\n",
      "epoch= 864 loss= 0.06707284599542618\n",
      "epoch= 865 loss= 0.0669977068901062\n",
      "epoch= 866 loss= 0.0669228732585907\n",
      "epoch= 867 loss= 0.06684798002243042\n",
      "epoch= 868 loss= 0.06677339971065521\n",
      "epoch= 869 loss= 0.06669901311397552\n",
      "epoch= 870 loss= 0.06662468612194061\n",
      "epoch= 871 loss= 0.066550612449646\n",
      "epoch= 872 loss= 0.06647653877735138\n",
      "epoch= 873 loss= 0.06640283763408661\n",
      "epoch= 874 loss= 0.06632907688617706\n",
      "epoch= 875 loss= 0.06625574827194214\n",
      "epoch= 876 loss= 0.06618242710828781\n",
      "epoch= 877 loss= 0.06610923260450363\n",
      "epoch= 878 loss= 0.06603628396987915\n",
      "epoch= 879 loss= 0.06596340239048004\n",
      "epoch= 880 loss= 0.06589069962501526\n",
      "epoch= 881 loss= 0.06581813097000122\n",
      "epoch= 882 loss= 0.06574587523937225\n",
      "epoch= 883 loss= 0.06567355990409851\n",
      "epoch= 884 loss= 0.06560155004262924\n",
      "epoch= 885 loss= 0.0655297338962555\n",
      "epoch= 886 loss= 0.06545791774988174\n",
      "epoch= 887 loss= 0.06538641452789307\n",
      "epoch= 888 loss= 0.06531503796577454\n",
      "epoch= 889 loss= 0.065243661403656\n",
      "epoch= 890 loss= 0.06517259031534195\n",
      "epoch= 891 loss= 0.06510158628225327\n",
      "epoch= 892 loss= 0.0650307759642601\n",
      "epoch= 893 loss= 0.06496008485555649\n",
      "epoch= 894 loss= 0.06488963961601257\n",
      "epoch= 895 loss= 0.06481920927762985\n",
      "epoch= 896 loss= 0.06474901735782623\n",
      "epoch= 897 loss= 0.06467901915311813\n",
      "epoch= 898 loss= 0.06460902094841003\n",
      "epoch= 899 loss= 0.06453926861286163\n",
      "epoch= 900 loss= 0.0644695907831192\n",
      "epoch= 901 loss= 0.06440027803182602\n",
      "epoch= 902 loss= 0.06433083862066269\n",
      "epoch= 903 loss= 0.0642617791891098\n",
      "epoch= 904 loss= 0.06419266015291214\n",
      "epoch= 905 loss= 0.06412384659051895\n",
      "epoch= 906 loss= 0.06405510008335114\n",
      "epoch= 907 loss= 0.06398648023605347\n",
      "epoch= 908 loss= 0.0639181062579155\n",
      "epoch= 909 loss= 0.06384973973035812\n",
      "epoch= 910 loss= 0.06378155946731567\n",
      "epoch= 911 loss= 0.06371362507343292\n",
      "epoch= 912 loss= 0.06364575028419495\n",
      "epoch= 913 loss= 0.06357795000076294\n",
      "epoch= 914 loss= 0.06351032853126526\n",
      "epoch= 915 loss= 0.06344301998615265\n",
      "epoch= 916 loss= 0.06337559223175049\n",
      "epoch= 917 loss= 0.0633084699511528\n",
      "epoch= 918 loss= 0.06324148178100586\n",
      "epoch= 919 loss= 0.0631745457649231\n",
      "epoch= 920 loss= 0.06310787051916122\n",
      "epoch= 921 loss= 0.06304125487804413\n",
      "epoch= 922 loss= 0.06297482550144196\n",
      "epoch= 923 loss= 0.06290845572948456\n",
      "epoch= 924 loss= 0.06284221261739731\n",
      "epoch= 925 loss= 0.06277622282505035\n",
      "epoch= 926 loss= 0.0627102330327034\n",
      "epoch= 927 loss= 0.06264442205429077\n",
      "epoch= 928 loss= 0.06257887184619904\n",
      "epoch= 929 loss= 0.0625133216381073\n",
      "epoch= 930 loss= 0.062448013573884964\n",
      "epoch= 931 loss= 0.0623827762901783\n",
      "epoch= 932 loss= 0.06231759861111641\n",
      "epoch= 933 loss= 0.06225267052650452\n",
      "epoch= 934 loss= 0.0621878020465374\n",
      "epoch= 935 loss= 0.0621231272816658\n",
      "epoch= 936 loss= 0.06205851212143898\n",
      "epoch= 937 loss= 0.061994146555662155\n",
      "epoch= 938 loss= 0.06192977726459503\n",
      "epoch= 939 loss= 0.06186560541391373\n",
      "epoch= 940 loss= 0.06180161237716675\n",
      "epoch= 941 loss= 0.06173762306571007\n",
      "epoch= 942 loss= 0.06167394667863846\n",
      "epoch= 943 loss= 0.06161027029156685\n",
      "epoch= 944 loss= 0.06154678016901016\n",
      "epoch= 945 loss= 0.061483412981033325\n",
      "epoch= 946 loss= 0.06142011284828186\n",
      "epoch= 947 loss= 0.06135699898004532\n",
      "epoch= 948 loss= 0.06129394471645355\n",
      "epoch= 949 loss= 0.06123114377260208\n",
      "epoch= 950 loss= 0.061168283224105835\n",
      "epoch= 951 loss= 0.06110572814941406\n",
      "epoch= 952 loss= 0.061043113470077515\n",
      "epoch= 953 loss= 0.06098080798983574\n",
      "epoch= 954 loss= 0.06091850996017456\n",
      "epoch= 955 loss= 0.06085645407438278\n",
      "epoch= 956 loss= 0.060794342309236526\n",
      "epoch= 957 loss= 0.06073260307312012\n",
      "epoch= 958 loss= 0.06067086011171341\n",
      "epoch= 959 loss= 0.060609184205532074\n",
      "epoch= 960 loss= 0.060547634959220886\n",
      "epoch= 961 loss= 0.06048627197742462\n",
      "epoch= 962 loss= 0.06042502820491791\n",
      "epoch= 963 loss= 0.06036379188299179\n",
      "epoch= 964 loss= 0.06030286103487015\n",
      "epoch= 965 loss= 0.06024199351668358\n",
      "epoch= 966 loss= 0.06018119305372238\n",
      "epoch= 967 loss= 0.06012063845992088\n",
      "epoch= 968 loss= 0.06006002426147461\n",
      "epoch= 969 loss= 0.05999971926212311\n",
      "epoch= 970 loss= 0.05993935465812683\n",
      "epoch= 971 loss= 0.05987923964858055\n",
      "epoch= 972 loss= 0.05981924757361412\n",
      "epoch= 973 loss= 0.05975925922393799\n",
      "epoch= 974 loss= 0.05969933420419693\n",
      "epoch= 975 loss= 0.059639714658260345\n",
      "epoch= 976 loss= 0.059580158442258835\n",
      "epoch= 977 loss= 0.0595206692814827\n",
      "epoch= 978 loss= 0.05946142226457596\n",
      "epoch= 979 loss= 0.05940205976366997\n",
      "epoch= 980 loss= 0.059342943131923676\n",
      "epoch= 981 loss= 0.05928407609462738\n",
      "epoch= 982 loss= 0.059225209057331085\n",
      "epoch= 983 loss= 0.059166401624679565\n",
      "epoch= 984 loss= 0.05910772457718849\n",
      "epoch= 985 loss= 0.059049226343631744\n",
      "epoch= 986 loss= 0.05899079889059067\n",
      "epoch= 987 loss= 0.05893249437212944\n",
      "epoch= 988 loss= 0.05887431278824806\n",
      "epoch= 989 loss= 0.05881619453430176\n",
      "epoch= 990 loss= 0.0587581992149353\n",
      "epoch= 991 loss= 0.05870039761066437\n",
      "epoch= 992 loss= 0.058642711490392685\n",
      "epoch= 993 loss= 0.05858496576547623\n",
      "epoch= 994 loss= 0.058527473360300064\n",
      "epoch= 995 loss= 0.05847010016441345\n",
      "epoch= 996 loss= 0.058412857353687286\n",
      "epoch= 997 loss= 0.05835561081767082\n",
      "epoch= 998 loss= 0.05829861760139465\n",
      "epoch= 999 loss= 0.058241501450538635\n",
      "w= 7.077388763427734\n",
      "b= -17.51447296142578\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAezklEQVR4nO3deZhddZ3n8ff3rrWlKpVUZU9IIGnWkYBlWLubEZfIKOl5BIVWRMWHp1VGnNGx1XaZ1v5Dn+4HRxsHpN3QyeACqJFGEYFGUUmshCSEBKSSYHZS2SpVqdRy7/3OH+fcyq3KTVJZTt2qOp/X89znnnPu7577PRzgU7/zO4u5OyIiEl+JShcgIiKVpSAQEYk5BYGISMwpCEREYk5BICISc6lKF3CympqafO7cuZUuQ0RkTFm5cuUed28u99mYC4K5c+fS2tpa6TJERMYUM/vzsT7ToSERkZhTEIiIxJyCQEQk5hQEIiIxpyAQEYm5yILAzKrMbIWZrTGzF8zsH8u0yZrZD82szcyWm9ncqOoREZHyouwR9AKvd/eLgYXAYjO7fEib24D97j4f+Arw5QjrERGRMiILAg90hbPp8DX0ntdLgPvD6QeBa83MoqjnpV2d3PWrl9jT1RvF6kVExqxIxwjMLGlmq4HdwOPuvnxIk5nAVgB3zwEdwOQy67ndzFrNrLW9vf2Uamnb3cXXnmxj36G+U/q+iMh4FWkQuHve3RcCs4BFZnbRKa7nPndvcfeW5uayV0ifUCLsZxT0IB4RkUFG5Kwhdz8APAUsHvLRdmA2gJmlgAZgbxQ1FA84FQpRrF1EZOyK8qyhZjObGE5XA28EXhzSbBlwazh9A/CkR/TszOLQgx81TCEiEm9R3nRuOnC/mSUJAudH7v6ImX0BaHX3ZcC3gO+bWRuwD7gpqmKKI9A6MiQiMlhkQeDua4FLyiz/XMl0D3BjVDWUShR7BAoCEZFBYnNlcSLcUg0Wi4gMFpsgsPDgkIJARGSw+ARBOEigGBARGSxGQVAcI1AUiIiUik0QFC8oUw6IiAwWoyAojhFUuBARkVEmNkFQvI5Ag8UiIoPFJwh0HYGISFkxCoLgXYPFIiKDxSYINEYgIlJejIIgeNdN50REBotNEAzchlo5ICIySIyCQBeUiYiUE5sg0N1HRUTKi00Q6DoCEZHyYhME6hGIiJQXmyAwPbxeRKSs2AWBYkBEZLDYBEFCZw2JiJQVmyDQdQQiIuXFJgg0WCwiUl5sgkCnj4qIlBefICj2CCpch4jIaBObIEjoNtQiImVFFgRmNtvMnjKz9Wb2gpndWabNNWbWYWarw9fnIqwH0KEhEZGhUhGuOwd8zN1XmdkEYKWZPe7u64e0+627vzXCOgA9vF5E5Fgi6xG4+053XxVOdwIbgJlR/d6J6ME0IiLljcgYgZnNBS4Blpf5+AozW2NmvzCzC4/x/dvNrNXMWtvb20+rFh0aEhEZLPIgMLM64CHgo+5+cMjHq4Cz3P1i4F+Bn5Zbh7vf5+4t7t7S3Nx8SnUkErrHhIhIOZEGgZmlCUJgqbs/PPRzdz/o7l3h9KNA2syaIqklfFePQERksCjPGjLgW8AGd7/rGG2mhe0ws0VhPXujqCeh6whERMqK8qyhq4BbgOfNbHW47NPAHAB3vxe4AfigmeWAw8BNHtGJ/gndhlpEpKzIgsDdn+HIEZljtbkbuDuqGgbRTedERMqK0ZXFupBARKSc2ATBkcHiipYhIjLqxCYI9GAaEZHyYhcE6hGIiAwWmyBAZw2JiJQVmyBIHPf8JRGR+IpNEOg21CIi5cUmCBK6jkBEpKwYBYEeXi8iUk5sgsA0WCwiUlZsgiCVCDY1l1cQiIiUik0QJBOGGeQKhUqXIiIyqsQmCADSiQT96hGIiAwSqyBIJY1cXj0CEZFS8QqChJHT+aMiIoPEKgjSyQT96hGIiAwSqyAIDg2pRyAiUipeQZBI0K+zhkREBolVEKTVIxAROUqsgiCVTOg6AhGRIeIVBAnTdQQiIkPEKgjSyYSuIxARGSJWQZBK6joCEZGhYhUEwS0m1CMQESkVqyDQdQQiIkeLLAjMbLaZPWVm683sBTO7s0wbM7OvmVmbma01s0ujqgcgk0rQpx6BiMggqQjXnQM+5u6rzGwCsNLMHnf39SVt3gIsCF+XAfeE75GoTifp6c9HtXoRkTEpsh6Bu+9091XhdCewAZg5pNkS4HseeBaYaGbTo6qpOp3ksIJARGSQERkjMLO5wCXA8iEfzQS2lsxv4+iwwMxuN7NWM2ttb28/5TqqMkkO9+nQkIhIqciDwMzqgIeAj7r7wVNZh7vf5+4t7t7S3Nx8yrXo0JCIyNEiDQIzSxOEwFJ3f7hMk+3A7JL5WeGySBQPDbkeYC8iMiDKs4YM+Bawwd3vOkazZcB7wrOHLgc63H1nVDVVZ5LkC67bTIiIlIjyrKGrgFuA581sdbjs08AcAHe/F3gUuA5oA7qB90VYD9lUkHuH+/NkUrG6hEJE5JgiCwJ3fwawE7Rx4MNR1TBUdSYJQE9/nobq9Ej9rIjIqBarP4ur00EQHO7TgLGISFE8g0BnDomIDIhVEFRlFAQiIkPFKgiKPYIeHRoSERkQyyBQj0BE5Ih4BYEODYmIHCVeQRD2CLp1aEhEZECsgqA2G1w20d2bq3AlIiKjR8yCIOgRdCkIREQGxCoIsqkkmWSCrl4dGhIRKYpVEADUVaXo6u2vdBkiIqNG/IIgm6KrR4eGRESKYhcEtdmUxghERErELggmKAhERAaJXRAEYwQKAhGRovgFgcYIREQGiV0QaIxARGSw2AXBBB0aEhEZJHZBUJdN0dNfoD9fqHQpIiKjQuyCoHi/oUPqFYiIAMMMAjO708zqLfAtM1tlZm+KurgoTAiDoFMDxiIiwPB7BO9394PAm4BG4BbgS5FVFaG6qrBH0KcgEBGB4QeBhe/XAd939xdKlo0pdWGPQKeQiogEhhsEK83sVwRB8JiZTQDG5GhrrQ4NiYgMkhpmu9uAhcAmd+82s0nA+yKrKkIN1WkAOg7rDqQiIjD8HsEVwEvufsDM3g18Bug43hfM7NtmttvM1h3j82vMrMPMVoevz51c6aemsSYIgv3dfSPxcyIio95wg+AeoNvMLgY+BmwEvneC73wXWHyCNr9194Xh6wvDrOW0FHsE+7vVIxARgeEHQc7dHVgC3O3uXwcmHO8L7v4bYN9p1nfGpZIJ6qtSHFCPQEQEGH4QdJrZpwhOG/13M0sA6TPw+1eY2Roz+4WZXXisRmZ2u5m1mllre3v7af/opNqMegQiIqHhBsE7gV6C6wl2AbOAfz7N314FnOXuFwP/Cvz0WA3d/T53b3H3lubm5tP8WZhYk1GPQEQkNKwgCP/nvxRoMLO3Aj3ufqIxghOt86C7d4XTjwJpM2s6nXUOV2NNWoPFIiKh4d5i4h3ACuBG4B3AcjO74XR+2MymmZmF04vCWvaezjqHq7Emw/5DOjQkIgLDv47gH4DXuftuADNrBn4NPHisL5jZA8A1QJOZbQM+Tziu4O73AjcAHzSzHHAYuCkckI6cDg2JiBwx3CBIFEMgtJcT9Cbc/eYTfH43cPcwf/+MaqxJc6gvT1+uQCYVuxuwiogMMtwg+KWZPQY8EM6/E3g0mpKiN7E2A8CB7j6m1FdVuBoRkcoaVhC4+/80s7cDV4WL7nP3n0RXVrSOXF3cryAQkdgbbo8Ad38IeCjCWkZMY03QI9CZQyIiJwgCM+sEyg3gGuDuXh9JVRGbGPYINGAsInKCIHD3495GYqw60iPQKaQiIrE8ZUaHhkREjohlEFRnktRkkuztUhCIiMQyCACm1lex62BPpcsQEam4GAdBllc7FAQiIrENgmnqEYiIADEOgqkNVew+2EuhMCK3NxIRGbViGwTT6qvoyxfYpzOHRCTmYh0EALs0TiAiMRfbIJjaEATBqxonEJGYi20QDPQIFAQiEnOxDYLmCVnM0CmkIhJ7sQ2CdDJBU11WPQIRib3YBgHA9IYqdqpHICIxF+sgmD2phi37uitdhohIRcU6CM5uqmXrvm76coVKlyIiUjGxDoJ5TbUUHLbuV69AROIr9kEAsLn9UIUrERGpHAUBsHmPgkBE4ivWQTCxJkNjTZpNCgIRibHIgsDMvm1mu81s3TE+NzP7mpm1mdlaM7s0qlqOZ8HUCby062AlflpEZFSIskfwXWDxcT5/C7AgfN0O3BNhLcd0wfR6XtzVSV63oxaRmIosCNz9N8C+4zRZAnzPA88CE81selT1HMuFM+rp7svzyl4dHhKReKrkGMFMYGvJ/LZw2VHM7HYzazWz1vb29jNaxAUz6gFYv0OHh0QknsbEYLG73+fuLe7e0tzcfEbXvWDKBNJJY92OjjO6XhGRsaKSQbAdmF0yPytcNqIyqQQXzmhg5Sv7R/qnRURGhUoGwTLgPeHZQ5cDHe6+sxKFLJo3ibXbOujpz1fi50VEKirK00cfAP4AnGtm28zsNjP7OzP7u7DJo8AmoA34N+BDUdVyIovmTqIvX2D11gOVKkFEpGJSUa3Y3W8+wecOfDiq3z8ZLXMbAfjj5n1cfvbkClcjIjKyxsRgcdQm1mQ4d+oEVrxyvLNdRUTGJwVB6Mr5k1m+eR/dfblKlyIiMqIUBKHXnzeFvlyBP2zcW+lSRERGlIIgtGjeJGoySZ58cXelSxERGVEKglA2leTq+U089eJugnFsEZF4UBCUeOMFU9nR0aPTSEUkVhQEJd580TQyqQQ/W72j0qWIiIwYBUGJ+qo01543hUfW7iSX1wPtRSQeFARDLFk4gz1dvfxhk84eEpF4UBAMcc25U6ivSvGj1m2VLkVEZEQoCIaoSie5sWU2v3h+J7sP9lS6HBGRyCkIyrjl8rPIFZwHVmw9cWMRkTFOQVDG3KZarjm3maXL/0xvTremFpHxTUFwDLddPY/dnb08uFJjBSIyvikIjuHq+U1cMmci/+epjfTldCqpiIxfCoJjMDM++oa/YPuBw/yoVWMFIjJ+KQiO468WNPG6uY185fE/0XG4v9LliIhEQkFwHGbG5992Ifu6+/jaEy9XuhwRkUgoCE7gopkN3PS6Odz/+1d4+dXOSpcjInLGKQiG4eNv+gvqqlJ8/MG1ugeRiIw7CoJhmFyX5Z/+5iLWbD3APf+xsdLliIicUQqCYXrra2bwtotn8NUnXua5LfsrXY6IyBmjIDgJX1xyIdMaqvjQ0lXs6eqtdDkiImeEguAkTKzJcO+7X8u+Q33c8f9W6UIzERkXFAQn6aKZDXzp7f+JZzft4+M/XkOhoOcbi8jYFmkQmNliM3vJzNrM7JNlPn+vmbWb2erw9YEo6zlT/usls/jE4nNZtmYHX/z39XrYvYiMaamoVmxmSeDrwBuBbcAfzWyZu68f0vSH7n5HVHVE5YN/fQ7tnb1853evkEoYn77ufMys0mWJiJy0yIIAWAS0ufsmADP7AbAEGBoEY5KZ8dn/cgGFgvNvv91Md1+eLy65iERCYSAiY0uUh4ZmAqV3a9sWLhvq7Wa21sweNLPZ5VZkZrebWauZtba3t0dR6ylJJIz/df2FfPCac1i6fAv/7YHnONyn5xeIyNhS6cHinwNz3f01wOPA/eUauft97t7i7i3Nzc0jWuCJmBl/v/g8Pn3deTy6bic3fuP37DhwuNJliYgMW5RBsB0o/Qt/VrhsgLvvdffiCfnfBF4bYT2Ruv2vzuGb72nhlT3dXH/3Mzz9p9HTcxEROZ4og+CPwAIzm2dmGeAmYFlpAzObXjJ7PbAhwnoid+35U/nJh65kUm2GW7+9gn96ZL0edSkio15kQeDuOeAO4DGC/8H/yN1fMLMvmNn1YbOPmNkLZrYG+Ajw3qjqGSkLpk5g2R1X854rzuKbz2xmyd2/Y+WfdUsKERm9bKydA9/S0uKtra2VLmNYntjwKp/56Tp2HezhbxfN4ROLz6OhOl3pskQkhsxspbu3lPus0oPF49q150/l8f/x17z/qnk8sGIL//lf/oPv/G6zbk0hIqOKgiBiddkUn33rBSy742rOmzaBf/z5et5w19P8bPV28ro9hYiMAgqCEXLRzAaWfuAy7n//ImqzKe78wWrecNfT/GDFFg0oi0hFaYygAgoF5xfrdnHv0xt5fnsHUyZkee9Vc3lny2wm12UrXZ6IjEPHGyNQEFSQu/O7tr3c+/RGnmnbQzppLL5oOu+6bA6XzZukexeJyBlzvCCI8l5DcgJmxtULmrh6QRNtuztZunwLD63cxs/X7GBeUy1vu3gG1188g/lT6ipdqoiMY+oRjDKH+/I8snYHD6/azrOb9+IOF86oZ8nCGbz5wmmcNbm20iWKyBikQ0Nj1K6OHh5Zu4Nla3awdlsHAPOn1HHt+VN4w/lTuXROI0nd7VREhkFBMA78ee8hfr1hN09seJUVm/eRKziNNWmuPKeJK+dP5spzmpg7uUbjCiJSloJgnDnY089v/tTOky/u5vdte9l1sAeAGQ1VXHFOE5fNm8SlZ03k7KY6PR9BRAAFwbjm7ryyt5vfte3hDxv38odNe9l3qA+A+qoUC+c0cumciVwyp5GFsybSUKNbXIjEkYIgRgoFZ9OeQ6zasp/nthzguS37eenVToq7eebEai6YUc8F0+sH3mc1VuuQksg4p9NHYySRMOZPqWP+lDre0RI8DqKrN8earQd4fnsH63cc5IUdHfx6w6sD4VBfleK8afWcM6WOc5prB74/o6Fah5ZEYkBBEAN12RRXzW/iqvlNA8u6+3K8tKuT9TsP8sKOg7z8aie/XLeT/d39A22q00nODoNhXlMtcybVDLyaJ2TVixAZJxQEMVWTSXHJnEYumdM4aPnerl42th+ibXcXbbu72NjeResr+1m2ZgelRxGr0glmNwahMDsMh1mN1cyYWM20hiom1WTUmxAZIxQEMsjkuiyT67Ismjdp0PLeXJ7t+w+zZV83W/d1s2XgdZhnN+3lUN/gG+dlkgmmNmSZ3lDN9IYqpjVUMb2+imnhfPOELE11WTIp3fdQpNIUBDIs2VSSs5vrOLv56NtduDv7u/vZtr+bnR097OroYWdHDzs7DrOzo4fnthxgV0cPffmjn8PQUJ2mqS5DU12WpglZmuuyYUgEy4qB0ViToTqTHIlNFYkdBYGcNjNjUm2GSbUZXjOrfBt3Z++hvoGQ2NPVS3tnL3u6wldnHxt2HOQ3nb109ubKriObStBYk2FiTZrGmgyNtWkm1mRorEkzsfro5ROr00yoSqvXIXICCgIZEWYW/NVfl+WimQ3HbdvTnw8Doo89YVjs7+7nQHcf+7v7Bqb/9GpXuKz/uA/5qUonqK9KM6EqRX0YDhOqUtRXpakfWJYaaDOhKk19dfBem0lSk0kpTGRcUxDIqFOVTjKrsYZZjTXDau/udPbmOHCoPwyKPg6EYdHZk6OzN8fBw/109uQ42NNPx+HgMNbBwzk6e/rpHcajQzPJBDXZJLWZFLXZIByK73XZFDWZJLXZ1FGf12ZS1ITz1ekk1ekkVekEVZlgOp1UwEjlKQhkzDOz8K/7NHMmDy88SvXm8kFg9AwOjM6efrr78hzqzXGoL093+F46v7erm+6+PN19OQ715jncf3JPm0smLAyHICCq00mqM0mqUskwLBJUDQRIcmC6OhO0zaaTZFMJsqnie4JMOJ8J57PpBJlkgmw6SSaZIJ00nforgygIJPayqSTZuiRNZ+DpcPmC092Xo7svT1dvju7ePIf6cnT35ejpL3C4L09PLh+89wfB0dNfCN5LPjvcn6fjcD+7DwbTxfY9/YWyg+4nwyzo4QShkTwqLLLJ0vnwPQyWTCpBOpkgkzTSyQSpMFiKy1OJI9Pp8LPjTWdSwXfSqUQYUgndUbcCFAQiZ1AyYeEYRJqpEf1GLl+gJ1cIgqQvT2+uQG8uT1+uQG+uMOR96PL8oDblvxv0evYdYz25vJ92GB2PGWHYBIGRKpkuhk8qYaSSRiphJBM2ECCphJFKJEiWflYyn0okSCWLy41kOF9sG6w3cWQ+GX6n3O8Mmg5/N2GDvpu0YLr0lbAjbUZLz0xBIDLGpJIJ6pIJ6rKV+8/X3ckXnP4wFHL5Av15pz9fCOePTPfnCuQKPjDdn3dyhSBgit/pzx9vevB8X87JF4J15gtOLu8cyuUG6skXgvXnws9K5/N5D5YXgnVWWsI4EhJlQiNpRrIkUG5eNIcP/OXZZ7wOBYGInDSz8K/gJFQzdq/vKBSc/kIhDIsgOHLF+TA08iWhUpw/EjhOLn8klPrzR9ZVKL578N2C+0C74qu4rNh24DMv+X7xM/czcviynEiDwMwWA18FksA33f1LQz7PAt8DXgvsBd7p7q9EWZOISFEiYWQTYzfIzpTIzl0zsyTwdeAtwAXAzWZ2wZBmtwH73X0+8BXgy1HVIyIi5UV5EvMioM3dN7l7H/ADYMmQNkuA+8PpB4FrbbSMnoiIxESUQTAT2Foyvy1cVraNu+eADmDy0BWZ2e1m1mpmre3t7RGVKyIST2PiskZ3v8/dW9y9pbm5udLliIiMK1EGwXZgdsn8rHBZ2TZmlgIaCAaNRURkhEQZBH8EFpjZPDPLADcBy4a0WQbcGk7fADzpY+0hyiIiY1xkp4+6e87M7gAeIzh99Nvu/oKZfQFodfdlwLeA75tZG7CPICxERGQERXodgbs/Cjw6ZNnnSqZ7gBujrEFERI7PxtqRGDNrB/58il9vAvacwXLGAm1zPGib4+F0tvksdy97ts2YC4LTYWat7t5S6TpGkrY5HrTN8RDVNo+J00dFRCQ6CgIRkZiLWxDcV+kCKkDbHA/a5niIZJtjNUYgIiJHi1uPQEREhlAQiIjEXGyCwMwWm9lLZtZmZp+sdD1nipnNNrOnzGy9mb1gZneGyyeZ2eNm9nL43hguNzP7WvjPYa2ZXVrZLTg1ZpY0s+fM7JFwfp6ZLQ+364fhbU0ws2w43xZ+PreihZ8GM5toZg+a2YtmtsHMrhjP+9nM/nv47/Q6M3vAzKrG4342s2+b2W4zW1ey7KT3q5ndGrZ/2cxuLfdbxxKLIBjmQ3LGqhzwMXe/ALgc+HC4bZ8EnnD3BcAT4TwE/wwWhK/bgXtGvuQz4k5gQ8n8l4GvhA852k/w0CMYXw8/+irwS3c/D7iYYPvH5X42s5nAR4AWd7+I4DY1NzE+9/N3gcVDlp3UfjWzScDngcsIngXz+WJ4DIu7j/sXcAXwWMn8p4BPVbquiLb1Z8AbgZeA6eGy6cBL4fQ3gJtL2g+0GysvgjvZPgG8HngEMIKrLVND9zfBva6uCKdTYTur9DacwjY3AJuH1j5e9zNHnlUyKdxvjwBvHq/7GZgLrDvV/QrcDHyjZPmgdid6xaJHwPAekjPmhd3hS4DlwFR33xl+tAuYGk6Ph38W/xv4BFAI5ycDBzx4uBEM3qZhPfxoDJgHtAPfCQ+JfdPMahmn+9ndtwP/AmwBdhLst5WM//1cdLL79bT2d1yCYNwzszrgIeCj7n6w9DMP/kQYF+cJm9lbgd3uvrLStYywFHApcI+7XwIc4sjhAmDc7edGgkfZzgNmALUcffgkFkZiv8YlCIbzkJwxy8zSBCGw1N0fDhe/ambTw8+nA7vD5WP9n8VVwPVm9grBc7BfT3DsfGL4cCMYvE3j5eFH24Bt7r48nH+QIBjG635+A7DZ3dvdvR94mGDfj/f9XHSy+/W09ndcgmA4D8kZk8zMCJ7rsMHd7yr5qPShP7cSjB0Ul78nPPvgcqCjpAs66rn7p9x9lrvPJdiPT7r7u4CnCB5uBEdv75h/+JG77wK2mtm54aJrgfWM0/1McEjocjOrCf8dL27vuN7PJU52vz4GvMnMGsPe1JvCZcNT6UGSERyMuQ74E7AR+IdK13MGt+tqgm7jWmB1+LqO4PjoE8DLwK+BSWF7IziDaiPwPMFZGRXfjlPc9muAR8Lps4EVQBvwYyAbLq8K59vCz8+udN2nsb0LgdZwX/8UaBzP+xn4R+BFYB3wfSA7Hvcz8ADBOEg/Qc/vtlPZr8D7w+1vA953MjXoFhMiIjEXl0NDIiJyDAoCEZGYUxCIiMScgkBEJOYUBCIiMacgEBlBZnZN8Y6pIqOFgkBEJOYUBCJlmNm7zWyFma02s2+Ezz/oMrOvhPfIf8LMmsO2C83s2fD+8D8puXf8fDP7tZmtMbNVZnZOuPo6O/JcgaXhlbMiFaMgEBnCzM4H3glc5e4LgTzwLoIbn7W6+4XA0wT3fwf4HvD37v4agqs9i8uXAl9394uBKwmuHoXgDrEfJXg2xtkE99ARqZjUiZuIxM61wGuBP4Z/rFcT3PSrAPwwbPN/gYfNrAGY6O5Ph8vvB35sZhOAme7+EwB37wEI17fC3beF86sJ7kX/TORbJXIMCgKRoxlwv7t/atBCs88OaXeq92fpLZnOo/8OpcJ0aEjkaE8AN5jZFBh4fuxZBP+9FO98+bfAM+7eAew3s78Ml98CPO3uncA2M/ubcB1ZM6sZyY0QGS79JSIyhLuvN7PPAL8yswTBXSE/TPAwmEXhZ7sJxhEguE3wveH/6DcB7wuX3wJ8w8y+EK7jxhHcDJFh091HRYbJzLrcva7SdYicaTo0JCISc+oRiIjEnHoEIiIxpyAQEYk5BYGISMwpCEREYk5BICISc/8fAf/vPn/Thr4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# prepare dataset\n",
    "x_data = torch.Tensor([[1.0], [2.0], [3.0]])\n",
    "y_data = torch.Tensor([[0], [0], [1]])\n",
    "\n",
    "# define model using class\n",
    "class LogisticRegressionModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = F.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "\n",
    "model = LogisticRegressionModel()\n",
    "\n",
    "# define loss function and optimizer\n",
    "criterion = torch.nn.BCELoss(size_average=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
    "\n",
    "# training cycle\n",
    "loss_list = []\n",
    "for epoch in range(1000):\n",
    "    # forward\n",
    "    y_pred = model(x_data)\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    loss_list.append(loss.item())\n",
    "    print('epoch=', epoch, 'loss=', loss.item())\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # update\n",
    "    optimizer.step()\n",
    "print('w=', model.linear.weight.item())\n",
    "print('b=', model.linear.bias.item())\n",
    "plt.plot(loss_list)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- result of logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "x = np.linspace(0, 10, 200)\n",
    "x_t = torch.Tensor(x).view(200, 1)\n",
    "y_t = model(x_t)\n",
    "y = y_t.data.numpy()\n",
    "plt.plot(x, y)\n",
    "plt.plot([0, 10], [0.5, 0.5], c='r')\n",
    "plt.xlabel('Hours')\n",
    "plt.ylabel('Probility of Pass')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- torch.nn.BCEloss函数的计算原理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9190952181816101"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 官网实例\n",
    "import torch\n",
    "m = torch.nn.Sigmoid()\n",
    "loss = torch.nn.BCELoss()\n",
    "input = torch.randn(3, requires_grad=True)\n",
    "target = torch.empty(3).random_(2)\n",
    "output = loss(m(input), target)\n",
    "# output.backward()\n",
    "output.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5249, 0.4911, 0.2720], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预测的概率\n",
    "m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5248640775680542, 0.49114295840263367, 0.27195703983306885]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two = m(input).tolist()\n",
    "two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9190951887554627"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实际计算公式\n",
    "import numpy as np\n",
    "(np.log(1-two[0])+np.log(two[1])+np.log(two[2]))/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture_07_Multiple_Dimension_Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pandas中的read_csv不自动将第一行作为表头，自己设置表头"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature0</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.294118</td>\n",
       "      <td>0.487437</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>-0.292929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>-0.531170</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.145729</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>-0.414141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.207153</td>\n",
       "      <td>-0.766866</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.058824</td>\n",
       "      <td>0.839196</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.305514</td>\n",
       "      <td>-0.492741</td>\n",
       "      <td>-0.633333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.105528</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>-0.535354</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>-0.162444</td>\n",
       "      <td>-0.923997</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376884</td>\n",
       "      <td>-0.344262</td>\n",
       "      <td>-0.292929</td>\n",
       "      <td>-0.602837</td>\n",
       "      <td>0.284650</td>\n",
       "      <td>0.887276</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.015075</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>-0.030303</td>\n",
       "      <td>-0.574468</td>\n",
       "      <td>-0.019374</td>\n",
       "      <td>-0.920581</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>-0.764706</td>\n",
       "      <td>0.226131</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>-0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096870</td>\n",
       "      <td>-0.776260</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>-0.411765</td>\n",
       "      <td>0.216080</td>\n",
       "      <td>0.180328</td>\n",
       "      <td>-0.535354</td>\n",
       "      <td>-0.735225</td>\n",
       "      <td>-0.219076</td>\n",
       "      <td>-0.857387</td>\n",
       "      <td>-0.700000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>-0.882353</td>\n",
       "      <td>0.266332</td>\n",
       "      <td>-0.016393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.102832</td>\n",
       "      <td>-0.768574</td>\n",
       "      <td>-0.133333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>-0.882353</td>\n",
       "      <td>-0.065327</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>-0.373737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.093890</td>\n",
       "      <td>-0.797609</td>\n",
       "      <td>-0.933333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>759 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature0  feature1  feature2  feature3  feature4  feature5  feature6  \\\n",
       "0   -0.294118  0.487437  0.180328 -0.292929  0.000000  0.001490 -0.531170   \n",
       "1   -0.882353 -0.145729  0.081967 -0.414141  0.000000 -0.207153 -0.766866   \n",
       "2   -0.058824  0.839196  0.049180  0.000000  0.000000 -0.305514 -0.492741   \n",
       "3   -0.882353 -0.105528  0.081967 -0.535354 -0.777778 -0.162444 -0.923997   \n",
       "4    0.000000  0.376884 -0.344262 -0.292929 -0.602837  0.284650  0.887276   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "754  0.176471  0.015075  0.245902 -0.030303 -0.574468 -0.019374 -0.920581   \n",
       "755 -0.764706  0.226131  0.147541 -0.454545  0.000000  0.096870 -0.776260   \n",
       "756 -0.411765  0.216080  0.180328 -0.535354 -0.735225 -0.219076 -0.857387   \n",
       "757 -0.882353  0.266332 -0.016393  0.000000  0.000000 -0.102832 -0.768574   \n",
       "758 -0.882353 -0.065327  0.147541 -0.373737  0.000000 -0.093890 -0.797609   \n",
       "\n",
       "     feature7  feature8  \n",
       "0   -0.033333         0  \n",
       "1   -0.666667         1  \n",
       "2   -0.633333         0  \n",
       "3    0.000000         1  \n",
       "4   -0.600000         0  \n",
       "..        ...       ...  \n",
       "754  0.400000         1  \n",
       "755 -0.800000         1  \n",
       "756 -0.700000         1  \n",
       "757 -0.133333         0  \n",
       "758 -0.933333         1  \n",
       "\n",
       "[759 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "diabetes = pd.read_csv('./diabetes.csv', header=None, prefix='feature')\n",
    "diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 0 loss= 0.6898143291473389\n",
      "epoch= 1 loss= 0.672759473323822\n",
      "epoch= 2 loss= 0.6623375415802002\n",
      "epoch= 3 loss= 0.655929684638977\n",
      "epoch= 4 loss= 0.6519653797149658\n",
      "epoch= 5 loss= 0.6494987607002258\n",
      "epoch= 6 loss= 0.647956371307373\n",
      "epoch= 7 loss= 0.6469876170158386\n",
      "epoch= 8 loss= 0.6463767290115356\n",
      "epoch= 9 loss= 0.6459903717041016\n",
      "epoch= 10 loss= 0.6457450985908508\n",
      "epoch= 11 loss= 0.6455888748168945\n",
      "epoch= 12 loss= 0.6454890370368958\n",
      "epoch= 13 loss= 0.6454249024391174\n",
      "epoch= 14 loss= 0.6453834772109985\n",
      "epoch= 15 loss= 0.6453564167022705\n",
      "epoch= 16 loss= 0.6453385353088379\n",
      "epoch= 17 loss= 0.6453264951705933\n",
      "epoch= 18 loss= 0.6453182101249695\n",
      "epoch= 19 loss= 0.6453123092651367\n",
      "epoch= 20 loss= 0.6453078389167786\n",
      "epoch= 21 loss= 0.6453043818473816\n",
      "epoch= 22 loss= 0.6453015208244324\n",
      "epoch= 23 loss= 0.6452990770339966\n",
      "epoch= 24 loss= 0.6452968716621399\n",
      "epoch= 25 loss= 0.6452948451042175\n",
      "epoch= 26 loss= 0.6452928781509399\n",
      "epoch= 27 loss= 0.6452910304069519\n",
      "epoch= 28 loss= 0.6452892422676086\n",
      "epoch= 29 loss= 0.6452873945236206\n",
      "epoch= 30 loss= 0.6452856063842773\n",
      "epoch= 31 loss= 0.6452838778495789\n",
      "epoch= 32 loss= 0.6452820897102356\n",
      "epoch= 33 loss= 0.6452803015708923\n",
      "epoch= 34 loss= 0.6452785134315491\n",
      "epoch= 35 loss= 0.6452767848968506\n",
      "epoch= 36 loss= 0.6452750563621521\n",
      "epoch= 37 loss= 0.6452732682228088\n",
      "epoch= 38 loss= 0.6452714800834656\n",
      "epoch= 39 loss= 0.6452696919441223\n",
      "epoch= 40 loss= 0.6452679634094238\n",
      "epoch= 41 loss= 0.6452661156654358\n",
      "epoch= 42 loss= 0.6452643871307373\n",
      "epoch= 43 loss= 0.645262598991394\n",
      "epoch= 44 loss= 0.6452608704566956\n",
      "epoch= 45 loss= 0.6452590227127075\n",
      "epoch= 46 loss= 0.645257294178009\n",
      "epoch= 47 loss= 0.6452555656433105\n",
      "epoch= 48 loss= 0.6452537775039673\n",
      "epoch= 49 loss= 0.6452519297599792\n",
      "epoch= 50 loss= 0.6452502012252808\n",
      "epoch= 51 loss= 0.6452484130859375\n",
      "epoch= 52 loss= 0.6452466249465942\n",
      "epoch= 53 loss= 0.645244836807251\n",
      "epoch= 54 loss= 0.6452429890632629\n",
      "epoch= 55 loss= 0.6452412605285645\n",
      "epoch= 56 loss= 0.6452394127845764\n",
      "epoch= 57 loss= 0.6452376842498779\n",
      "epoch= 58 loss= 0.6452358365058899\n",
      "epoch= 59 loss= 0.6452340483665466\n",
      "epoch= 60 loss= 0.6452322602272034\n",
      "epoch= 61 loss= 0.6452304720878601\n",
      "epoch= 62 loss= 0.6452286243438721\n",
      "epoch= 63 loss= 0.6452268362045288\n",
      "epoch= 64 loss= 0.6452250480651855\n",
      "epoch= 65 loss= 0.6452232003211975\n",
      "epoch= 66 loss= 0.645221471786499\n",
      "epoch= 67 loss= 0.645219624042511\n",
      "epoch= 68 loss= 0.6452178359031677\n",
      "epoch= 69 loss= 0.6452159881591797\n",
      "epoch= 70 loss= 0.6452141404151917\n",
      "epoch= 71 loss= 0.6452123522758484\n",
      "epoch= 72 loss= 0.6452105045318604\n",
      "epoch= 73 loss= 0.6452087163925171\n",
      "epoch= 74 loss= 0.6452067494392395\n",
      "epoch= 75 loss= 0.645205020904541\n",
      "epoch= 76 loss= 0.645203173160553\n",
      "epoch= 77 loss= 0.6452013254165649\n",
      "epoch= 78 loss= 0.6451994776725769\n",
      "epoch= 79 loss= 0.6451976299285889\n",
      "epoch= 80 loss= 0.6451957821846008\n",
      "epoch= 81 loss= 0.6451939344406128\n",
      "epoch= 82 loss= 0.6451920866966248\n",
      "epoch= 83 loss= 0.6451902389526367\n",
      "epoch= 84 loss= 0.6451883912086487\n",
      "epoch= 85 loss= 0.6451864838600159\n",
      "epoch= 86 loss= 0.6451846361160278\n",
      "epoch= 87 loss= 0.645182728767395\n",
      "epoch= 88 loss= 0.645180881023407\n",
      "epoch= 89 loss= 0.645179033279419\n",
      "epoch= 90 loss= 0.6451771855354309\n",
      "epoch= 91 loss= 0.6451752781867981\n",
      "epoch= 92 loss= 0.6451734304428101\n",
      "epoch= 93 loss= 0.6451715230941772\n",
      "epoch= 94 loss= 0.6451696753501892\n",
      "epoch= 95 loss= 0.6451677083969116\n",
      "epoch= 96 loss= 0.6451658606529236\n",
      "epoch= 97 loss= 0.6451640129089355\n",
      "epoch= 98 loss= 0.645162045955658\n",
      "epoch= 99 loss= 0.6451601386070251\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. prepare dataset\n",
    "xy = np.loadtxt('./diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = torch.from_numpy(xy[:, :-1])\n",
    "y_data = torch.from_numpy(xy[:, -1]).view(-1, 1)\n",
    "\n",
    "# 2. define model using class\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(8, 6)\n",
    "        self.linear2 = torch.nn.Linear(6, 4)\n",
    "        self.linear3 = torch.nn.Linear(4, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.linear1(x))\n",
    "        x = self.sigmoid(self.linear2(x))\n",
    "        x = self.sigmoid(self.linear3(x))\n",
    "        return x\n",
    "  \n",
    "model = Model()\n",
    "\n",
    "# 3. define loss function and optimizer\n",
    "criterion = torch.nn.BCELoss(size_average=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
    "\n",
    "# 4. training cycle\n",
    "cost_list = []\n",
    "for epoch in range(100):\n",
    "    # forward\n",
    "    y_pred = model(x_data)  # 这里的batch即为所有数据\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    cost_list.append(loss.item())\n",
    "    print('epoch=', epoch, 'loss=', loss.item())\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # update\n",
    "    optimizer.step()\n",
    "\n",
    "plt.plot(cost_list)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(759, 9)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([759, 8])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([759, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- exercise\n",
    "    - try some other activation functions\n",
    "- 尝试很多不同的激活函数后的总结\n",
    "    - 针对二分类任务，因为最后输出的需要是一个概率（即取值必须在0到1之间），所以激活函数的因变量的取值不在0到1之间的激活函数是不适用于这种二分类任务的，例如torch.nn.Tanh和torch.nn.LeakyReLU以及torch.nn.ReLU\n",
    "    - 针对torch.nn.ReLU激活函数，因为当自变量小于0时的梯度为0，所以很可能会出现在多个训练epoch中因为梯度取值为零导致的参数无法更新，损失保持不变的情况\n",
    "    - 经过分析，针对类似这样的二分类任务，其中最合适的激活函数是torch.nn.Sigmoid函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 0 loss= 0.9253013134002686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-5157e9c14cac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0mcost_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'loss='\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/pytorch/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2525\u001b[0m     return torch._C._nn.binary_cross_entropy(\n\u001b[0;32m-> 2526\u001b[0;31m         input, target, weight, reduction_enum)\n\u001b[0m\u001b[1;32m   2527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "# 1. prepare dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xy_data = np.loadtxt('./diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = torch.from_numpy(xy_data[:, :-1])\n",
    "y_data = torch.from_numpy(xy_data[:, -1]).view(-1, 1)\n",
    "\n",
    "# 2. define model using class\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(8, 6)\n",
    "        self.linear2 = torch.nn.Linear(6, 4)\n",
    "        self.linear3 = torch.nn.Linear(4, 1)\n",
    "        self.activition = torch.nn.LeakyReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.activition(self.linear1(x))\n",
    "        x = self.activition(self.linear2(x))\n",
    "        x = self.activition(self.linear3(x))\n",
    "        return x\n",
    "\n",
    "model = Model()\n",
    "\n",
    "# 3. define loss function and optimizer\n",
    "criterion = torch.nn.BCELoss(size_average=True)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
    "\n",
    "# 4. training cycle\n",
    "cost_list = []\n",
    "for epoch in range(100):\n",
    "    # forward\n",
    "    y_pred = model(x_data)\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    cost_list.append(loss.item())\n",
    "    print('epoch=', epoch, 'loss=', loss.item())\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # update\n",
    "    optimizer.step()\n",
    "\n",
    "plt.plot(cost_list)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture_08_Dataset_and_Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. prepare dataset\n",
    "class DiabetesDataset(Dataset):\n",
    "    def __init__(self, filepath):\n",
    "        xy = np.loadtxt(filepath, delimiter=',', dtype=np.float32)\n",
    "        self.len = xy.shape[0]\n",
    "        self.x_data = torch.from_numpy(xy[:, :-1])\n",
    "        self.y_data = torch.from_numpy(xy[:, [-1]])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "# 2. define model using class\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = torch.nn.Linear(8, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.linear(x))\n",
    "        return x\n",
    "    # forward函数如果这样定义的话会报错\n",
    "    # def forward(self, x):\n",
    "    #     x = torch.nn.Sigmoid(self.linear(x))\n",
    "    #     return x\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    dataset = DiabetesDataset('./diabetes.csv')\n",
    "    train_loader = DataLoader(dataset=dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "    \n",
    "    model = Model()\n",
    "    \n",
    "    # 3. define the loss function and optimizer\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.5)\n",
    "    \n",
    "    # 4. training cycle\n",
    "    # 需要有每个batch的loss变化图和每个epoch的loss变化图\n",
    "    batch_loss_list = []\n",
    "    epoch_loss_list = []\n",
    "\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        epoch_loss = 0\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            # i表示第几个batch，data表示当前这个batch的所有数据\n",
    "            # 1. prepare data\n",
    "            input, labels = data\n",
    "            # 2. forward\n",
    "            y_pred = model(input)\n",
    "            loss = criterion(y_pred, labels)\n",
    "            batch_loss_list.append(loss.item())\n",
    "            epoch_loss += loss.item()\n",
    "            # 3. backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # 4. update\n",
    "            optimizer.step()\n",
    "        epoch_loss_list.append(epoch_loss/32)\n",
    "    plt.plot(list(range(len(batch_loss_list))), batch_loss_list)\n",
    "    plt.plot(list(range(0, len(dataset)//32*100, len(dataset)//32)), epoch_loss_list)\n",
    "    plt.show()\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- exercise\n",
    "    - build dataloader for Titanic dataset\n",
    "    - build a classifier using dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "train = pd.read_csv('./titanic/train.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Pclass                                          Name  \\\n",
       "0            892       3                              Kelly, Mr. James   \n",
       "1            893       3              Wilkes, Mrs. James (Ellen Needs)   \n",
       "2            894       2                     Myles, Mr. Thomas Francis   \n",
       "3            895       3                              Wirz, Mr. Albert   \n",
       "4            896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)   \n",
       "..           ...     ...                                           ...   \n",
       "413         1305       3                            Spector, Mr. Woolf   \n",
       "414         1306       1                  Oliva y Ocana, Dona. Fermina   \n",
       "415         1307       3                  Saether, Mr. Simon Sivertsen   \n",
       "416         1308       3                           Ware, Mr. Frederick   \n",
       "417         1309       3                      Peter, Master. Michael J   \n",
       "\n",
       "        Sex   Age  SibSp  Parch              Ticket      Fare Cabin Embarked  \n",
       "0      male  34.5      0      0              330911    7.8292   NaN        Q  \n",
       "1    female  47.0      1      0              363272    7.0000   NaN        S  \n",
       "2      male  62.0      0      0              240276    9.6875   NaN        Q  \n",
       "3      male  27.0      0      0              315154    8.6625   NaN        S  \n",
       "4    female  22.0      1      1             3101298   12.2875   NaN        S  \n",
       "..      ...   ...    ...    ...                 ...       ...   ...      ...  \n",
       "413    male   NaN      0      0           A.5. 3236    8.0500   NaN        S  \n",
       "414  female  39.0      0      0            PC 17758  108.9000  C105        C  \n",
       "415    male  38.5      0      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
       "416    male   NaN      0      0              359309    8.0500   NaN        S  \n",
       "417    male   NaN      1      1                2668   22.3583   NaN        C  \n",
       "\n",
       "[418 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "test = pd.read_csv('./titanic/test.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将训练数据与测试数据结合后进行特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>1305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Spector, Mr. Woolf</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A.5. 3236</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>1306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Oliva y Ocana, Dona. Fermina</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17758</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C105</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Saether, Mr. Simon Sivertsen</td>\n",
       "      <td>male</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101262</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>1308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Ware, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359309</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>1309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Peter, Master. Michael J</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2668</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PassengerId  Survived  Pclass  \\\n",
       "0               1       0.0       3   \n",
       "1               2       1.0       1   \n",
       "2               3       1.0       3   \n",
       "3               4       1.0       1   \n",
       "4               5       0.0       3   \n",
       "...           ...       ...     ...   \n",
       "1304         1305       NaN       3   \n",
       "1305         1306       NaN       1   \n",
       "1306         1307       NaN       3   \n",
       "1307         1308       NaN       3   \n",
       "1308         1309       NaN       3   \n",
       "\n",
       "                                                   Name     Sex   Age  SibSp  \\\n",
       "0                               Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1     Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                                Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3          Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                              Allen, Mr. William Henry    male  35.0      0   \n",
       "...                                                 ...     ...   ...    ...   \n",
       "1304                                 Spector, Mr. Woolf    male   NaN      0   \n",
       "1305                       Oliva y Ocana, Dona. Fermina  female  39.0      0   \n",
       "1306                       Saether, Mr. Simon Sivertsen    male  38.5      0   \n",
       "1307                                Ware, Mr. Frederick    male   NaN      0   \n",
       "1308                           Peter, Master. Michael J    male   NaN      1   \n",
       "\n",
       "      Parch              Ticket      Fare Cabin Embarked  \n",
       "0         0           A/5 21171    7.2500   NaN        S  \n",
       "1         0            PC 17599   71.2833   C85        C  \n",
       "2         0    STON/O2. 3101282    7.9250   NaN        S  \n",
       "3         0              113803   53.1000  C123        S  \n",
       "4         0              373450    8.0500   NaN        S  \n",
       "...     ...                 ...       ...   ...      ...  \n",
       "1304      0           A.5. 3236    8.0500   NaN        S  \n",
       "1305      0            PC 17758  108.9000  C105        C  \n",
       "1306      0  SOTON/O.Q. 3101262    7.2500   NaN        S  \n",
       "1307      0              359309    8.0500   NaN        S  \n",
       "1308      1                2668   22.3583   NaN        C  \n",
       "\n",
       "[1309 rows x 12 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test = train.append(test, ignore_index=True)\n",
    "train_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 筛选有效列（特征）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived       418\n",
       "Pclass           0\n",
       "Sex              0\n",
       "Age            263\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Fare             1\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_new = train_test.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
    "train_test_new.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 对缺失值进行插值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived       418\n",
       "Pclass           0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Fare             0\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Age采用均值填充\n",
    "train_test_new['Age'] = train_test_new['Age'].fillna(train_test_new['Age'].mean())\n",
    "# Fare采用均值填充\n",
    "train_test_new['Fare'] = train_test_new['Fare'].fillna(train_test_new['Fare'].mean())\n",
    "# Embarked采用众数填充\n",
    "train_test_new['Embarked'] = train_test_new['Embarked'].fillna(train_test_new['Embarked'].mode()[0])\n",
    "train_test_new.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 对类别型变量离散化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>1305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>1306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>1307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>1308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>1309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1309 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PassengerId  Survived  Pclass     Sex        Age  SibSp  Parch  \\\n",
       "0               1       0.0       3    male  22.000000      1      0   \n",
       "1               2       1.0       1  female  38.000000      1      0   \n",
       "2               3       1.0       3  female  26.000000      0      0   \n",
       "3               4       1.0       1  female  35.000000      1      0   \n",
       "4               5       0.0       3    male  35.000000      0      0   \n",
       "...           ...       ...     ...     ...        ...    ...    ...   \n",
       "1304         1305       NaN       3    male  29.881138      0      0   \n",
       "1305         1306       NaN       1  female  39.000000      0      0   \n",
       "1306         1307       NaN       3    male  38.500000      0      0   \n",
       "1307         1308       NaN       3    male  29.881138      0      0   \n",
       "1308         1309       NaN       3    male  29.881138      1      1   \n",
       "\n",
       "          Fare Embarked  \n",
       "0       7.2500        S  \n",
       "1      71.2833        C  \n",
       "2       7.9250        S  \n",
       "3      53.1000        S  \n",
       "4       8.0500        S  \n",
       "...        ...      ...  \n",
       "1304    8.0500        S  \n",
       "1305  108.9000        C  \n",
       "1306    7.2500        S  \n",
       "1307    8.0500        S  \n",
       "1308   22.3583        C  \n",
       "\n",
       "[1309 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass        Age  SibSp  Parch     Fare  \\\n",
       "0              1       0.0       3  22.000000      1      0   7.2500   \n",
       "1              2       1.0       1  38.000000      1      0  71.2833   \n",
       "2              3       1.0       3  26.000000      0      0   7.9250   \n",
       "3              4       1.0       1  35.000000      1      0  53.1000   \n",
       "4              5       0.0       3  35.000000      0      0   8.0500   \n",
       "..           ...       ...     ...        ...    ...    ...      ...   \n",
       "886          887       0.0       2  27.000000      0      0  13.0000   \n",
       "887          888       1.0       1  19.000000      0      0  30.0000   \n",
       "888          889       0.0       3  29.881138      1      2  23.4500   \n",
       "889          890       1.0       1  26.000000      0      0  30.0000   \n",
       "890          891       0.0       3  32.000000      0      0   7.7500   \n",
       "\n",
       "     Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0             0         1           0           0           1  \n",
       "1             1         0           1           0           0  \n",
       "2             1         0           0           0           1  \n",
       "3             1         0           0           0           1  \n",
       "4             0         1           0           0           1  \n",
       "..          ...       ...         ...         ...         ...  \n",
       "886           0         1           0           0           1  \n",
       "887           1         0           0           0           1  \n",
       "888           1         0           0           0           1  \n",
       "889           0         1           1           0           0  \n",
       "890           0         1           0           1           0  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_new_lisanhua = pd.get_dummies(train_test_new)\n",
    "train, test = train_test_new_lisanhua[0: len(train)], train_test_new_lisanhua[len(train):]\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass        Age  SibSp  Parch      Fare  \\\n",
       "0            892       NaN       3  34.500000      0      0    7.8292   \n",
       "1            893       NaN       3  47.000000      1      0    7.0000   \n",
       "2            894       NaN       2  62.000000      0      0    9.6875   \n",
       "3            895       NaN       3  27.000000      0      0    8.6625   \n",
       "4            896       NaN       3  22.000000      1      1   12.2875   \n",
       "..           ...       ...     ...        ...    ...    ...       ...   \n",
       "413         1305       NaN       3  29.881138      0      0    8.0500   \n",
       "414         1306       NaN       1  39.000000      0      0  108.9000   \n",
       "415         1307       NaN       3  38.500000      0      0    7.2500   \n",
       "416         1308       NaN       3  29.881138      0      0    8.0500   \n",
       "417         1309       NaN       3  29.881138      1      1   22.3583   \n",
       "\n",
       "     Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0             0         1           0           1           0  \n",
       "1             1         0           0           0           1  \n",
       "2             0         1           0           1           0  \n",
       "3             0         1           0           0           1  \n",
       "4             1         0           0           0           1  \n",
       "..          ...       ...         ...         ...         ...  \n",
       "413           0         1           0           0           1  \n",
       "414           1         0           1           0           0  \n",
       "415           0         1           0           0           1  \n",
       "416           0         1           0           0           1  \n",
       "417           0         1           1           0           0  \n",
       "\n",
       "[418 rows x 12 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 构建train的dataset类和test的dataset类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class train_dataset(Dataset):\n",
    "    def __init__(self, train_data_after_feature_engineering):\n",
    "        # 传入的是经过特征工程的dataframe格式的特征数据\n",
    "        self.train_data = np.array(train_data_after_feature_engineering.values[:, 1:], dtype=np.float32)  # 去掉PassengerId列\n",
    "        self.len = len(self.train_data)\n",
    "    \n",
    "    # 返回指定索引的数据\n",
    "    def __getitem__(self, index):\n",
    "        data, labels = self.train_data[:, 1:], self.train_data[:, [0]]\n",
    "        return data[index], labels[index]\n",
    "    \n",
    "    # 返回数据集的长度\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "class test_dataset(Dataset):\n",
    "    def __init__(self, test_data_after_feature_engineering):\n",
    "        self.test_data = np.array(test_data_after_feature_engineering.values[:, 2:], dtype=np.float32)\n",
    "        self.len = len(self.test_data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.test_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 构建train和test的dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化Dataset\n",
    "train_data = train_dataset(train)\n",
    "test_data = test_dataset(test)\n",
    "\n",
    "# 构建dataloader\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 构建分类网络进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 0 loss= 0.6842992625066212\n",
      "epoch= 1 loss= 0.6708889326878956\n",
      "epoch= 2 loss= 0.6683619128806251\n",
      "epoch= 3 loss= 0.6673982398850578\n",
      "epoch= 4 loss= 0.6671712909426007\n",
      "epoch= 5 loss= 0.6667860448360443\n",
      "epoch= 6 loss= 0.6670938772814614\n",
      "epoch= 7 loss= 0.6669511986630303\n",
      "epoch= 8 loss= 0.6665401096854892\n",
      "epoch= 9 loss= 0.6661691516637802\n",
      "epoch= 10 loss= 0.6664657273462841\n",
      "epoch= 11 loss= 0.6664705595799855\n",
      "epoch= 12 loss= 0.6656744203397206\n",
      "epoch= 13 loss= 0.6659317825521741\n",
      "epoch= 14 loss= 0.6661501143659864\n",
      "epoch= 15 loss= 0.6653504073619843\n",
      "epoch= 16 loss= 0.6654272249766758\n",
      "epoch= 17 loss= 0.6656271048954555\n",
      "epoch= 18 loss= 0.6653796562126705\n",
      "epoch= 19 loss= 0.6653713009187153\n",
      "epoch= 20 loss= 0.6654224097728729\n",
      "epoch= 21 loss= 0.6650770349161965\n",
      "epoch= 22 loss= 0.665263084428651\n",
      "epoch= 23 loss= 0.6644902761493411\n",
      "epoch= 24 loss= 0.6645529738494328\n",
      "epoch= 25 loss= 0.6649933946984155\n",
      "epoch= 26 loss= 0.6647364114012037\n",
      "epoch= 27 loss= 0.6644185568605151\n",
      "epoch= 28 loss= 0.6640336705105645\n",
      "epoch= 29 loss= 0.6646787290062223\n",
      "epoch= 30 loss= 0.6637206631047385\n",
      "epoch= 31 loss= 0.6636726664645332\n",
      "epoch= 32 loss= 0.6641440157379422\n",
      "epoch= 33 loss= 0.6634585516793388\n",
      "epoch= 34 loss= 0.6633100828954152\n",
      "epoch= 35 loss= 0.6628103724547795\n",
      "epoch= 36 loss= 0.6624041795730591\n",
      "epoch= 37 loss= 0.662023623074804\n",
      "epoch= 38 loss= 0.6615131561245237\n",
      "epoch= 39 loss= 0.6607211381196976\n",
      "epoch= 40 loss= 0.6597872099706105\n",
      "epoch= 41 loss= 0.6596412254231316\n",
      "epoch= 42 loss= 0.659112383212362\n",
      "epoch= 43 loss= 0.6591123129640307\n",
      "epoch= 44 loss= 0.6576234698295593\n",
      "epoch= 45 loss= 0.6570806588445391\n",
      "epoch= 46 loss= 0.6567148225648063\n",
      "epoch= 47 loss= 0.6562864099230085\n",
      "epoch= 48 loss= 0.6555905363389424\n",
      "epoch= 49 loss= 0.6549851787941796\n",
      "epoch= 50 loss= 0.6542995955262866\n",
      "epoch= 51 loss= 0.6533974621977124\n",
      "epoch= 52 loss= 0.652783242719514\n",
      "epoch= 53 loss= 0.6516550374882562\n",
      "epoch= 54 loss= 0.6514915653637477\n",
      "epoch= 55 loss= 0.6502176289047513\n",
      "epoch= 56 loss= 0.6491467037371227\n",
      "epoch= 57 loss= 0.6484917849302292\n",
      "epoch= 58 loss= 0.6474253535270691\n",
      "epoch= 59 loss= 0.6467467056853431\n",
      "epoch= 60 loss= 0.6459627023765019\n",
      "epoch= 61 loss= 0.6446705737284252\n",
      "epoch= 62 loss= 0.6435902863740921\n",
      "epoch= 63 loss= 0.6424968753542218\n",
      "epoch= 64 loss= 0.6408199455056872\n",
      "epoch= 65 loss= 0.6409012036664146\n",
      "epoch= 66 loss= 0.6400737421853202\n",
      "epoch= 67 loss= 0.638696415083749\n",
      "epoch= 68 loss= 0.6371295388255801\n",
      "epoch= 69 loss= 0.6362794914415905\n",
      "epoch= 70 loss= 0.6353338020188468\n",
      "epoch= 71 loss= 0.6339617648294994\n",
      "epoch= 72 loss= 0.6331724694796971\n",
      "epoch= 73 loss= 0.631867168205125\n",
      "epoch= 74 loss= 0.6312644949981144\n",
      "epoch= 75 loss= 0.6299747186047691\n",
      "epoch= 76 loss= 0.6282446597303663\n",
      "epoch= 77 loss= 0.6279866141932351\n",
      "epoch= 78 loss= 0.6261094574417386\n",
      "epoch= 79 loss= 0.6246857792139053\n",
      "epoch= 80 loss= 0.6239412256649562\n",
      "epoch= 81 loss= 0.6226201759917396\n",
      "epoch= 82 loss= 0.621598807828767\n",
      "epoch= 83 loss= 0.620612844824791\n",
      "epoch= 84 loss= 0.619306451507977\n",
      "epoch= 85 loss= 0.6189310742276055\n",
      "epoch= 86 loss= 0.6176929026842117\n",
      "epoch= 87 loss= 0.6179902510983604\n",
      "epoch= 88 loss= 0.6168528497219086\n",
      "epoch= 89 loss= 0.6162971960646766\n",
      "epoch= 90 loss= 0.6154516296727317\n",
      "epoch= 91 loss= 0.6149904696004731\n",
      "epoch= 92 loss= 0.6141902080604008\n",
      "epoch= 93 loss= 0.6143394964081901\n",
      "epoch= 94 loss= 0.6134974669132914\n",
      "epoch= 95 loss= 0.6139823198318481\n",
      "epoch= 96 loss= 0.6130825919764382\n",
      "epoch= 97 loss= 0.6120164841413498\n",
      "epoch= 98 loss= 0.6120200327464512\n",
      "epoch= 99 loss= 0.6101993450096675\n",
      "epoch= 100 loss= 0.6080568517957415\n",
      "epoch= 101 loss= 0.6089904946940286\n",
      "epoch= 102 loss= 0.6067129778010505\n",
      "epoch= 103 loss= 0.6081709563732147\n",
      "epoch= 104 loss= 0.6067469567060471\n",
      "epoch= 105 loss= 0.6066421717405319\n",
      "epoch= 106 loss= 0.6064536028674671\n",
      "epoch= 107 loss= 0.605108876313482\n",
      "epoch= 108 loss= 0.6045795402356556\n",
      "epoch= 109 loss= 0.6031914736543383\n",
      "epoch= 110 loss= 0.6032971505607877\n",
      "epoch= 111 loss= 0.6023671797343663\n",
      "epoch= 112 loss= 0.6023769974708557\n",
      "epoch= 113 loss= 0.6001816647393363\n",
      "epoch= 114 loss= 0.6009300627878734\n",
      "epoch= 115 loss= 0.5978112689086369\n",
      "epoch= 116 loss= 0.5988833861691611\n",
      "epoch= 117 loss= 0.5979682100670678\n",
      "epoch= 118 loss= 0.597832912845271\n",
      "epoch= 119 loss= 0.5965544070516314\n",
      "epoch= 120 loss= 0.5970398017338344\n",
      "epoch= 121 loss= 0.5949985086917877\n",
      "epoch= 122 loss= 0.5938894801906177\n",
      "epoch= 123 loss= 0.5936458046947207\n",
      "epoch= 124 loss= 0.5935870589954513\n",
      "epoch= 125 loss= 0.5938977875879833\n",
      "epoch= 126 loss= 0.5922611440931048\n",
      "epoch= 127 loss= 0.5901163561003548\n",
      "epoch= 128 loss= 0.5893580338784626\n",
      "epoch= 129 loss= 0.5906490726130349\n",
      "epoch= 130 loss= 0.5895326967750277\n",
      "epoch= 131 loss= 0.5891645337854113\n",
      "epoch= 132 loss= 0.5864042661019734\n",
      "epoch= 133 loss= 0.5863132625818253\n",
      "epoch= 134 loss= 0.5843298860958644\n",
      "epoch= 135 loss= 0.5839964715497834\n",
      "epoch= 136 loss= 0.5817353448697499\n",
      "epoch= 137 loss= 0.5841397834675652\n",
      "epoch= 138 loss= 0.5817190515143531\n",
      "epoch= 139 loss= 0.5799345618912152\n",
      "epoch= 140 loss= 0.5785873372639928\n",
      "epoch= 141 loss= 0.5805760536875043\n",
      "epoch= 142 loss= 0.5789305535810334\n",
      "epoch= 143 loss= 0.5764705485531262\n",
      "epoch= 144 loss= 0.5758877673319408\n",
      "epoch= 145 loss= 0.578219799058778\n",
      "epoch= 146 loss= 0.5762902764337403\n",
      "epoch= 147 loss= 0.5712477852191243\n",
      "epoch= 148 loss= 0.5752092333776611\n",
      "epoch= 149 loss= 0.5752716713718006\n",
      "epoch= 150 loss= 0.5741637146898678\n",
      "epoch= 151 loss= 0.5673402739422662\n",
      "epoch= 152 loss= 0.5678200519510678\n",
      "epoch= 153 loss= 0.5663482025265694\n",
      "epoch= 154 loss= 0.568457770560469\n",
      "epoch= 155 loss= 0.5675308097686086\n",
      "epoch= 156 loss= 0.5753944739699364\n",
      "epoch= 157 loss= 0.5655055471829006\n",
      "epoch= 158 loss= 0.562853927058833\n",
      "epoch= 159 loss= 0.5604625961610249\n",
      "epoch= 160 loss= 0.5630508054580007\n",
      "epoch= 161 loss= 0.5638755623783384\n",
      "epoch= 162 loss= 0.5649090643439975\n",
      "epoch= 163 loss= 0.5604937534247126\n",
      "epoch= 164 loss= 0.5635922242488179\n",
      "epoch= 165 loss= 0.5577006371957915\n",
      "epoch= 166 loss= 0.5678208864160946\n",
      "epoch= 167 loss= 0.561894606266703\n",
      "epoch= 168 loss= 0.5502504748957497\n",
      "epoch= 169 loss= 0.5610799310462815\n",
      "epoch= 170 loss= 0.556366038109575\n",
      "epoch= 171 loss= 0.5460031319941793\n",
      "epoch= 172 loss= 0.5673320687242916\n",
      "epoch= 173 loss= 0.5422100626996585\n",
      "epoch= 174 loss= 0.5587364584207535\n",
      "epoch= 175 loss= 0.5515166563647134\n",
      "epoch= 176 loss= 0.5499186505164418\n",
      "epoch= 177 loss= 0.5446505876524108\n",
      "epoch= 178 loss= 0.547899274953774\n",
      "epoch= 179 loss= 0.5467701799103192\n",
      "epoch= 180 loss= 0.5466527289577893\n",
      "epoch= 181 loss= 0.5478086375764438\n",
      "epoch= 182 loss= 0.5397603362798691\n",
      "epoch= 183 loss= 0.530506295817239\n",
      "epoch= 184 loss= 0.5451332479715347\n",
      "epoch= 185 loss= 0.5488355681300163\n",
      "epoch= 186 loss= 0.543871491083077\n",
      "epoch= 187 loss= 0.5522084619317736\n",
      "epoch= 188 loss= 0.5392631994826453\n",
      "epoch= 189 loss= 0.5564389037234443\n",
      "epoch= 190 loss= 0.5326817333698273\n",
      "epoch= 191 loss= 0.5399001219442913\n",
      "epoch= 192 loss= 0.538210537816797\n",
      "epoch= 193 loss= 0.5326638658131871\n",
      "epoch= 194 loss= 0.5337551949279649\n",
      "epoch= 195 loss= 0.5227160006761551\n",
      "epoch= 196 loss= 0.5477567112871579\n",
      "epoch= 197 loss= 0.5274826362729073\n",
      "epoch= 198 loss= 0.5246833477701459\n",
      "epoch= 199 loss= 0.5123938981975827\n",
      "epoch= 200 loss= 0.5264008811541966\n",
      "epoch= 201 loss= 0.5246940159371921\n",
      "epoch= 202 loss= 0.5375539745603289\n",
      "epoch= 203 loss= 0.5304495245218277\n",
      "epoch= 204 loss= 0.5369387535112244\n",
      "epoch= 205 loss= 0.5240643247961998\n",
      "epoch= 206 loss= 0.5276254596454757\n",
      "epoch= 207 loss= 0.5283019627843585\n",
      "epoch= 208 loss= 0.5145736059972218\n",
      "epoch= 209 loss= 0.5246624435697284\n",
      "epoch= 210 loss= 0.5328829714230129\n",
      "epoch= 211 loss= 0.5286307696785245\n",
      "epoch= 212 loss= 0.5450571051665715\n",
      "epoch= 213 loss= 0.5080672385437148\n",
      "epoch= 214 loss= 0.5264297308666366\n",
      "epoch= 215 loss= 0.5111016897218568\n",
      "epoch= 216 loss= 0.5285705093826566\n",
      "epoch= 217 loss= 0.5338085346988269\n",
      "epoch= 218 loss= 0.5244290551968983\n",
      "epoch= 219 loss= 0.5305185594729015\n",
      "epoch= 220 loss= 0.5191707760095596\n",
      "epoch= 221 loss= 0.5191623419523239\n",
      "epoch= 222 loss= 0.5216729300362724\n",
      "epoch= 223 loss= 0.5200360289641789\n",
      "epoch= 224 loss= 0.5245159789919853\n",
      "epoch= 225 loss= 0.513182242001806\n",
      "epoch= 226 loss= 0.5223943112151963\n",
      "epoch= 227 loss= 0.5067845987422126\n",
      "epoch= 228 loss= 0.5220158674887249\n",
      "epoch= 229 loss= 0.5232222271817071\n",
      "epoch= 230 loss= 0.5198102167674473\n",
      "epoch= 231 loss= 0.5221512211220605\n",
      "epoch= 232 loss= 0.5253246160490173\n",
      "epoch= 233 loss= 0.5309390553406307\n",
      "epoch= 234 loss= 0.5252530479005405\n",
      "epoch= 235 loss= 0.5017085905585971\n",
      "epoch= 236 loss= 0.5232397669128009\n",
      "epoch= 237 loss= 0.5020450353622437\n",
      "epoch= 238 loss= 0.5106803998351097\n",
      "epoch= 239 loss= 0.511754076395716\n",
      "epoch= 240 loss= 0.49206897084202084\n",
      "epoch= 241 loss= 0.508683161011764\n",
      "epoch= 242 loss= 0.5094247502940041\n",
      "epoch= 243 loss= 0.516167374593871\n",
      "epoch= 244 loss= 0.5089079780238015\n",
      "epoch= 245 loss= 0.5106831469706127\n",
      "epoch= 246 loss= 0.5044784013714109\n",
      "epoch= 247 loss= 0.4920348125909056\n",
      "epoch= 248 loss= 0.5114390945860318\n",
      "epoch= 249 loss= 0.49537297444684164\n",
      "epoch= 250 loss= 0.5311362956251416\n",
      "epoch= 251 loss= 0.51321720544781\n",
      "epoch= 252 loss= 0.5266204018677983\n",
      "epoch= 253 loss= 0.5020359456539154\n",
      "epoch= 254 loss= 0.5167476183601788\n",
      "epoch= 255 loss= 0.5174543229596955\n",
      "epoch= 256 loss= 0.5202923810907772\n",
      "epoch= 257 loss= 0.5067828776580947\n",
      "epoch= 258 loss= 0.51472357660532\n",
      "epoch= 259 loss= 0.5209623553923198\n",
      "epoch= 260 loss= 0.5130477068679673\n",
      "epoch= 261 loss= 0.5089382656982967\n",
      "epoch= 262 loss= 0.49570787591593607\n",
      "epoch= 263 loss= 0.49102344789675306\n",
      "epoch= 264 loss= 0.5159113960606712\n",
      "epoch= 265 loss= 0.5253071699823652\n",
      "epoch= 266 loss= 0.5195686604295459\n",
      "epoch= 267 loss= 0.5111267140933445\n",
      "epoch= 268 loss= 0.5164459624460765\n",
      "epoch= 269 loss= 0.5018817516309875\n",
      "epoch= 270 loss= 0.5071741747004646\n",
      "epoch= 271 loss= 0.5254256757242339\n",
      "epoch= 272 loss= 0.5213384245123182\n",
      "epoch= 273 loss= 0.49873548852545874\n",
      "epoch= 274 loss= 0.5051564680678504\n",
      "epoch= 275 loss= 0.4978354796767235\n",
      "epoch= 276 loss= 0.4962994818176542\n",
      "epoch= 277 loss= 0.51262737597738\n",
      "epoch= 278 loss= 0.5168550472174372\n",
      "epoch= 279 loss= 0.5080828304801669\n",
      "epoch= 280 loss= 0.48970070694174084\n",
      "epoch= 281 loss= 0.49497621612889425\n",
      "epoch= 282 loss= 0.5189064975295749\n",
      "epoch= 283 loss= 0.4865932964852878\n",
      "epoch= 284 loss= 0.5242871131215777\n",
      "epoch= 285 loss= 0.4906220925705774\n",
      "epoch= 286 loss= 0.5158248916268349\n",
      "epoch= 287 loss= 0.5149919571621078\n",
      "epoch= 288 loss= 0.4939162773745401\n",
      "epoch= 289 loss= 0.51010705104896\n",
      "epoch= 290 loss= 0.5136088590536799\n",
      "epoch= 291 loss= 0.5181282726781709\n",
      "epoch= 292 loss= 0.49362802718366894\n",
      "epoch= 293 loss= 0.5010608126010213\n",
      "epoch= 294 loss= 0.5174671241215297\n",
      "epoch= 295 loss= 0.513597557587283\n",
      "epoch= 296 loss= 0.5142204090952873\n",
      "epoch= 297 loss= 0.5045773003782544\n",
      "epoch= 298 loss= 0.4990490110857146\n",
      "epoch= 299 loss= 0.49892994335719515\n",
      "epoch= 300 loss= 0.4753112196922302\n",
      "epoch= 301 loss= 0.5183894240430423\n",
      "epoch= 302 loss= 0.49725026318005155\n",
      "epoch= 303 loss= 0.4931624989424433\n",
      "epoch= 304 loss= 0.501217857003212\n",
      "epoch= 305 loss= 0.49009375487055096\n",
      "epoch= 306 loss= 0.49794337153434753\n",
      "epoch= 307 loss= 0.5138363827552114\n",
      "epoch= 308 loss= 0.5022285591278758\n",
      "epoch= 309 loss= 0.49781857963119236\n",
      "epoch= 310 loss= 0.49954613723925184\n",
      "epoch= 311 loss= 0.4940486731273787\n",
      "epoch= 312 loss= 0.5014895126223564\n",
      "epoch= 313 loss= 0.5094014959675925\n",
      "epoch= 314 loss= 0.4821037490453039\n",
      "epoch= 315 loss= 0.5112167192356927\n",
      "epoch= 316 loss= 0.49917668104171753\n",
      "epoch= 317 loss= 0.4910075462290219\n",
      "epoch= 318 loss= 0.4909686265247209\n",
      "epoch= 319 loss= 0.5096532691802297\n",
      "epoch= 320 loss= 0.5103546700307301\n",
      "epoch= 321 loss= 0.486304725919451\n",
      "epoch= 322 loss= 0.5102682145578521\n",
      "epoch= 323 loss= 0.5058291075485093\n",
      "epoch= 324 loss= 0.5136854893394879\n",
      "epoch= 325 loss= 0.5038200925503459\n",
      "epoch= 326 loss= 0.5030777273433549\n",
      "epoch= 327 loss= 0.509662464261055\n",
      "epoch= 328 loss= 0.5018375803317342\n",
      "epoch= 329 loss= 0.5139274405581611\n",
      "epoch= 330 loss= 0.49062298025403706\n",
      "epoch= 331 loss= 0.4762135350278446\n",
      "epoch= 332 loss= 0.5128641266907964\n",
      "epoch= 333 loss= 0.5018145527158465\n",
      "epoch= 334 loss= 0.4939260355063847\n",
      "epoch= 335 loss= 0.49130560031958986\n",
      "epoch= 336 loss= 0.5001167218600001\n",
      "epoch= 337 loss= 0.5212987714580127\n",
      "epoch= 338 loss= 0.5020405405334064\n",
      "epoch= 339 loss= 0.48698835713522776\n",
      "epoch= 340 loss= 0.5129084533878735\n",
      "epoch= 341 loss= 0.4826282933354378\n",
      "epoch= 342 loss= 0.4760621211358479\n",
      "epoch= 343 loss= 0.4977673462459019\n",
      "epoch= 344 loss= 0.4878090683903013\n",
      "epoch= 345 loss= 0.48368915383304867\n",
      "epoch= 346 loss= 0.4952801125390189\n",
      "epoch= 347 loss= 0.4845347787652697\n",
      "epoch= 348 loss= 0.48678107133933474\n",
      "epoch= 349 loss= 0.5126502673540797\n",
      "epoch= 350 loss= 0.4995031463248389\n",
      "epoch= 351 loss= 0.4926823654345104\n",
      "epoch= 352 loss= 0.4957422518304416\n",
      "epoch= 353 loss= 0.4875355852501733\n",
      "epoch= 354 loss= 0.5004266798496246\n",
      "epoch= 355 loss= 0.4879221777830805\n",
      "epoch= 356 loss= 0.49209114802735193\n",
      "epoch= 357 loss= 0.49956146414790836\n",
      "epoch= 358 loss= 0.47891214596373693\n",
      "epoch= 359 loss= 0.4827573671936989\n",
      "epoch= 360 loss= 0.48021042346954346\n",
      "epoch= 361 loss= 0.49701685458421707\n",
      "epoch= 362 loss= 0.4946929376040186\n",
      "epoch= 363 loss= 0.4810074833886964\n",
      "epoch= 364 loss= 0.4968668839761189\n",
      "epoch= 365 loss= 0.4874568464500563\n",
      "epoch= 366 loss= 0.4928746883358274\n",
      "epoch= 367 loss= 0.5055441239050457\n",
      "epoch= 368 loss= 0.4842142452086721\n",
      "epoch= 369 loss= 0.47889699254717144\n",
      "epoch= 370 loss= 0.4892582233463015\n",
      "epoch= 371 loss= 0.4897302900041853\n",
      "epoch= 372 loss= 0.49733662605285645\n",
      "epoch= 373 loss= 0.4784549953682082\n",
      "epoch= 374 loss= 0.46987019159964155\n",
      "epoch= 375 loss= 0.5005738511681557\n",
      "epoch= 376 loss= 0.4828216092927115\n",
      "epoch= 377 loss= 0.47844833401697023\n",
      "epoch= 378 loss= 0.48043341508933474\n",
      "epoch= 379 loss= 0.47948247087853296\n",
      "epoch= 380 loss= 0.49151418464524405\n",
      "epoch= 381 loss= 0.49991357220070703\n",
      "epoch= 382 loss= 0.4880513240184103\n",
      "epoch= 383 loss= 0.4991203748754093\n",
      "epoch= 384 loss= 0.49116509194884983\n",
      "epoch= 385 loss= 0.487784780561924\n",
      "epoch= 386 loss= 0.4750691865171705\n",
      "epoch= 387 loss= 0.4902698876602309\n",
      "epoch= 388 loss= 0.4901788905262947\n",
      "epoch= 389 loss= 0.4837409353681973\n",
      "epoch= 390 loss= 0.4715080750840051\n",
      "epoch= 391 loss= 0.48802422253148897\n",
      "epoch= 392 loss= 0.48309718391724993\n",
      "epoch= 393 loss= 0.47190994556461063\n",
      "epoch= 394 loss= 0.48178994229861666\n",
      "epoch= 395 loss= 0.49157688873154776\n",
      "epoch= 396 loss= 0.46530718143497196\n",
      "epoch= 397 loss= 0.49741778522729874\n",
      "epoch= 398 loss= 0.514120585152081\n",
      "epoch= 399 loss= 0.47856171961341587\n",
      "epoch= 400 loss= 0.4725830533674785\n",
      "epoch= 401 loss= 0.48088580795696806\n",
      "epoch= 402 loss= 0.4823002719453403\n",
      "epoch= 403 loss= 0.4740951731801033\n",
      "epoch= 404 loss= 0.4770275035074779\n",
      "epoch= 405 loss= 0.4814139860016959\n",
      "epoch= 406 loss= 0.4870505556464195\n",
      "epoch= 407 loss= 0.49092845086540493\n",
      "epoch= 408 loss= 0.4654237564120974\n",
      "epoch= 409 loss= 0.4939112088509968\n",
      "epoch= 410 loss= 0.5095130013568061\n",
      "epoch= 411 loss= 0.4739046330962862\n",
      "epoch= 412 loss= 0.479610270687512\n",
      "epoch= 413 loss= 0.46258662215300966\n",
      "epoch= 414 loss= 0.4788799775498254\n",
      "epoch= 415 loss= 0.49062784016132355\n",
      "epoch= 416 loss= 0.4773179462977818\n",
      "epoch= 417 loss= 0.47055858267205103\n",
      "epoch= 418 loss= 0.4691751721714224\n",
      "epoch= 419 loss= 0.47707134378807886\n",
      "epoch= 420 loss= 0.48556558255638393\n",
      "epoch= 421 loss= 0.49713331567389624\n",
      "epoch= 422 loss= 0.47433254548481535\n",
      "epoch= 423 loss= 0.47252611815929413\n",
      "epoch= 424 loss= 0.5003309441464288\n",
      "epoch= 425 loss= 0.4984105612550463\n",
      "epoch= 426 loss= 0.48973216648612705\n",
      "epoch= 427 loss= 0.47470157806362423\n",
      "epoch= 428 loss= 0.47965272409575327\n",
      "epoch= 429 loss= 0.4731839011822428\n",
      "epoch= 430 loss= 0.48610248416662216\n",
      "epoch= 431 loss= 0.48262227699160576\n",
      "epoch= 432 loss= 0.4904409646987915\n",
      "epoch= 433 loss= 0.5143315472773143\n",
      "epoch= 434 loss= 0.4759508381996836\n",
      "epoch= 435 loss= 0.4887582127537046\n",
      "epoch= 436 loss= 0.4700395241379738\n",
      "epoch= 437 loss= 0.4898651699934687\n",
      "epoch= 438 loss= 0.4934746612395559\n",
      "epoch= 439 loss= 0.48483228577034815\n",
      "epoch= 440 loss= 0.4896988943219185\n",
      "epoch= 441 loss= 0.48580977639981676\n",
      "epoch= 442 loss= 0.47928119770118166\n",
      "epoch= 443 loss= 0.4694563980613436\n",
      "epoch= 444 loss= 0.469311135155814\n",
      "epoch= 445 loss= 0.4789497884256499\n",
      "epoch= 446 loss= 0.4839335243616785\n",
      "epoch= 447 loss= 0.4627372484122004\n",
      "epoch= 448 loss= 0.4802137560078076\n",
      "epoch= 449 loss= 0.48416946828365326\n",
      "epoch= 450 loss= 0.47298119749341694\n",
      "epoch= 451 loss= 0.4698993595583098\n",
      "epoch= 452 loss= 0.4644380525818893\n",
      "epoch= 453 loss= 0.4651221569095339\n",
      "epoch= 454 loss= 0.5022432474153382\n",
      "epoch= 455 loss= 0.46821632449116024\n",
      "epoch= 456 loss= 0.5025960366640773\n",
      "epoch= 457 loss= 0.4638858512043953\n",
      "epoch= 458 loss= 0.4837494449956076\n",
      "epoch= 459 loss= 0.45701433452112333\n",
      "epoch= 460 loss= 0.4730831491095679\n",
      "epoch= 461 loss= 0.4720090680888721\n",
      "epoch= 462 loss= 0.4702926586781229\n",
      "epoch= 463 loss= 0.4815687303032194\n",
      "epoch= 464 loss= 0.4777053881968771\n",
      "epoch= 465 loss= 0.46842687683446066\n",
      "epoch= 466 loss= 0.47819801952157703\n",
      "epoch= 467 loss= 0.46268702085529057\n",
      "epoch= 468 loss= 0.46486091294458937\n",
      "epoch= 469 loss= 0.47707945108413696\n",
      "epoch= 470 loss= 0.48568215859787806\n",
      "epoch= 471 loss= 0.4724485086543219\n",
      "epoch= 472 loss= 0.46907778616462437\n",
      "epoch= 473 loss= 0.46971999428101946\n",
      "epoch= 474 loss= 0.4993921220302582\n",
      "epoch= 475 loss= 0.4795012782726969\n",
      "epoch= 476 loss= 0.4648370678935732\n",
      "epoch= 477 loss= 0.46619378881795065\n",
      "epoch= 478 loss= 0.48393102309533526\n",
      "epoch= 479 loss= 0.47775871200220926\n",
      "epoch= 480 loss= 0.457143386559827\n",
      "epoch= 481 loss= 0.464851082435676\n",
      "epoch= 482 loss= 0.4744799679943493\n",
      "epoch= 483 loss= 0.4695324482662337\n",
      "epoch= 484 loss= 0.49950301753623144\n",
      "epoch= 485 loss= 0.47983534953423906\n",
      "epoch= 486 loss= 0.4707108565739223\n",
      "epoch= 487 loss= 0.48480917513370514\n",
      "epoch= 488 loss= 0.5048857693161283\n",
      "epoch= 489 loss= 0.46907685697078705\n",
      "epoch= 490 loss= 0.47360250247376307\n",
      "epoch= 491 loss= 0.47622634896210264\n",
      "epoch= 492 loss= 0.455825859946864\n",
      "epoch= 493 loss= 0.4666562708360808\n",
      "epoch= 494 loss= 0.4727423850979124\n",
      "epoch= 495 loss= 0.466664867741721\n",
      "epoch= 496 loss= 0.4557844123670033\n",
      "epoch= 497 loss= 0.47662718700511114\n",
      "epoch= 498 loss= 0.4633856916001865\n",
      "epoch= 499 loss= 0.46489873049514635\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define model using class\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class TitanicModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TitanicModel, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(10, 8)\n",
    "        self.linear2 = torch.nn.Linear(8, 4)\n",
    "        self.linear3 = torch.nn.Linear(4, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.linear1(x))\n",
    "        x = self.sigmoid(self.linear2(x))\n",
    "        x = self.sigmoid(self.linear3(x))\n",
    "        return x\n",
    "\n",
    "model = TitanicModel()\n",
    "\n",
    "# define loss functions and optimizer\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n",
    "\n",
    "# training cycle\n",
    "epoch_loss_list = []\n",
    "batch_loss_list = []\n",
    "for epoch in range(500):\n",
    "    epoch_loss = 0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        input, labels = data  # 获得数据和标签\n",
    "        # forward\n",
    "        y_pred = model(input)\n",
    "        loss = criterion(y_pred, labels)\n",
    "        epoch_loss += loss.item()\n",
    "        batch_loss_list.append(loss.item())\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # update\n",
    "        optimizer.step()\n",
    "    epoch_loss_list.append(epoch_loss/len(train_dataloader))\n",
    "    print('epoch=', epoch, 'loss=', epoch_loss/len(train_dataloader))\n",
    "plt.plot(list(range(len(batch_loss_list))), batch_loss_list)\n",
    "plt.plot(list(range(0, len(epoch_loss_list)*len(train_dataloader), len(train_dataloader))), epoch_loss_list)\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 对测试集数据进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         1\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_submission = pd.read_csv('./titanic/gender_submission.csv')\n",
    "gender_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass        Age  SibSp  Parch     Fare  \\\n",
       "0              1       0.0       3  22.000000      1      0   7.2500   \n",
       "1              2       1.0       1  38.000000      1      0  71.2833   \n",
       "2              3       1.0       3  26.000000      0      0   7.9250   \n",
       "3              4       1.0       1  35.000000      1      0  53.1000   \n",
       "4              5       0.0       3  35.000000      0      0   8.0500   \n",
       "..           ...       ...     ...        ...    ...    ...      ...   \n",
       "886          887       0.0       2  27.000000      0      0  13.0000   \n",
       "887          888       1.0       1  19.000000      0      0  30.0000   \n",
       "888          889       0.0       3  29.881138      1      2  23.4500   \n",
       "889          890       1.0       1  26.000000      0      0  30.0000   \n",
       "890          891       0.0       3  32.000000      0      0   7.7500   \n",
       "\n",
       "     Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0             0         1           0           0           1  \n",
       "1             1         0           1           0           0  \n",
       "2             1         0           0           0           1  \n",
       "3             1         0           0           0           1  \n",
       "4             0         1           0           0           1  \n",
       "..          ...       ...         ...         ...         ...  \n",
       "886           0         1           0           0           1  \n",
       "887           1         0           0           0           1  \n",
       "888           1         0           0           0           1  \n",
       "889           0         1           1           0           0  \n",
       "890           0         1           0           1           0  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108.9000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>29.881138</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass        Age  SibSp  Parch      Fare  \\\n",
       "0            892       NaN       3  34.500000      0      0    7.8292   \n",
       "1            893       NaN       3  47.000000      1      0    7.0000   \n",
       "2            894       NaN       2  62.000000      0      0    9.6875   \n",
       "3            895       NaN       3  27.000000      0      0    8.6625   \n",
       "4            896       NaN       3  22.000000      1      1   12.2875   \n",
       "..           ...       ...     ...        ...    ...    ...       ...   \n",
       "413         1305       NaN       3  29.881138      0      0    8.0500   \n",
       "414         1306       NaN       1  39.000000      0      0  108.9000   \n",
       "415         1307       NaN       3  38.500000      0      0    7.2500   \n",
       "416         1308       NaN       3  29.881138      0      0    8.0500   \n",
       "417         1309       NaN       3  29.881138      1      1   22.3583   \n",
       "\n",
       "     Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0             0         1           0           1           0  \n",
       "1             1         0           0           0           1  \n",
       "2             0         1           0           1           0  \n",
       "3             0         1           0           0           1  \n",
       "4             1         0           0           0           1  \n",
       "..          ...       ...         ...         ...         ...  \n",
       "413           0         1           0           0           1  \n",
       "414           1         0           1           0           0  \n",
       "415           0         1           0           0           1  \n",
       "416           0         1           0           0           1  \n",
       "417           0         1           1           0           0  \n",
       "\n",
       "[418 rows x 12 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         1\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 停止构建计算图\n",
    "final_result = []\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(test_dataloader):\n",
    "        input = data\n",
    "        y_pred = model(input)\n",
    "        final_result.extend(list(map(lambda x: 1 if x>0.5 else 0, y_pred.view(-1).tolist())))\n",
    "final_file = pd.DataFrame({'PassengerId': test['PassengerId'], 'Survived': final_result})\n",
    "final_file.to_csv('Titanic_predict_result.csv', index=False, encoding='utf-8')\n",
    "final_file\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    213\n",
       "0    205\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_file['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture_09_Softmax_Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9729)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "y = torch.LongTensor([0])\n",
    "z = torch.Tensor([[0.2, 0.1, -0.1]])\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "loss = criterion(z, y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss1= 0.4966353178024292 \n",
      "Batch Loss2= 1.2388995885849\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "Y = torch.LongTensor([2, 0, 1])\n",
    "Y_pred1 = torch.Tensor([[0.1, 0.2, 0.9], \n",
    "                        [1.1, 0.1, 0.2], \n",
    "                        [0.2, 2.1, 0.1]])\n",
    "Y_pred2 = torch.Tensor([[0.8, 0.2, 0.3], \n",
    "                        [0.2, 0.3, 0.5], \n",
    "                        [0.2, 0.2, 0.5]])\n",
    "l1 = criterion(Y_pred1, Y)\n",
    "l2 = criterion(Y_pred2, Y)\n",
    "print('Batch Loss1=', l1.item(), '\\nBatch Loss2=', l2.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim \n",
    "\n",
    "batch_size = 64\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize((0.1307, ), (0.3081, ))  # MINIST数据集的均值和方差\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./', \n",
    "                               train=True, \n",
    "                               download=True, \n",
    "                               transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./', \n",
    "                              train=False, \n",
    "                              transform=transform)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=batch_size, \n",
    "                         shuffle=False)\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(784, 512)\n",
    "        self.l2 = torch.nn.Linear(512, 256)\n",
    "        self.l3 = torch.nn.Linear(256, 128)\n",
    "        self.l4 = torch.nn.Linear(128, 64)\n",
    "        self.l5 = torch.nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)  # 一张图片即为一个行向量即一个样本\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        x = F.relu(self.l4(x))\n",
    "        return self.l5(x)\n",
    "\n",
    "model = Net()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "def train(epoch):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, data in enumerate(train_loader, 0):\n",
    "        inputs, target = data\n",
    "        optimizer.zero_grad()\n",
    "        # forward+backward+update\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if batch_idx%300 == 299:\n",
    "            print('[%d, %5d] loss: %.3f'%(epoch+1, batch_idx+1, running_loss/300))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)  # torch.max函数的dim=0时表示每一列的最大值，dim=1时表示每一行的最大值\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy on test set: %d %%'%(100*correct/total))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    for epoch in range(10):\n",
    "        train(epoch)\n",
    "        test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture_10_Basic_CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 输入、输出和卷积核的尺寸之间的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 100, 100])\n",
      "torch.Size([1, 10, 98, 98])\n",
      "torch.Size([10, 5, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "in_channels, out_channels = 5, 10\n",
    "width, height = 100, 100\n",
    "kernel_size = 3\n",
    "batch_size = 1\n",
    "\n",
    "input = torch.randn(batch_size, \n",
    "                    in_channels, \n",
    "                    width, \n",
    "                    height)\n",
    "\n",
    "# 输入的通道，输出的通道，卷积核的尺寸\n",
    "conv_layer = torch.nn.Conv2d(in_channels, \n",
    "                             out_channels, \n",
    "                             kernel_size=kernel_size)\n",
    "\n",
    "output = conv_layer(input)\n",
    "print(input.shape)\n",
    "print(output.shape)\n",
    "print(conv_layer.weight.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 引入padding这个参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 91., 168., 224., 215., 127.],\n",
      "          [114., 211., 295., 262., 149.],\n",
      "          [192., 259., 282., 214., 122.],\n",
      "          [194., 251., 253., 169.,  86.],\n",
      "          [ 96., 112., 110.,  68.,  31.]]]], grad_fn=<ThnnConv2DBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "input = [3, 4, 6, 5, 7, \n",
    "         2, 4, 6, 8, 2, \n",
    "         1, 6, 7, 8, 4, \n",
    "         9, 7, 4, 6, 2, \n",
    "         3, 7, 5, 4, 1]\n",
    "input = torch.Tensor(input).view(1, 1, 5, 5)\n",
    "conv_layer = torch.nn.Conv2d(1, 1, kernel_size=3, padding=1, bias=False)\n",
    "kernel = torch.Tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]).view(1, 1, 3, 3)\n",
    "conv_layer.weight.data = kernel.data\n",
    "\n",
    "output = conv_layer(input)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 引入stride这个参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[211., 262.],\n",
      "          [251., 169.]]]], grad_fn=<ThnnConv2DBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "input = [3, 4, 6, 5, 7, \n",
    "         2, 4, 6, 8, 2, \n",
    "         1, 6, 7, 8, 4, \n",
    "         9, 7, 4, 6, 2, \n",
    "         3, 7, 5, 4, 1]\n",
    "\n",
    "input = torch.Tensor(input).view(1, 1, 5, 5)  # batch_size, in_channel, width, height\n",
    "conv_layer = torch.nn.Conv2d(1, 1, kernel_size=3, stride=2, bias=False)\n",
    "kernel = torch.Tensor([1, 2, 3, 4, 5, 6, 7, 8, 9]).view(1, 1, 3, 3)\n",
    "conv_layer.weight.data = kernel.data\n",
    "output = conv_layer(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 引入max_pooling，最大池化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[4., 8.],\n",
      "          [9., 8.]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "input = [3, 4, 6, 5, \n",
    "         2, 4, 6, 8, \n",
    "         1, 6, 7, 8, \n",
    "         9, 7, 4, 6]\n",
    "input = torch.Tensor(input).view(1, 1, 4, 4)\n",
    "maxpooling_layer = torch.nn.MaxPool2d(kernel_size=2)\n",
    "output = maxpooling_layer(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 构建一个简单的CNN网络，并将网络放在GPU上运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = torch.nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.pooling = torch.nn.MaxPool2d(2)\n",
    "        self.fc = torch.nn.Linear(320, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Flatten data from (n, 1, 28, 28) to (n, 784)\n",
    "        # 前面层级的CNN网络的作用是提取和挖掘特征\n",
    "        batch_size = x.size(0)\n",
    "        x = F.relu(self.pooling(self.conv1(x)))\n",
    "        x = F.relu(self.pooling(self.conv2(x)))\n",
    "        x = x.view(batch_size, -1)  # flatten\n",
    "        # 到fully collected network这边才实现分类\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "model = Net()\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)  # 将模型的参数和所有模型相关的缓存全部迁移到gpu的tensor上面\n",
    "\n",
    "def train(epoch):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, data in enumerate(train_loader, 0):\n",
    "        inputs, target = data\n",
    "        inputs, target = inputs.to(device), target.to(device)  # 将训练数据迁移到gpu上\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward+backward+update\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % 300 = 299:\n",
    "            print('[%d, %5d loss: %.3f'%(epoch+1, batch_idx+1, running_loss/2000))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            inputs, target = data\n",
    "            inputs, target = inputs.to(device), target.to(device)  # 测试数据迁移到gpu上\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, dim=1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    print('Accuracy on test set: %d %% [%d%d]'%(100*correct/total, correct, total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture_11_Advanced_CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1x1的卷积可以实现不同通道信息的融合，可以实现通道的降维"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- inception网络单元的实现\n",
    "    - 如果卷积核的尺寸是3x3，stride是1，那么如果想要卷积后的图片的尺寸与卷积前的图片的尺寸相同需要padding=1\n",
    "    - 如果卷积核的尺寸是5x5，stride是1，那么如果想要卷积后的图片的尺寸与卷积前的图片的尺寸相同需要padding=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class InceptionA(torch.nn.Module):\n",
    "    def __init__(self, in_channels):  # 初始化需要输入input的通道\n",
    "        super(InceptionA, self).__init__()\n",
    "        self.branch1x1 = torch.nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        \n",
    "        self.branch5x5_1 = torch.nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.branch5x5_2 = torch.nn.Conv2d(16, 24, kernel_size=5, padding=2)\n",
    "        \n",
    "        self.branch3x3_1 = torch.nn.Conv2d(in_channels, 16, kernel_size=1)\n",
    "        self.branch3x3_2 = torch.nn.Conv2d(16, 24, kernel_size=3, padding=1)\n",
    "        self.branch3x3_3 = torch.nn.Conv2d(24, 24, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.branch_pool = torch.nn.Conv2d(in_channels, 24, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        branch1x1 = self.branch1x1(x)\n",
    "        \n",
    "        branch5x5 = self.branch5x5_1(x)\n",
    "        branch5x5 = self.branch5x5_2(branch5x5)\n",
    "        \n",
    "        branch3x3 = self.branch3x3_1(x)\n",
    "        branch3x3 = self.branch3x3_2(branch3x3)\n",
    "        branch3x3 = self.branch3x3_3(branch3x3)\n",
    "        \n",
    "        branch_pool = F.avg_pool2d(x, kernel_size=3, stride=1, padding=1)\n",
    "        branch_pool = self.branch_pool(branch_pool)\n",
    "        \n",
    "        outputs = [branch1x1, branch5x5, branch3x3, branch_pool]\n",
    "        return torch.cat(outputs, dim=1)\n",
    "    \n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = torch.nn.Conv2d(88, 20, kernel_size=5)\n",
    "        \n",
    "        self.incep1 = InceptionA(in_channels=10)\n",
    "        self.incep2 = InceptionA(in_channels=20)\n",
    "        \n",
    "        self.mp = torch.nn.MaxPool2d(2)\n",
    "        self.fc = torch.nn.Linear(1408, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)  # 获得batch_size\n",
    "        x = F.relu(self.mp(self.conv1(x)))\n",
    "        x = self.incep1(x)\n",
    "        x = F.relu(self.mp(self.conv2(x)))\n",
    "        x = self.incep2(x)\n",
    "        x = x.view(in_size, -1)  # 除开batch_size这个维度外展开至一维的\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- residual block 残差网络单元的实现\n",
    "    - 残差网络因为输入和输出之间需要相加，所以输入在经过残差网络前后的尺寸应该是保持不变的，包括有batch_size，channel，width，height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(torch.nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.conv1 = torch.nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.conv1(x))\n",
    "        y = self.conv2(y)\n",
    "        return F.relu(x+y)\n",
    "    \n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 16, kernel_size=5)\n",
    "        self.conv2 = torch.nn.Conv2d(16, 32, kernel_size=5)\n",
    "        self.mp = torch.nn.MaxPool2d(2)\n",
    "        \n",
    "        self.rblock1 = ResidualBlock(16)\n",
    "        self.rblock2 = ResidualBlock(32)\n",
    "        \n",
    "        self.fc = torch.nn.Linear(512, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0)\n",
    "        x = self.mp(F.relu(self.conv1(x)))\n",
    "        x = self.rblock1(x)\n",
    "        x = self.mp(F.relu(self.conv2(x)))\n",
    "        x = self.rblock2(x)\n",
    "        x = x.view(in_size, -1\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- constant scaling block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstantScaling(torch.nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ConstantScaling, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.conv1(x))\n",
    "        y = self.conv2(y)\n",
    "        return F.relu(0.5*y+0.5*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- conv shortcut block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvShortcut(torch.nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ConvShortcut, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
    "        self.conv3 = torch.nn.Conv2d(channels, channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.conv1(x))\n",
    "        y = self.conv2(y)\n",
    "        z = self.conv3(x)\n",
    "        return F.relu(y+z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture_12_Basic_RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pytorch中的循环神经网络单元RNNCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== 0 ====================\n",
      "Input size: torch.Size([1, 4])\n",
      "outputs size: torch.Size([1, 2])\n",
      "tensor([[-0.5313, -0.2857]], grad_fn=<TanhBackward>)\n",
      "==================== 1 ====================\n",
      "Input size: torch.Size([1, 4])\n",
      "outputs size: torch.Size([1, 2])\n",
      "tensor([[-0.0756, -0.2883]], grad_fn=<TanhBackward>)\n",
      "==================== 2 ====================\n",
      "Input size: torch.Size([1, 4])\n",
      "outputs size: torch.Size([1, 2])\n",
      "tensor([[-0.7855,  0.1854]], grad_fn=<TanhBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 1\n",
    "seq_len = 3\n",
    "input_size = 4\n",
    "hidden_size = 2\n",
    "\n",
    "# 若使用RNNCell则需要自己构造循环\n",
    "cell = torch.nn.RNNCell(input_size=input_size, hidden_size=hidden_size)  # 需要指定输入的维度和隐藏层的维度\n",
    "\n",
    "# (seq, batch, features)\n",
    "dataset = torch.randn(seq_len, batch_size, input_size)\n",
    "hidden = torch.zeros(batch_size, hidden_size)  # 初始化第一层的隐藏层的取值\n",
    "\n",
    "# 对每个seq进行遍历并放入到循环神经网络中处理\n",
    "for idx, input in enumerate(dataset):\n",
    "    print('='*20, idx, '='*20)\n",
    "    print('Input size:', input.shape)\n",
    "    \n",
    "    hidden = cell(input, hidden)\n",
    "    print('outputs size:', hidden.shape)\n",
    "    print(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 含有多个隐藏层的循环神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output size torch.Size([3, 1, 2])\n",
      "Output: tensor([[[-0.5094,  0.4242]],\n",
      "\n",
      "        [[ 0.4488, -0.6451]],\n",
      "\n",
      "        [[-0.7084, -0.3307]]], grad_fn=<StackBackward>)\n",
      "hidden size: torch.Size([1, 1, 2])\n",
      "Hidden: tensor([[[-0.7084, -0.3307]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 1\n",
    "seq_len = 3\n",
    "input_size = 4\n",
    "hidden_size = 2\n",
    "num_layers = 1\n",
    "\n",
    "# 直接采用RNN则不需要自己构造循环\n",
    "cell = torch.nn.RNN(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers)  # num_layers表示隐藏层的层数\n",
    "\n",
    "# (seqLen, batchSize, inputSize)\n",
    "inputs = torch.randn(seq_len, batch_size, input_size)\n",
    "hidden = torch.zeros(num_layers, batch_size, hidden_size)\n",
    "\n",
    "out, hidden = cell(inputs, hidden)\n",
    "\n",
    "print('Output size', out.shape)\n",
    "print('Output:', out)\n",
    "print('hidden size:', hidden.shape)\n",
    "print('Hidden:', hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train a model to learn: 'hello' -> 'ohlol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted string:llhhe, Epoch [1/15] loss=7.4720\n",
      "Predicted string:ollll, Epoch [2/15] loss=5.9813\n",
      "Predicted string:ollll, Epoch [3/15] loss=5.1148\n",
      "Predicted string:ollll, Epoch [4/15] loss=4.5604\n",
      "Predicted string:ohlll, Epoch [5/15] loss=4.2131\n",
      "Predicted string:ohlll, Epoch [6/15] loss=3.9848\n",
      "Predicted string:ohlol, Epoch [7/15] loss=3.8035\n",
      "Predicted string:ohlol, Epoch [8/15] loss=3.6315\n",
      "Predicted string:ohlol, Epoch [9/15] loss=3.4715\n",
      "Predicted string:ohlol, Epoch [10/15] loss=3.3382\n",
      "Predicted string:ohlol, Epoch [11/15] loss=3.2217\n",
      "Predicted string:ohlol, Epoch [12/15] loss=3.1244\n",
      "Predicted string:ohlol, Epoch [13/15] loss=3.0671\n",
      "Predicted string:ohlol, Epoch [14/15] loss=2.9986\n",
      "Predicted string:ohlol, Epoch [15/15] loss=2.8630\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "input_size = 4\n",
    "hidden_size = 4\n",
    "batch_size = 1\n",
    "\n",
    "# the dictionary\n",
    "idx2char = ['e', 'h', 'l', 'o']\n",
    "x_data = [1, 0, 2, 2, 3]\n",
    "y_data = [3, 1, 2, 3, 2]\n",
    "\n",
    "one_hot_lookup = [[1, 0, 0, 0], \n",
    "                  [0, 1, 0, 0],\n",
    "                  [0, 0, 1, 0],\n",
    "                  [0, 0, 0, 1]]\n",
    "\n",
    "x_one_hot = [one_hot_lookup[x] for x in x_data]\n",
    "\n",
    "inputs = torch.Tensor(x_one_hot).view(-1, batch_size, input_size)  # seq_len为4\n",
    "labels = torch.LongTensor(y_data).view(-1, 1)\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnncell = torch.nn.RNNCell(input_size=self.input_size, hidden_size=self.hidden_size)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        hidden = self.rnncell(input, hidden)\n",
    "        return hidden\n",
    "\n",
    "    # 初始化隐藏层的取值\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(self.batch_size, self.hidden_size)\n",
    "    \n",
    "net = Model(input_size, hidden_size, batch_size)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)\n",
    "\n",
    "# training cycle\n",
    "for epoch in range(15):\n",
    "    loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    hidden = net.init_hidden()  # 初始化隐藏层\n",
    "    print('Predicted string:', end='')\n",
    "    for input, label in zip(inputs, labels):\n",
    "        hidden = net(input, hidden)\n",
    "        loss += criterion(hidden, label)  # 每层的输出需要计算损失函数\n",
    "        _, idx = hidden.max(dim=1)  # 返回预测的类别，预测可能出现的类别即字典中包含的所有的元素\n",
    "        print(idx2char[idx.item()], end='')\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(', Epoch [%d/15] loss=%.4f'%(epoch+1, loss.item()))\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将RNNCell更改为RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted string:ooeee, Epoch [0/15] loss=1.8067\n",
      "Predicted string:ooooe, Epoch [1/15] loss=1.5144\n",
      "Predicted string:ooooo, Epoch [2/15] loss=1.2478\n",
      "Predicted string:olool, Epoch [3/15] loss=1.0872\n",
      "Predicted string:oholl, Epoch [4/15] loss=1.0019\n",
      "Predicted string:lholl, Epoch [5/15] loss=0.9331\n",
      "Predicted string:lholl, Epoch [6/15] loss=0.8688\n",
      "Predicted string:oholl, Epoch [7/15] loss=0.8212\n",
      "Predicted string:ohlol, Epoch [8/15] loss=0.7896\n",
      "Predicted string:ohlol, Epoch [9/15] loss=0.7613\n",
      "Predicted string:ohlol, Epoch [10/15] loss=0.7298\n",
      "Predicted string:ohlol, Epoch [11/15] loss=0.6952\n",
      "Predicted string:ohlol, Epoch [12/15] loss=0.6600\n",
      "Predicted string:ohlol, Epoch [13/15] loss=0.6271\n",
      "Predicted string:ohlol, Epoch [14/15] loss=0.6005\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_size, num_layers=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = torch.nn.RNN(input_size=self.input_size, \n",
    "                                hidden_size=self.hidden_size, \n",
    "                                num_layers=self.num_layers)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        hidden = torch.zeros(self.num_layers, \n",
    "                             self.batch_size, \n",
    "                             self.hidden_size)  # 第一个隐藏层的初始化，初始化全部设置为0\n",
    "        out, _ = self.rnn(input, hidden)  # out是所有隐藏层的输出，_表示最后一个隐藏层的内容\n",
    "        return out.view(-1, self.hidden_size)\n",
    "\n",
    "input_size = 4\n",
    "hidden_size = 4\n",
    "num_layers = 1\n",
    "batch_size = 1\n",
    "seq_len = 5\n",
    "\n",
    "# define model using class\n",
    "net = Model(input_size, hidden_size, batch_size, num_layers)\n",
    "\n",
    "# prepare dataset\n",
    "idx2char = ['e', 'h', 'l', 'o']\n",
    "x_data = [1, 0, 2, 2, 3]\n",
    "y_data = [3, 1, 2, 3, 2]\n",
    "one_hot_lookup = [[1, 0, 0, 0], \n",
    "                  [0, 1, 0, 0], \n",
    "                  [0, 0, 1, 0], \n",
    "                  [0, 0, 0, 1]]\n",
    "\n",
    "x_one_hot = [one_hot_lookup[x] for x in x_data]\n",
    "inputs = torch.Tensor(x_one_hot).view(seq_len, batch_size, input_size)\n",
    "labels = torch.LongTensor(y_data)\n",
    "\n",
    "# define loss functions and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)\n",
    "\n",
    "# training cycle\n",
    "for epoch in range(15):\n",
    "    # forward\n",
    "    y_pred = net(inputs)\n",
    "    _, predicted = torch.max(y_pred.data, dim=1)\n",
    "    predicted_str = [idx2char[x] for x in predicted]\n",
    "    loss = criterion(y_pred, labels)\n",
    "    print('Predicted string:'+''.join(predicted_str)+', Epoch [%d/15] loss=%.4f'%(epoch, loss.item()))\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # update \n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use embedding and linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  lllll, Epoch [1/15] loss=1.337\n",
      "Predicted:  lhlll, Epoch [2/15] loss=1.017\n",
      "Predicted:  ohlll, Epoch [3/15] loss=0.775\n",
      "Predicted:  ohlol, Epoch [4/15] loss=0.552\n",
      "Predicted:  ohlol, Epoch [5/15] loss=0.351\n",
      "Predicted:  ohlol, Epoch [6/15] loss=0.223\n",
      "Predicted:  ohlol, Epoch [7/15] loss=0.140\n",
      "Predicted:  ohlol, Epoch [8/15] loss=0.089\n",
      "Predicted:  ohlol, Epoch [9/15] loss=0.059\n",
      "Predicted:  ohlol, Epoch [10/15] loss=0.039\n",
      "Predicted:  ohlol, Epoch [11/15] loss=0.026\n",
      "Predicted:  ohlol, Epoch [12/15] loss=0.018\n",
      "Predicted:  ohlol, Epoch [13/15] loss=0.012\n",
      "Predicted:  ohlol, Epoch [14/15] loss=0.009\n",
      "Predicted:  ohlol, Epoch [15/15] loss=0.007\n"
     ]
    }
   ],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):  # 此处可以指定初始化需要的参数\n",
    "        super(Model, self).__init__()\n",
    "        self.emb = torch.nn.Embedding(input_size, embedding_size)\n",
    "        self.rnn = torch.nn.RNN(input_size=embedding_size,  # RNN输入的维度为embedding_size\n",
    "                                hidden_size=hidden_size, \n",
    "                                num_layers=num_layers, \n",
    "                                batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_size, num_class)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        hidden = torch.zeros(num_layers, x.size(0), hidden_size)  # 注意batch_first=True\n",
    "        x = self.emb(x)  # x的维度为(batch, seqLen, embeddingSize)\n",
    "        x, _ = self.rnn(x, hidden)  # x是每个隐藏层的输出，维度为(batch_size, seqLen, hidden_size)\n",
    "        x = self.fc(x)  # x现在的维度为(batch_size, seqLen, num_class)\n",
    "        return x.view(-1, num_class)  # x现在的维度为(batch_size*seqLen, num_class)\n",
    "    \n",
    "# parameters\n",
    "num_class = 4\n",
    "input_size = 4\n",
    "hidden_size = 8\n",
    "embedding_size = 10\n",
    "num_layers = 2\n",
    "batch_size = 1\n",
    "seq_len = 5\n",
    "\n",
    "idx2char = ['e', 'h', 'l', 'o']\n",
    "x_data = [[1, 0, 2, 2, 3]]  # (batch, seq_len)\n",
    "y_data = [3, 1, 2, 3, 2]  # (batch*seq_len)\n",
    "\n",
    "inputs = torch.LongTensor(x_data)\n",
    "labels = torch.LongTensor(y_data)\n",
    "\n",
    "net = Model()\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.05)\n",
    "\n",
    "for epoch in range(15):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    _, idx = outputs.max(dim=1)\n",
    "    idx = idx.data.numpy()\n",
    "    print('Predicted: ', ''.join(idx2char[x] for x in idx), end='')\n",
    "    print(', Epoch [%d/15] loss=%.3f'%(epoch+1, loss.item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=[1/15] predicted string: hhhhh loss=1.4556509256362915\n",
      "epoch=[2/15] predicted string: hhhhh loss=1.2695140838623047\n",
      "epoch=[3/15] predicted string: hheee loss=1.095517873764038\n",
      "epoch=[4/15] predicted string: heeee loss=1.007908582687378\n",
      "epoch=[5/15] predicted string: eeeee loss=0.9867005348205566\n",
      "epoch=[6/15] predicted string: heeee loss=0.9086171388626099\n",
      "epoch=[7/15] predicted string: hheee loss=0.7997862696647644\n",
      "epoch=[8/15] predicted string: hheee loss=0.6967059373855591\n",
      "epoch=[9/15] predicted string: hheee loss=0.605985164642334\n",
      "epoch=[10/15] predicted string: hheee loss=0.5224521160125732\n",
      "epoch=[11/15] predicted string: hheeo loss=0.4298643171787262\n",
      "epoch=[12/15] predicted string: hheeo loss=0.3398049473762512\n",
      "epoch=[13/15] predicted string: hheeo loss=0.26292338967323303\n",
      "epoch=[14/15] predicted string: hheeo loss=0.20090839266777039\n",
      "epoch=[15/15] predicted string: hheeo loss=0.154021754860878\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset\n",
    "import torch\n",
    "idx2char = ['h', 'e', 'l', 'o']\n",
    "x_data = [0, 1, 2, 2, 3]  # hello\n",
    "y_data = [0, 0, 1, 1, 3]  # hheeo\n",
    "y_data = torch.LongTensor(y_data)\n",
    "\n",
    "# define model using class\n",
    "class LSTM_Model(torch.nn.Module):\n",
    "    def __init__(self, input_num, hidden_size, num_layers, embedding_size, num_class):\n",
    "        super(LSTM_Model, self).__init__()\n",
    "        self.input_num = input_num\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_class = num_class\n",
    "        \n",
    "        self.lstm = torch.nn.LSTM(self.embedding_size, self.hidden_size, self.num_layers)\n",
    "        self.emb = torch.nn.Embedding(self.input_num, self.embedding_size)\n",
    "        self.fc = torch.nn.Linear(self.hidden_size, self.num_class)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        input = self.emb(input)  # input为(seqLen, batch_size, input_num)\n",
    "        output, _ = self.lstm(input)  # output为(seqLen, batch_size, hidden_size)\n",
    "        return self.fc(output.view(-1, hidden_size))\n",
    "\n",
    "input_num = 5\n",
    "hidden_size = 5\n",
    "num_layers = 2\n",
    "embedding_size = 8\n",
    "num_class = 4\n",
    "seq_len = 5\n",
    "batch_size = 1\n",
    "\n",
    "model = LSTM_Model(input_num, hidden_size, num_layers, embedding_size, num_class)\n",
    "\n",
    "# construct loss functions and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# training cycle\n",
    "for epoch in range(15):\n",
    "    # forward\n",
    "    input = torch.LongTensor(x_data).view(seq_len, batch_size)\n",
    "    y_pred = model(input)\n",
    "    _, predicted_num = torch.max(y_pred, dim=1)\n",
    "    predicted_str = [idx2char[x] for x in predicted_num]\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('epoch=[{}/15] predicted string: '.format(epoch+1)+''.join(predicted_str)+' loss={}'.format(loss.item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=[1/15] predicted string: ooooo loss=1.3996633291244507\n",
      "epoch=[2/15] predicted string: lllll loss=1.2695358991622925\n",
      "epoch=[3/15] predicted string: lllll loss=1.0663855075836182\n",
      "epoch=[4/15] predicted string: eello loss=0.75921231508255\n",
      "epoch=[5/15] predicted string: eello loss=0.5712812542915344\n",
      "epoch=[6/15] predicted string: eello loss=0.4111711084842682\n",
      "epoch=[7/15] predicted string: eello loss=0.31522053480148315\n",
      "epoch=[8/15] predicted string: eello loss=0.2758745551109314\n",
      "epoch=[9/15] predicted string: hello loss=0.253097265958786\n",
      "epoch=[10/15] predicted string: hello loss=0.2264854609966278\n",
      "epoch=[11/15] predicted string: hello loss=0.1966380774974823\n",
      "epoch=[12/15] predicted string: hello loss=0.1621108502149582\n",
      "epoch=[13/15] predicted string: hello loss=0.1187082976102829\n",
      "epoch=[14/15] predicted string: hello loss=0.08412198722362518\n",
      "epoch=[15/15] predicted string: hello loss=0.053834401071071625\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# 1. prepare the dataset\n",
    "idx2char = ['h', 'e', 'l', 'o']\n",
    "x_data = [0, 0, 1, 1, 3]  # hheeo\n",
    "y_data = [0, 1, 2, 2, 3] # hello\n",
    "\n",
    "# 2. define model using class\n",
    "class GRU_Model(torch.nn.Module):\n",
    "    def __init__(self, seq_len, num_class, hidden_size, embedding_size, batch_size, num_layers):\n",
    "        super(GRU_Model, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.num_class = num_class\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(self.seq_len, self.embedding_size)\n",
    "        self.gru = torch.nn.GRU(self.embedding_size, self.hidden_size, self.num_layers)\n",
    "        self.fc = torch.nn.Linear(self.hidden_size, self.num_class)\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = torch.LongTensor(x_data).view(self.seq_len, self.batch_size)\n",
    "        input = self.embedding(input)  # input的维度为(swq_len, batch_size, embedding_size)\n",
    "        input, _ = self.gru(input)\n",
    "        input = input.view(-1, self.hidden_size)\n",
    "        return self.fc(input)\n",
    "\n",
    "# 初始化参数\n",
    "seq_len = len(y_data)\n",
    "num_class = len(idx2char)\n",
    "hidden_size = 10\n",
    "embedding_size = 10\n",
    "batch_size = 1\n",
    "num_layers = 2\n",
    "\n",
    "model = GRU_Model(seq_len, num_class, hidden_size, embedding_size, batch_size, num_layers)\n",
    "\n",
    "# 3. construct loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()  # 输入的数据是softmax之前的数据\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# 4. training cycle\n",
    "for epoch in range(15):\n",
    "    # forward\n",
    "    y_pred = model(x_data)  # y_pred的维度为(batch_size, num_class)\n",
    "    _, y_predicted_num = torch.max(y_pred, dim=1)\n",
    "    y_predicted_str = [idx2char[x] for x in y_predicted_num]\n",
    "    labels = torch.LongTensor(y_data)\n",
    "    loss = criterion(y_pred, labels)\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print('epoch=[{}/15]'.format(epoch+1)+' predicted string: {}'.format(''.join(y_predicted_str))+' loss={}'.format(loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture_13_RNN_Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adsit</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ajdrna</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Antonowitsch</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Antonowitz</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ballalatak</td>\n",
       "      <td>Czech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13369</th>\n",
       "      <td>Zabek</td>\n",
       "      <td>Polish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13370</th>\n",
       "      <td>Zdunowski</td>\n",
       "      <td>Polish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13371</th>\n",
       "      <td>Zdunowski</td>\n",
       "      <td>Polish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13372</th>\n",
       "      <td>Ziemniak</td>\n",
       "      <td>Polish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13373</th>\n",
       "      <td>Zientek</td>\n",
       "      <td>Polish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13374 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name Country\n",
       "0             Adsit   Czech\n",
       "1            Ajdrna   Czech\n",
       "2      Antonowitsch   Czech\n",
       "3        Antonowitz   Czech\n",
       "4        Ballalatak   Czech\n",
       "...             ...     ...\n",
       "13369         Zabek  Polish\n",
       "13370     Zdunowski  Polish\n",
       "13371     Zdunowski  Polish\n",
       "13372      Ziemniak  Polish\n",
       "13373       Zientek  Polish\n",
       "\n",
       "[13374 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "names_train = pd.read_csv('./names_train.csv', header=None, names=['Name', 'Country'])\n",
    "names_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1. prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. prepare dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "# parameters\n",
    "HIDDEN_SIZE = 100  # hidden_size与input_size是相同的, input_size应该表示的是整个字典的大小\n",
    "BATCH_SIZE = 256\n",
    "N_LAYER = 2\n",
    "N_EPOCHS = 100\n",
    "N_CHARS = 128\n",
    "USE_GPU = True\n",
    "\n",
    "class NameDataset(Dataset):\n",
    "    def __init__(self, is_train_set=True):\n",
    "        filename = './names_train.csv' if is_train_set else './names_test.csv'\n",
    "        file = pd.read_csv(filename, header=None, names=['Name', 'Country'])\n",
    "        self.names = file['Name'].tolist()  # 包含name字符串的list\n",
    "        self.len = len(self.names)\n",
    "        self.countries = file['Country'].tolist()  # 包含country字符串的list\n",
    "        self.country_list = list(sorted(set(self.countries)))  # 消除重复的country，并将country按照字母大小的顺序进行排列\n",
    "        self.country_dict = self.getCountryDict()  # 自定义函数将country转化为字典，key是不同的country字符串，value是其索引\n",
    "        self.country_num = len(self.country_list)  # 返回country的数目\n",
    "\n",
    "    def __getitem__(self, index):  # 返回的是name字符串和country对应的索引号，即种类号，比如han, 1\n",
    "        return self.names[index], self.country_dict[self.countries[index]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    # 将country映射到0, 1, 2等这些种类\n",
    "    def getCountryDict(self):\n",
    "        country_dict = dict()\n",
    "        for idx, country_name in enumerate(self.country_list):\n",
    "            country_dict[country_name] = idx \n",
    "        return country_dict \n",
    "\n",
    "    # 将种类编号转换为具体的country\n",
    "    def idx2country(self, index):\n",
    "        return self.country_list[index]\n",
    "\n",
    "    # 获得country的种类的总数\n",
    "    def getCountriesNum(self):\n",
    "        return self.country_num\n",
    "\n",
    "trainset = NameDataset(is_train_set=True)\n",
    "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)  # trainloder中返回的数据为han, 1\n",
    "testset = NameDataset(is_train_set=False)\n",
    "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "N_COUNTRY = trainset.getCountriesNum()  # N_COUNTRY是模型最后的输出的size\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. define the model using class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model using class\n",
    "class RNNClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers, bidirectional=True):  # 模型使用的是双端的GRU\n",
    "        super(RNNClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers \n",
    "        self.n_directions = 2 if bidirectional else 1\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(input_size, hidden_size)  # input_size表示的是整个coutry字典的大小  input_size的具体内容需要弄清楚 input_size即num_embedding-size of the dictionary of embeddings\n",
    "        self.gru = torch.nn.GRU(hidden_size, hidden_size, n_layers, bidirectional=bidirectional)\n",
    "        self.fc = torch.nn.Linear(hidden_size*self.n_directions, output_size)\n",
    "\n",
    "    def __init__hidden(self, batch_size):  # 这个初始化可以不进行（GRU中默认初始化为0），这里的batch_size需要给定\n",
    "        hidden = torch.zeros(self.n_layers*self.n_directions, batch_size, self.hidden_size)\n",
    "        return create_tensor(hidden)  # 将数据放到GPU上面\n",
    "\n",
    "    def forward(self, input, seq_lengths):\n",
    "        # input shape: batch_size, seq_lengths --> seq_lengths, batch_size\n",
    "        input = input.t()\n",
    "        batch_size = input.size(1)\n",
    "\n",
    "        hidden = self.__init__hidden(batch_size)\n",
    "        embedding = self.embedding(input)   # 此时embedding的维度为(seq_lengths, batch_size, hidden_size)\n",
    "\n",
    "        # pack them up\n",
    "        gru_input = pack_padded_sequence(embedding, seq_lengths) \n",
    "        output, hidden = self.gru(gru_input, hidden)\n",
    "        if self.n_directions == 2:\n",
    "            hidden_cat = torch.cat([hidden[-1], hidden[-2]], dim=1)  # 这里的hidden的维度需要进一步弄清楚\n",
    "        else:\n",
    "            hidden_cat = hidden[-1]\n",
    "        fc_output = self.fc(hidden_cat)\n",
    "        return fc_output\n",
    "    \n",
    "# convert name to tensor\n",
    "def name2list(name):  # 将一个字符串转化为对应的ASCII list\n",
    "    arr = [ord(c) for c in name]\n",
    "    return arr, len(arr)  # 返回列表和列表对应的长度\n",
    "\n",
    "def create_tensor(tensor):\n",
    "    if USE_GPU:\n",
    "        device = torch.device('cuda:0')\n",
    "        tensor = tensor.to(device)\n",
    "        return tensor\n",
    "\n",
    "def make_tensors(names, countries):\n",
    "    sequences_and_lengths = [name2list(name) for name in names]\n",
    "    name_sequences = [s1[0] for s1 in sequences_and_lengths]\n",
    "    seq_lengths = torch.LongTensor([s1[1] for s1 in sequences_and_lengths])\n",
    "    countries = countries.long()\n",
    "\n",
    "    # make tensor of name, BatchSizexSeqLen\n",
    "    seq_tensor = torch.zeros(len(name_sequences), seq_lengths.max()).long()\n",
    "    for idx, (seq, seq_len) in enumerate(zip(name_sequences, seq_lengths)):\n",
    "        seq_tensor[idx, :seq_len] = torch.LongTensor(seq)\n",
    "\n",
    "    # sort by length to use pack_padded_sequence\n",
    "    seq_lengths, perm_idx = seq_lengths.sort(dim=0, descending=True)\n",
    "    seq_tensor = seq_tensor[perm_idx]\n",
    "    countries = countries[perm_idx]\n",
    "\n",
    "    # return create_tensor(seq_tensor), create_tensor(seq_lengths), create_tensor(countries)\n",
    "    return create_tensor(seq_tensor), seq_lengths, create_tensor(countries)\n",
    "\n",
    "input_size = N_CHARS\n",
    "hidden_size = HIDDEN_SIZE\n",
    "output_size = N_COUNTRY\n",
    "n_layers = N_LAYER\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "classifier = RNNClassifier(input_size, hidden_size, output_size, n_layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNClassifier(\n",
       "  (embedding): Embedding(128, 100)\n",
       "  (gru): GRU(100, 100, num_layers=2, bidirectional=True)\n",
       "  (fc): Linear(in_features=200, out_features=18, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- define loss functions and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(classifier.parameters(), lr=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- training cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(epoch):  # 定义每个epoch的训练函数\n",
    "    total_loss = 0  # 统计每个epoch的loss\n",
    "    for i, (names, countries) in enumerate(trainloader):  # trainloader返回的数据格式是han, 0\n",
    "        inputs, seq_lengths, target = make_tensors(names, countries)  # 此时还没有embedding\n",
    "        output = classifier(inputs, seq_lengths)  # 在模型中先对输入的数据进行embedding再输入到网络中\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        # if i % 10 == 0:\n",
    "        # print(f'[{time_since(start)}] Epoch {epoch}', end='')\n",
    "        # print(f'[{i*len(inputs)}/{len(trainset)}]', end='   ')\n",
    "        # print(f'loss={total_loss/((i+1)*len(inputs))}')\n",
    "    return total_loss\n",
    "        # prtotal_loss\n",
    "    # 画出训练loss的变化情况\n",
    "    # plt.plot(epoch_loss_list)\n",
    "    # plt.ylabel('loss')\n",
    "    # plt.xlabel('epoch')\n",
    "\n",
    "def testModel():\n",
    "    correct = 0\n",
    "    total = len(testset)\n",
    "    print('evaluating trained model ...')\n",
    "    with torch.no_grad():\n",
    "        for i, (names, countries) in enumerate(testloader):\n",
    "            inputs, seq_lengths, target = make_tensors(names, countries)\n",
    "            output = classifier(inputs, seq_lengths)\n",
    "            pred = output.max(dim=1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        percent = '%.2f'%(100*correct/total)\n",
    "        print(f'Test set: Accuracy {correct}/{total} {percent}%')\n",
    "    # return correct/total\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 训练和测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 0 epoch_loss= 52.087039321660995\n",
      "epoch= 1 epoch_loss= 47.3882954120636\n",
      "epoch= 2 epoch_loss= 38.45996308326721\n",
      "epoch= 3 epoch_loss= 40.954197227954865\n",
      "epoch= 4 epoch_loss= 37.826224595308304\n",
      "epoch= 5 epoch_loss= 41.294422030448914\n",
      "epoch= 6 epoch_loss= 38.75519406795502\n",
      "epoch= 7 epoch_loss= 36.76535093784332\n",
      "epoch= 8 epoch_loss= 40.40023323893547\n",
      "epoch= 9 epoch_loss= 38.996862441301346\n",
      "epoch= 10 epoch_loss= 35.71906819939613\n",
      "epoch= 11 epoch_loss= 38.0752327144146\n",
      "epoch= 12 epoch_loss= 38.48666524887085\n",
      "epoch= 13 epoch_loss= 33.51902875304222\n",
      "epoch= 14 epoch_loss= 36.8626184463501\n",
      "epoch= 15 epoch_loss= 37.074576050043106\n",
      "epoch= 16 epoch_loss= 34.40928277373314\n",
      "epoch= 17 epoch_loss= 33.928251057863235\n",
      "epoch= 18 epoch_loss= 34.85398659110069\n",
      "epoch= 19 epoch_loss= 40.459141314029694\n",
      "epoch= 20 epoch_loss= 32.32842203974724\n",
      "epoch= 21 epoch_loss= 36.28886967897415\n",
      "epoch= 22 epoch_loss= 33.96310290694237\n",
      "epoch= 23 epoch_loss= 37.27762854099274\n",
      "epoch= 24 epoch_loss= 33.416763842105865\n",
      "epoch= 25 epoch_loss= 38.40441423654556\n",
      "epoch= 26 epoch_loss= 37.92120659351349\n",
      "epoch= 27 epoch_loss= 35.70113170146942\n",
      "epoch= 28 epoch_loss= 35.20532184839249\n",
      "epoch= 29 epoch_loss= 33.672472298145294\n",
      "epoch= 30 epoch_loss= 36.33028209209442\n",
      "epoch= 31 epoch_loss= 33.790662467479706\n",
      "epoch= 32 epoch_loss= 40.244047820568085\n",
      "epoch= 33 epoch_loss= 33.661805748939514\n",
      "epoch= 34 epoch_loss= 37.369914174079895\n",
      "epoch= 35 epoch_loss= 36.0799979865551\n",
      "epoch= 36 epoch_loss= 34.14413005113602\n",
      "epoch= 37 epoch_loss= 34.696130365133286\n",
      "epoch= 38 epoch_loss= 34.45327988266945\n",
      "epoch= 39 epoch_loss= 37.074175506830215\n",
      "epoch= 40 epoch_loss= 31.41683280467987\n",
      "epoch= 41 epoch_loss= 34.041278034448624\n",
      "epoch= 42 epoch_loss= 35.86246797442436\n",
      "epoch= 43 epoch_loss= 35.94634348154068\n",
      "epoch= 44 epoch_loss= 35.49998486042023\n",
      "epoch= 45 epoch_loss= 33.1452551484108\n",
      "epoch= 46 epoch_loss= 34.45482620596886\n",
      "epoch= 47 epoch_loss= 33.86262512207031\n",
      "epoch= 48 epoch_loss= 31.787679731845856\n",
      "epoch= 49 epoch_loss= 31.83521682024002\n",
      "epoch= 50 epoch_loss= 35.71272864937782\n",
      "epoch= 51 epoch_loss= 33.76573368906975\n",
      "epoch= 52 epoch_loss= 33.03933110833168\n",
      "epoch= 53 epoch_loss= 34.941349148750305\n",
      "epoch= 54 epoch_loss= 31.216656118631363\n",
      "epoch= 55 epoch_loss= 35.5490645468235\n",
      "epoch= 56 epoch_loss= 29.91562807559967\n",
      "epoch= 57 epoch_loss= 32.84124958515167\n",
      "epoch= 58 epoch_loss= 32.312718719244\n",
      "epoch= 59 epoch_loss= 33.06066021323204\n",
      "epoch= 60 epoch_loss= 34.01541143655777\n",
      "epoch= 61 epoch_loss= 30.292171090841293\n",
      "epoch= 62 epoch_loss= 35.05271252989769\n",
      "epoch= 63 epoch_loss= 32.345255970954895\n",
      "epoch= 64 epoch_loss= 33.11878761649132\n",
      "epoch= 65 epoch_loss= 36.16753113269806\n",
      "epoch= 66 epoch_loss= 33.23284697532654\n",
      "epoch= 67 epoch_loss= 31.939455091953278\n",
      "epoch= 68 epoch_loss= 30.063106954097748\n",
      "epoch= 69 epoch_loss= 31.522075295448303\n",
      "epoch= 70 epoch_loss= 37.358356297016144\n",
      "epoch= 71 epoch_loss= 30.815776854753494\n",
      "epoch= 72 epoch_loss= 34.460499972105026\n",
      "epoch= 73 epoch_loss= 31.997722297906876\n",
      "epoch= 74 epoch_loss= 27.765366852283478\n",
      "epoch= 75 epoch_loss= 33.833751291036606\n",
      "epoch= 76 epoch_loss= 36.349436312913895\n",
      "epoch= 77 epoch_loss= 28.310309290885925\n",
      "epoch= 78 epoch_loss= 32.28813624382019\n",
      "epoch= 79 epoch_loss= 33.21268591284752\n",
      "epoch= 80 epoch_loss= 35.02942171692848\n",
      "epoch= 81 epoch_loss= 30.343143463134766\n",
      "epoch= 82 epoch_loss= 29.75002184510231\n",
      "epoch= 83 epoch_loss= 31.54854464530945\n",
      "epoch= 84 epoch_loss= 31.836849853396416\n",
      "epoch= 85 epoch_loss= 30.27941209077835\n",
      "epoch= 86 epoch_loss= 30.76352408528328\n",
      "epoch= 87 epoch_loss= 32.611605286598206\n",
      "epoch= 88 epoch_loss= 30.03708267211914\n",
      "epoch= 89 epoch_loss= 29.690755993127823\n",
      "epoch= 90 epoch_loss= 33.26929673552513\n",
      "epoch= 91 epoch_loss= 31.14993527531624\n",
      "epoch= 92 epoch_loss= 36.23491641879082\n",
      "epoch= 93 epoch_loss= 31.32863837480545\n",
      "epoch= 94 epoch_loss= 31.247094124555588\n",
      "epoch= 95 epoch_loss= 33.38957616686821\n",
      "epoch= 96 epoch_loss= 32.195310950279236\n",
      "epoch= 97 epoch_loss= 33.24793756008148\n",
      "epoch= 98 epoch_loss= 32.42729538679123\n",
      "epoch= 99 epoch_loss= 30.3963061273098\n",
      "evaluating trained model ...\n",
      "Test set: Accuracy 4860/6700 72.54%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 训练\n",
    "import matplotlib.pyplot as plt\n",
    "epoch_loss_list = []\n",
    "for epoch in range(N_EPOCHS):\n",
    "    epoch_loss = trainModel(epoch)\n",
    "    epoch_loss_list.append(epoch_loss)\n",
    "    print('epoch=', epoch, 'epoch_loss=', epoch_loss)\n",
    "plt.plot(epoch_loss_list)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "# 测试\n",
    "testModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 理解pack_padded_sequence\n",
    "    - [重要参考网址一](https://www.cnblogs.com/kykai/p/14033580.html)\n",
    "    - [重要参考网址二](https://www.cnblogs.com/sbj123456789/p/9834018.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在句子经过pad填充以后：\n",
      "tensor([1, 2, 0, 0, 0, 0])\n",
      "\n",
      "所有句子融合以后可以获得整个矩阵：\n",
      "tensor([[1, 2, 0, 0, 0, 0],\n",
      "        [1, 2, 3, 0, 0, 0],\n",
      "        [1, 2, 3, 4, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0],\n",
      "        [1, 2, 3, 4, 5, 6]])\n",
      "\n",
      "经过了pack_padded_sequence处理\n",
      "PackedSequence(data=tensor([1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 5, 6]), batch_sizes=tensor([5, 4, 3, 2, 1, 1]), sorted_indices=tensor([4, 2, 1, 0, 3]), unsorted_indices=tensor([3, 2, 1, 4, 0]))\n",
      "\n",
      "Unpack还原的结果：\n",
      "tensor([[1, 2, 0, 0, 0, 0],\n",
      "        [1, 2, 3, 0, 0, 0],\n",
      "        [1, 2, 3, 4, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0],\n",
      "        [1, 2, 3, 4, 5, 6]])\n",
      "\n",
      "同时返回seq的length：\n",
      "tensor([2, 3, 4, 1, 6])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.nn import utils as nn_utils\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "# seq example\n",
    "# batch的尺寸是5，假设我们有五句话，每句话有不定长的词汇\n",
    "# 这里只假设每个词汇的feature是一维的\n",
    "batch_size = 5\n",
    "a = torch.tensor([1, 2])\n",
    "b = torch.tensor([1, 2, 3])\n",
    "c = torch.tensor([1, 2, 3, 4])\n",
    "d = torch.tensor([1])\n",
    "e = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# general setting\n",
    "# 提取五个句子的有效内容的长度\n",
    "# 并且提取最大句子的长度\n",
    "seq_lens = []\n",
    "for i in [a, b, c, d, e]:\n",
    "    seq_lens.append(len(i))\n",
    "max_len = max(seq_lens)\n",
    "\n",
    "# zero padding\n",
    "# 通过加入0pad，让他们长度相等，这个长度是最长句子的长度\n",
    "a = F.pad(a, (0, max_len-len(a)))\n",
    "b = F.pad(b, (0, max_len-len(b)))\n",
    "c = F.pad(c, (0, max_len-len(c)))\n",
    "d = F.pad(d, (0, max_len-len(d)))\n",
    "e = F.pad(e, (0, max_len-len(e)))\n",
    "print('在句子经过pad填充以后：\\n{}\\n'.format(a))\n",
    "\n",
    "# merge the seq\n",
    "seq = torch.cat((a, b, c, d, e), 0).view(-1, max_len)\n",
    "print('所有句子融合以后可以获得整个矩阵：\\n{}\\n'.format(seq))\n",
    "\n",
    "# Pack\n",
    "# 1. input size 可以是(TxBx*)=(最长序列长度T, batch_size B, 任意维度*)\n",
    "# 2. input size 可以是(BxTx*)，如果batch_first=True\n",
    "# 这里我们选择batch在前，所以是2\n",
    "packed_seq = pack_padded_sequence(seq, seq_lens, batch_first=True, enforce_sorted=False)\n",
    "print('经过了pack_padded_sequence处理\\n{}\\n'.format(packed_seq))\n",
    "\n",
    "# Unpack\n",
    "unpacked_seq, unpacked_lens = pad_packed_sequence(packed_seq, batch_first=True)\n",
    "print('Unpack还原的结果：\\n{}\\n'.format(unpacked_seq))\n",
    "print('同时返回seq的length：\\n{}\\n'.format(unpacked_lens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sentiment analysis on movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>156056</td>\n",
       "      <td>8544</td>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>156057</td>\n",
       "      <td>8544</td>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>156058</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>156059</td>\n",
       "      <td>8544</td>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>156060</td>\n",
       "      <td>8544</td>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PhraseId  SentenceId  \\\n",
       "0              1           1   \n",
       "1              2           1   \n",
       "2              3           1   \n",
       "3              4           1   \n",
       "4              5           1   \n",
       "...          ...         ...   \n",
       "156055    156056        8544   \n",
       "156056    156057        8544   \n",
       "156057    156058        8544   \n",
       "156058    156059        8544   \n",
       "156059    156060        8544   \n",
       "\n",
       "                                                   Phrase  Sentiment  \n",
       "0       A series of escapades demonstrating the adage ...          1  \n",
       "1       A series of escapades demonstrating the adage ...          2  \n",
       "2                                                A series          2  \n",
       "3                                                       A          2  \n",
       "4                                                  series          2  \n",
       "...                                                   ...        ...  \n",
       "156055                                          Hearst 's          2  \n",
       "156056                          forced avuncular chortles          1  \n",
       "156057                                 avuncular chortles          3  \n",
       "156058                                          avuncular          2  \n",
       "156059                                           chortles          2  \n",
       "\n",
       "[156060 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sentiment_train = pd.read_csv('./sentiment-analysis-on-movie-reviews/train.tsv', sep='\\t')\n",
    "sentiment_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 遗传算法\n",
    "[参考网址](https://blog.csdn.net/weixin_58427214/article/details/125860212)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 求解$x^3cos(x)(-1.57<=x<=20.18)$的最小值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 计算所需二进制编码位数\n",
    "# [start, end]为取值范围，precision为精度，即小数点后的位数\n",
    "import math\n",
    "def get_binary_bit(start, end, precision):\n",
    "    numbers = (end-start)*pow(10, precision)+1  # 将区间划分为等距离的点\n",
    "    if int(math.log(numbers, 2)) == math.log(numbers, 2):\n",
    "        return int(math.log(numbers, 2))\n",
    "    else:\n",
    "        return int(math.log(numbers, 2))+1\n",
    "    \n",
    "    \n",
    "# 2. 编码\n",
    "# 将十进制数转化为对应的二进制数，decimal为未编码的十进制数\n",
    "def binary_encode(decimal, start, end, precision):\n",
    "    bit = get_binary_bit(start, end, precision)\n",
    "    # 将十进制转换为对应的二进制编码\n",
    "    binary = bin(int(decimal-start)*pow(10, precision))\n",
    "    # 由于bin()生成的是0bxxxxxx的形式，因此切片\n",
    "    binary = str(binary)[2:]\n",
    "    # 补齐位数\n",
    "    while len(binary) < bit:\n",
    "        binary = '0'+binary\n",
    "    # 返回二进制编码\n",
    "    return binary\n",
    "\n",
    "\n",
    "# 3. 解码\n",
    "# 将二进制编码转换为对应的实际取值，binary为二进制编码\n",
    "def binary_decode(binary, start, precision):\n",
    "    # 将二进制编码转为标准形式0bxxxxxx\n",
    "    binary = '0b'+binary\n",
    "    # 将二进制编码转为十进制编码\n",
    "    decimal = int(binary, 2)\n",
    "    # 将十进制编码转为对应的十进制数\n",
    "    decimal = start + decimal/pow(10, precision)\n",
    "    return decimal\n",
    "\n",
    "# 4. 随机生成初始种群\n",
    "# population为种群大小\n",
    "import random\n",
    "def initialization(population, start, end, precision):\n",
    "    initialized = []\n",
    "    for i in range(population):\n",
    "        # 随机生成指定范围和精度的小数，并转为二进制编码\n",
    "        random_float = random.uniform(start, end)\n",
    "        random_float_precision = round(random_float, precision)\n",
    "        random_binary = binary_decode(random_float_precision, start, end, precision)\n",
    "        initialized.append(random_binary)\n",
    "    # 返回初始化种群\n",
    "    return initialized\n",
    "\n",
    "# 4. 随机初始初始种群（缩小随机取值的区间，加快算法的收敛）\n",
    "# [optimize_start, optimize_end]为大致估计区间\n",
    "def initialization(population, start, end, precision, optimize_start, optimize_end):\n",
    "    initialized = []\n",
    "    for i in range(population):\n",
    "        random_float = random.uniform(optimize_start, optimize_end)\n",
    "        random_float_precision = round(random_float, precision)\n",
    "        random_binary = binary_encode(random_float_precision, start, end, precision)\n",
    "        initialized.append(random_binary)\n",
    "    return initialized\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13 |Anaconda, Inc.| (default, Jun  4 2021, 14:25:59) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
